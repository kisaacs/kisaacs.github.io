define({ entries : {
    "Adamoli2010Trevis": {
        "abstract": "When developers profile their applications to identify performance problems, they normally use profilers producing calling context trees. A calling context tree (CCT) represents the caller-callee relationships of a program. A dynamically collected CCT provides method coverage information. The CCTs produced by profilers also include method hot- ness information. Trevis, our context tree visualization and analysis framework, allows users to visualize, compare, cluster, and intersect CCTs produced by profilers. We evaluate Trevis in the context of a novel profiling tool called FlyBy. FlyBy runs transparently on an end-user\u2019s computer and continuously samples the applications\u2019 call stack. When the user perceives the application as sluggish, she presses a \u201cWas Slow!\u201d button to tell FlyBy to file a performance failure re- port. The report contains the CCT based on the call stack samples FlyBy gathered over the last few seconds before the user pressed the button. We show how Trevis allows us to visualize and classify FlyBy bug reports.",
        "acmid": "1879224",
        "address": "New York, NY, USA",
        "author": "Adamoli, Andrea and Hauswirth, Matthias",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879224",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, name: Trevis, context: software, subcontext: callgraph, vis: sunburst, vis: radial, vis: ensemble, vis: clustering",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "73--82",
        "publisher": "ACM",
        "series": "SoftVis",
        "title": "Trevis: A Context Tree Visualization \\& Analysis Framework and Its Use for Classifying Performance Failure Reports",
        "type": "InProceedings",
        "year": "2010"
    },
    "Adhianto2010HPCToolkit": {
        "abstract": "HPCTOOLKIT is an integrated suite of tools that supports measurement, analysis, attribution, and presentation of application performance for both sequential and parallel programs. HPCTOOLKIT can pinpoint and quantify scalability bottlenecks in fully optimized parallel programs with a measurement overhead of only a few percent. Recently, new capabilities were added to HPCTOOLKIT for collecting call path profiles for fully optimized codes without any compiler support, pinpointing and quantifying bottlenecks in multithreaded programs, exploring performance information and source code using a new user interface, and displaying hierarchical space-time diagrams based on traces of asynchronous call path samples. This paper provides an overview of HPCTOOLKIT and illustrates its utility for performance analysis of parallel applications.",
        "author": "Adhianto, Laksono and Banerjee, S. and Fagan, Mike and Krentel, Mark and Marin, G. and Mellor-Crummey, John M. and Tallent, Nathan R.",
        "doi": "10.1002/cpe.1553",
        "issn": "1532-0634",
        "journal": "Concurrency and Computation: Practice and Experience",
        "keywords": "type: research, name: HPCToolkit, context: software, context: tasks, subcontext: callgraph, subcontext: trace, vis: indented tree, vis: timelines, parallel scale: 10K",
        "number": "6",
        "pages": "685--701",
        "publisher": "John Wiley \\& Sons, Ltd.",
        "series": "Wiley",
        "title": "HPCTOOLKIT: tools for performance analysis of optimized parallel programs",
        "type": "article",
        "volume": "22",
        "year": "2010"
    },
    "Adhianto2016HPCToolkit": {
        "abstract": "Analysis and optimization of long-running applications on large-scale parallel systems is important to avoid unacceptable inefficiencies. Tracing is one of the most popular techniques for understanding the performance of parallel programs. Since tracing captures data in the time dimension, the size of a trace is linearly proportional to execution time. For that reason, traces of long-running executions of parallel programs may contain gigabytes or even terabytes of data. Presenting huge traces in a scalable fashion and identifying performance bottlenecks hidden in an ocean of data are challenging problems. To pinpoint performance bottlenecks effectively, a performance visualization tool needs to be relatively responsive and scalable. It also needs to be able to present both a global view of the performance of all threads and processes in a parallel execution, and a local view to see the full detail of a trace for an individual thread or process. Our approach to address this challenge is to use a client-server approach for trace visualization in hpctraceviewer, which is part of the HPCTOOLKIT performance tools. This paper demonstrates the utility of our tool for identifying performance bottlenecks in large-scale executions through case studies with two Department of Energy procurement benchmarks: Algebraic Multi Grid (AMG) and Unstructured Mesh Transport (UMT) codes. Finally, the experiment shows that our implementation is scalable, rendering views of huge traces stored on remote supercomputers in a few seconds.",
        "author": "Adhianto, Laksono and Taffet, Philip",
        "booktitle": "45th International Conference on Parallel Processing Workshops",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: timelines, vis: client-server, parallel scale: 10k",
        "pages": "319--328",
        "series": "ICCPW",
        "title": "Addressing Challenges in Visualizing Huge Call-Path Traces",
        "type": "inproceedings",
        "year": "2016"
    },
    "Aftandilian2010": {
        "abstract": "Understanding the data structures in a program is crucial to understanding how the program works, or why it doesn\u2019t work. Inspecting the code that implements the data structures, however, is an arduous task and often fails to yield insights into the global organization of a program\u2019s data. Inspecting the actual contents of the heap solves these problems but presents a significant challenge of its own: finding an effective way to present the enormous number of objects it contains. In this paper we present Heapviz, a tool for visualizing and exploring snapshots of the heap obtained from a running Java program. Unlike existing tools, such as traditional debuggers, Heapviz presents a global view of the program state as a graph, together with powerful interactive capabilities for navigating it. Our tool employs several key techniques that help manage the scale of the data. First, we reduce the size and complexity of the graph by using algorithms inspired by static shape analysis to aggregate the nodes that make up a data structure. Second, we introduce a dominator-based layout scheme that emphasizes hierarchical containment and ownership relations. Finally, the interactive interface allows the user to expand and contract regions of the heap to mod- ulate data structure detail, inspect individual objects and field values, and search for objects based on type or connectivity. By applying Heapviz to both constructed and real-world examples, we show that Heapviz provides pro- grammers with a powerful and intuitive tool for exploring program behavior.",
        "acmid": "1879222",
        "address": "New York, NY, USA",
        "author": "Aftandilian, Edward E. and Kelley, Sean and Gramazio, Connor and Ricci, Nathan and Su, Sara L. and Guyer, Samuel Z.",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879222",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, name: Heapviz, context: software, subcontext: data structures, subcontext: debugging",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "53--62",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Heapviz: Interactive Heap Visualization for Program Understanding and Debugging",
        "type": "InProceedings",
        "year": "2010"
    },
    "Ahn2009STAT": {
        "abstract": "We present a scalable temporal order analysis technique that supports debugging of large scale applications by classifying MPI tasks based on their logical program execution order. Our approach combines static analysis techniques with dynamic analysis to determine this temporal order scalably. It uses scalable stack trace analysis techniques to guide selection of critical program execution points in anomalous application runs. Our novel temporal ordering engine then leverages this information along with the application's static control structure to apply data flow analysis techniques to determine key application data such as loop control variables. We then use lightweight techniques to gather the dynamic data that determines the temporal order of the MPI tasks. Our evaluation, which extends the Stack Trace Analysis Tool (STAT), demonstrates that this temporal order analysis technique can isolate bugs in benchmark codes with injected faults as well as a real world hang case with AMG2006.",
        "acmid": "1654104",
        "address": "New York, NY, USA",
        "articleno": "44",
        "author": "Ahn, Dong H. and de Supinski, Bronis R. and Laguna, Ignacio and Lee, Gregory L. and Liblit, Ben and Miller, Barton P. and Schulz, Martin",
        "booktitle": "Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis",
        "doi": "10.1145/1654059.1654104",
        "isbn": "978-1-60558-744-8",
        "keywords": "type: research, name: STAT, context: software, subcontext: callgraph, vis: node-link, parallel scale: 1M, subcontext: debugging",
        "location": "Portland, Oregon",
        "numpages": "11",
        "pages": "44:1--44:11",
        "publisher": "ACM",
        "series": "SC",
        "title": "Scalable Temporal Order Analysis for Large Scale Debugging",
        "type": "InProceedings",
        "year": "2009"
    },
    "Alpern1990": {
        "abstract": "The authors describe a conceptual model, the memory hierarchy framework, and a visual language for using the model. The model is more faithful to the structure of computers than the Von Neumann and Turing models. It addresses the issues of data movement and exposes and unifies storage mechanisms such as cache, translation lookaside buffers, main memory, and disks. The visual language presents the details of a computer's memory hierarchy in a concise drawing composed of rectangles and connecting segments. Using this framework, the authors improved the performance of a matrix multiplication algorithm by more than an order of magnitude. The framework gives insight into computer architecture and performance bottlenecks by making effective use of human visual abilities.",
        "acmid": "949548",
        "address": "Los Alamitos, CA, USA",
        "author": "Alpern, Bowen and Carter, Larry and Selker, Ted",
        "booktitle": "Proceedings of the 1st Conference on Visualization '90",
        "doi": "10.1109/VISUAL.1990.146371",
        "isbn": "0-8186-2083-8",
        "keywords": "type: research, context: hardware, subcontext: memory, vis: nested graphs, vis: node-link",
        "location": "San Francisco, California",
        "numpages": "7",
        "pages": "107--113",
        "publisher": "IEEE Computer Society Press",
        "series": "VIS",
        "title": "Visualizing Computer Memory Architectures",
        "type": "InProceedings",
        "year": "1990"
    },
    "Battle2016StreamTrace": {
        "abstract": "As real-time monitoring and analysis become increasingly important, researchers and developers turn to data stream management systems (DSMS's) for fast, efficient ways to pose temporal queries over their datasets. However, these systems are inherently complex, and even database experts find it difficult to understand the behavior of DSMS queries. To help analysts better understand these temporal queries, we developed StreamTrace, an interactive visualization tool that breaks down how a temporal query processes a given dataset, step-by-step. The design of StreamTrace is based on input from expert DSMS users; we evaluated the system with a lab study of programmers who were new to streaming queries. Results from the study demonstrate that StreamTrace can help users to verify that queries behave as expected and to isolate the regions of a query that may be causing unexpected results.",
        "author": "Battle, Leilani and Fisher, Danyel and DeLine, Robert and Barnett, Mike and Chandramouli, Badrish and Goldstein, Jonathan",
        "booktitle": "Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems",
        "doi": "10.1145/2858036.2858408",
        "keywords": "type: research, subcontext: databases, context: software, vis: timelines, vis: node-link, parallel scale: 1+, name: StreamTrace",
        "pages": "5433--5443",
        "series": "CHI",
        "title": "Making Sense of Temporal Queries with Interactive Visualization",
        "type": "InProceedings",
        "year": "2016"
    },
    "Beck2013": {
        "abstract": "Finding and fixing performance bottlenecks requires sound knowledge of the program that is to be optimized. In this paper, we propose an approach for presenting performance-related information to software engineers by visually augmenting source code shown in an editor. Small diagrams at each method declaration and method call visualize the propagation of runtime consumption through the program as well as the interplay of threads in parallelized programs. Advantages of in situ visualization like this over traditional representations, where code and profiling information are shown in different places, promise to be the prevention of a split-attention effect caused by multiple views; information is presented where required, which supports understanding and navigation. We implemented the approach as an IDE plug-in and tested it in a user study with four developers improving the performance of their own programs. The user study provides insights into the process of understanding performance bottlenecks with our approach.",
        "author": "Beck, Fabian and Moseler, Oliver and Diehl, Stephan and Rey, G\\\"unter D.",
        "booktitle": "2013 IEEE 21st International Conference on Program Comprehension",
        "doi": "10.1109/ICPC.2013.6613834",
        "issn": "1063-6897",
        "keywords": "type: research, context: software, vis: code",
        "month": "May",
        "pages": "63-72",
        "series": "ICPC",
        "title": "In situ understanding of performance bottlenecks through visually augmented code",
        "type": "InProceedings",
        "year": "2013"
    },
    "Bemmerl1992VISTOP": {
        "abstract": "Parallel programming is orders of magnitudes more complex than writing sequential programs. This is particularly true for programming distributed memory multiprocessor architectures based on message passing programming models. Understanding the synchronization and communication behavior of parallel programs is one of the most critical issues in programming distributed memory multiprocessors. The paper describes methods and tools for visualization and animation of the dynamic execution of parallel programs. Based on an evaluation and classification of existing visualization environments, the visualization and animation tool VISTOP (VISualization TOol for Parallel Systems) is presented as part of the integrated tool environment TOPSYS (TOols for Parallel SYStems) for pro- gramming distributed memory multiprocessors. VISTOP supports the interactive on-line visualization of message passing programs based on various views, in particular, a process graph based concurrency view for detecting synchronization and communication bugs.",
        "author": "Bemmerl, Thomas and Braun, Peter",
        "booktitle": "Parallel Processing: CONPAR 92-VAPP V",
        "doi": "10.1007/3-540-55895-0_400",
        "editor": "Boug\\'e, Luc and Cosnard, Michel and Robert, Yves and Trystram, Denis",
        "isbn": "978-3-540-55895-8",
        "keywords": "type: research, name: VISTOP, context: software, context: hardware, context: tasks, vis: icons, vis: indented tree, vis: matrix, parallel scale: 10",
        "pages": "79-90",
        "publisher": "Springer Berlin Heidelberg",
        "series": "Lecture Notes in Computer Science",
        "title": "Visualization of message passing parallel programs",
        "type": "InCollection",
        "volume": "634",
        "year": "1992"
    },
    "Beniamine2015TABARNAC": {
        "abstract": " In modern parallel architectures, memory accesses represent a common bottleneck. Thus, optimizing the way applications access the memory is an important way to improve performance and energy consumption. Memory accesses are even more important with NUMA machines, as the access time to data depends on its location in the memory. Many efforts were made to develop adaptive tools to improve memory accesses at the runtime by optimizing the mapping of data and threads to NUMA nodes. However, theses tools are not able to change the memory access pattern of the original application, therefore a code written without considering memory performance might not benefit from them. Moreover, automatic mapping tools take time to converge towards the best mapping, losing optimization opportunities. A deeper understanding of the memory behavior can help optimizing it, removing the need for runtime analysis. In this paper, we present TABARNAC, a tool for analyzing the memory behavior of parallel applications with a focus on NUMA architectures. TABARNAC provides a new visualization of the memory access behavior, focusing on the distribution of accesses by thread and by structure. Such visualization allows the developer to easily understand why performance issues occur and how to fix them. Using TABARNAC, we explain why some applications do not benefit from data and thread mapping. Moreover, we propose several code modifications to improve the memory access behavior of several parallel applications.",
        "acmid": "2835239",
        "articleno": "1",
        "author": "Beniamine, David and Diener, Matthias and Huard, Guillaume and Navaux, Philippe O. A.",
        "booktitle": "Proceedings of the 2nd Workshop on Visual Performance Analysis",
        "doi": "10.1145/2835238.2835239",
        "keywords": "type: research, context: hardware, subcontext: memory, subcontext: memory trace, subcontext: NUMA, subcontext: threads, vis: scatterplots, name: TABARNAC, vis: filtering",
        "numpages": "9",
        "pages": "1:1--1:9",
        "publisher": "ACM",
        "series": "VPA",
        "title": "TABARNAC: Visualizing and Resolving Memory Access Issues on NUMA Architectures",
        "type": "InProceedings",
        "year": "2015"
    },
    "Bernardin2008Lumiere": {
        "abstract": "We present a visualization system to assist designers of scheduling-based multi-threaded out-of-core algorithms. Our system facilitates the understanding and improving of the algorithm through a stack of visual widgets that effectively correlate the out-of-core system state with scheduling decisions. The stack presents an increasing refinement in the scope of both time and abstraction level; at the top of the stack, the evolution of a derived efficiency measure is shown for the scope of the entire out-of-core system execution and at the bottom the details of a single scheduling decision are displayed. The stack provides much more than a temporal zoom-effect as each widget presents a different view of the scheduling decision data, presenting distinct aspects of the out-of-core system state as well as correlating them with the neighboring widgets in the stack. This approach allows designers to to better understand and more effectively react to problems in scheduling or algorithm design. As a case study we consider a global illumination renderer and show how visualization of the scheduling behavior has led to key improvements of the renderer\u2019s performance.",
        "acmid": "1409746",
        "address": "New York, NY, USA",
        "author": "Bernardin, Tony and Budge, Brian C. and Hamann, Bernd",
        "booktitle": "Proceedings of the 4th ACM Symposium on Software Visualization",
        "doi": "10.1145/1409720.1409746",
        "isbn": "978-1-60558-112-5",
        "keywords": "type: research, name: Lumiere, context: software, subcontext: trace, vis: animation, vis: line charts, vis: multiple coordinated views, parallel scale: NR",
        "location": "Ammersee, Germany",
        "numpages": "10",
        "pages": "165--174",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Stacked-widget Visualization of Scheduling-based Algorithms",
        "type": "InProceedings",
        "year": "2008"
    },
    "Bezemer2015FlameGraph": {
        "abstract": "Flame graphs are gaining rapidly in popularity in industry to visualize performance profiles collected by stack-trace based profilers. In some cases, for example, during performance regression detection, profiles of different software versions have to be compared. Doing this manually using two or more flame graphs or textual profiles is tedious and error-prone. In this `Early Research Achievements'-track paper, we present our preliminary results on using differential flame graphs instead. Differential flame graphs visualize the differences between two performance profiles. In addition, we discuss which research fields we expect to benefit from using differential flame graphs. We have implemented our approach in an open source prototype called FLAMEGRAPHDIFF, which is available on GitHub. FLAMEGRAPHDIFF makes it easy to generate interactive differential flame graphs from two existing performance profiles. These graphs facilitate easy tracing of elements in the different graphs to ease the understanding of the (d)evolution of the performance of an application.",
        "author": "Bezemer, Cor-Paul and Pouwelse, Johan and Gregg, Brendan",
        "booktitle": "IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering",
        "doi": "10.1109/SANER.2015.7081872",
        "keywords": "type: research, context: software, subcontext: stack trace, subcontext: callgraph, name: flame graph, vis: icicle plot, parallel scale: 1+",
        "month": "mar,",
        "pages": "535--539",
        "series": "SANER",
        "title": "Understanding software performance regressions using differential flame graphs",
        "type": "InProceedings",
        "year": "2015"
    },
    "Bhatele2012": {
        "abstract": "Performance analysis of parallel scientific codes is becoming increasingly difficult due to the rapidly growing complexity of applications and architectures. Existing tools fall short in providing intuitive views that facilitate the process of performance debugging and tuning. In this paper, we extend recent ideas of projecting and visualizing performance data for faster, more intuitive analysis of applications. We collect detailed per-level and per-phase measurements for a dynamically load-balanced, structured AMR library and project per-core data collected in the hardware domain on to the application\u2019s communication topology. We show how our projections and visualizations lead to a rapid diagnosis of and mitigation strategy for a previously elusive scaling bottleneck in the library that is hard to detect using conventional tools. Our new insights have resulted in a 22\\% performance improvement for a 65,536-core run of the AMR library on an IBM Blue Gene/P system.",
        "acmid": "2389038",
        "address": "Los Alamitos, CA, USA",
        "articleno": "31",
        "author": "Bhatele, Abhinav and Gamblin, Todd and Isaacs, Katherine E. and Gunney, Brian T. N. and Schulz, Martin and Bremer, Peer-Timo and Hamann, Bernd",
        "booktitle": "Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis",
        "doi": "10.1109/SC.2012.80",
        "isbn": "978-1-4673-0804-5",
        "keywords": "type: research, context: tasks, subcontext: commgraph, vis: radial tree, vis: node-link, vis: aggregation, parallel scale: 10K",
        "location": "Salt Lake City, Utah",
        "numpages": "11",
        "pages": "31:1--31:11",
        "publisher": "IEEE Computer Society Press",
        "series": "SC",
        "title": "Novel Views of Performance Data to Analyze Large-scale Adaptive Applications",
        "type": "InProceedings",
        "year": "2012"
    },
    "Bhatele2016DragonView": {
        "abstract": "The dragonfly topology is a popular choice for building high-radix, low-diameter, hierarchical networks with high-bandwidth  links. On Cray installations of the dragonfly network, job placement policies and routing inefficiencies can lead to significant network congestion for a single job and multi-job workloads. In this paper, we explore the effects of job placement, parallel workloads and network configurations on network health to develop a better understanding of inter-job interference. We have developed a functional network simulator, Damselfly, to model the network behavior of Cray Cascade, and a visual analytics tool, DragonView, to analyze the simulation output. We simulate several parallel workloads based on five representative communication patterns on up to 131,072 cores. Our simulations and visualizations provide unique insight into the buildup of network congestion and present a trade-off between deployment dollar costs and performance of the network.",
        "author": "Bhatele, Abhinav and Jain, Nikhil and Livnat, Yarden and Pascucci, Valerio and Bremer, Peer-Timo",
        "booktitle": "Proceedings of the IEEE International Parallel \\& Distributed Processing Symposium",
        "keywords": "type: research, context: hardware, subcontext: network, subcontext: dragonfly, vis: radial, vis: edge-bundling, vis: adjacency matrix, vis: histograms, vis: filtering, name: DragonView, parallel scale: 1k",
        "month": "may,",
        "series": "IPDPS",
        "title": "Analyzing Network Health and Congestion in Dragonfly-based Supercomputers",
        "type": "inproceedings",
        "year": "2016"
    },
    "Blochinger2005": {
        "abstract": "An important task in parallel programming is the appropriate distribution of work on the processors. This distribution is usually dynamically changing and hard to predict, further it is very sensitive to the change of parameters. Even with advanced analysis tools this problem is hard to be solved. We propose to visualize the program structure as it changes over the execution time. We therefore present a new automatic layout algorithm based on Sugiyama\u2019s framework, which enables the user to detect structural patterns which might be fatal for the performance of the program - patterns which might be impossible to detect in a more analytical way. Furthermore it assists the user to find appropriate timing parameters for load balancing. We integrate our visualization into an integrated development environment that supports the implementation, execution, and analysis of parallel programs.",
        "acmid": "1056036",
        "address": "New York, NY, USA",
        "author": "Blochinger, Wolfgang and Kaufmann, Michael and Siebenhaller, Martin",
        "booktitle": "Proceedings of the 2005 ACM Symposium on Software Visualization",
        "doi": "10.1145/1056018.1056036",
        "isbn": "1-59593-073-6",
        "keywords": "type: research, name: DOTS, context: tasks, subcontext: trace, vis: node-link, vis: layered-layout, subcontext: threads, parallel scale: 10",
        "location": "St. Louis, Missouri",
        "numpages": "10",
        "pages": "125--134",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Visualizing Structural Properties of Irregular Parallel Computations",
        "type": "InProceedings",
        "year": "2005"
    },
    "Blochinger2006DOTS": {
        "abstract": "This paper deals with a visualization-based approach to performance analyzing and tuning of highly irregular task-parallel applications. At its core lies a novel automatic layout algorithm for execution graphs which is based on Sugiyama's framework. Our visualization enables the application designer to reliably detect manifestations of parallel overhead and to investigate on their individual root causes. We particularly focus on structural properties of task-parallel computations which are hard to detect in a more analytical way, for example, false sharing and false parallelism. In addition, we discuss embedding our visualization into an integrated development environment, realizing a seamless work-flow for implementation, execution, analysis, and tuning of parallel progams.",
        "author": "Blochinger, Wolfgang and Kaufmann, Michael and Siebenhaller, Martin",
        "doi": "10.1057/palgrave.ivs.9500123",
        "journal": "Information Visualization",
        "keywords": "type: research, name: DOTS, context: tasks, subcontext: trace, vis: node-link, vis: layered-layout, subcontext: threads, parallel scale: 10",
        "number": "2",
        "pages": "81-94",
        "title": "Visualization Aided Performance Tuning of Irregular Task-Parallel Computations",
        "type": "article",
        "volume": "5",
        "year": "2006"
    },
    "Bosch2000Rivet": {
        "abstract": "In this paper, we present an evolving system for the analysis and visualization of parallel application per- formance on shared memory multiprocessors. Our system couples SimOS, a complete machine simulator, with Rivet, a powerful visualization environment. This system demonstrates how visualization is necessary to realize the full power of simulation for performance analysis. We identify several features required of the visualization system, including flexibility, exploratory interaction techniques, and data aggregation schemes. We demonstrate the effectiveness of this parallel analysis and visualization system with a case study. We developed two visualizations within Rivet to study the Argus parallel rendering library, focusing on the memory system and process scheduling activity of Argus respectively. Using these visualizations, we uncovered several unexpected interactions between Argus and the underlying operating system. The results of the analysis led to changes that greatly improved its performance and scalability. Argus had previously been unable to scale beyond 26 processors; after analysis and modification, it achieved linear speedup up to 45 processors.",
        "author": "Bosch, Robert P. and Stolte, Christ and Stoll, Gordon and Rosenblum, Mendel and Hanrahan, Pat",
        "booktitle": "Proceedings of the Sixth International Symposium on High-Performance Computer Architecture",
        "doi": "10.1109/HPCA.2000.824365",
        "keywords": "type: research, name: Rivet, vis: visualization toolkit, context: software, context: tasks, vis: code, vis: timelines, vis: small multiples, parallel scale: 10",
        "pages": "360-371",
        "series": "HPCA",
        "title": "Performance analysis and visualization of parallel systems using SimOS and Rivet: a case study",
        "type": "InProceedings",
        "year": "2000"
    },
    "Bosch2001Thesis": {
        "author": "Bosch, Robert P.",
        "keywords": "type: thesis, name: Rivet, vis: visualization toolkit, name: SUIF Explorer, context: software, vis: code, name: Thor, context: hardware, subcontext: memory, vis: bar charts, vis: stacked bar charts, name: PipeCleaner, vis: timelines, vis: animation, name: The Visual Computer, vis: space-filling, vis: indented tree, vis: multiple views, vis: time series, context: tasks, subcontext: trace, parallel scale: 10",
        "publisher": "Stanford University",
        "title": "Using visualization to understand the behavior of computer systems",
        "type": "Book",
        "year": "2001"
    },
    "Brendel2016": {
        "abstract": "To fully exploit the potential of today\u2019s computers, application developers need to design for concurrency. Along with parallel execution new performance problems emerge. Developers gain insight into application behavior by visualizing inter-process communication in timelines. They use this insight to eliminate performance bottlenecks. Timeline visualizations overlay function call structure with communication information and additional performance data. In many cases such visualizations suffer from information overload and visual clutter that complicate analysis. We address these problems by introducing techniques inspired by hierarchical edge bundling into time-based communication visualization. Our visualization combines individual messages into dominant communication paths and thereby highlights higher-level structures. Furthermore, we introduce scalable visualizations for communication profiles, which offer an alternative view on communication patterns. This work employs edge bundling at unprecedented scale to address emerging problems in timeline displays.",
        "author": "Brendel, Ronny and Heyde, Michael and Brunst, Holger and Hilbrich, Tobias and Weber, Matthias",
        "booktitle": "Proceedings of the Third International Workshop on Visual Performance Analysis",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: edge bundling, vis: Gantt, vis: timelines",
        "pages": "1--8",
        "series": "VPA",
        "title": "Edge bundling for visualizing communication behavior",
        "type": "inproceedings",
        "year": "2016"
    },
    "Brinkmann2013Temanejo": {
        "abstract": "In recent years memory layouts have become more and more complex and bandwidth turned out to be the crucial performance parameter. This reflects in new programming paradigms which focus on data flow rather than instruction sequence. A very successful approach is StarSs, where the parallel programme consists of small computing units called tasks and dependencies between these tasks which are defined by the programmer. At runtime a dependency graph is created which determines the parallel or sequential execution of the tasks. When it comes to debugging StarSs applications, traditional debuggers such as gdb don\u2019t provide enough information and control to uncover shortcomings of the program. We present a new type of debugger which acts on the task level giving the user access to the dependency graph. Information is extracted from the running application with the lightweight library Ayudame and the information is passed to the remote client Temanejo which visualises the dependency graph and passes user requests, such as blocking or prioritising a task, to the application.",
        "author": "Brinkmann, Steffen and Gracia, Jos{\\'e} and Niethammer, Christoph",
        "booktitle": "Tools for High Performance Computing 2012",
        "keywords": "type: research, context: tasks, subcontext: task graph, subcontext: debugging, vis: node-link, vis: glyphs, name: Temanejo",
        "pages": "13--21",
        "publisher": "Springer",
        "title": "Task debugging with {Temanejo}",
        "type": "InCollection",
        "year": "2013"
    },
    "Broquedis2010hwloc": {
        "author": "Broquedis, Francois and Clet-Ortega, Jerome and Moreaud, Stephanie and Furmento, Nathalie and Goglin, Brice and Mercier, Guillaume and Thibault, Samuel and Namyst, Raymond",
        "booktitle": "Parallel, Distributed and Network-Based Processing (PDP), 2010 18th Euromicro International Conference on",
        "doi": "10.1109/PDP.2010.67",
        "issn": "1066-6192",
        "keywords": "type: research, name: hwloc, context: hardware, subcontext: node, subcontext: memory, vis: space-filling, parallel scale: 1+",
        "month": "Feb",
        "pages": "180-186",
        "title": "hwloc: A Generic Framework for Managing Hardware Affinities in HPC Applications",
        "type": "InProceedings",
        "year": "2010"
    },
    "Brown2015Boxfish": {
        "abstract": "As the scale of high-performance computing systems increases, optimizing inter-process communication becomes more challenging while being critical for ensuring good performance. However, the hardware layer abstraction provided by MPI makes it difficult to study application communication performance over the network hardware, especially for collective operations. We present a new approach to network performance analysis based on exposing low-level communication metrics in a flexible manner and conducting hardware-centric analysis of these metrics. We show how low-level network metrics can be revealed using Open MPI's Peruse utility, without interfacing with the hardware layer. A lightweight profiler, ibprof, was developed to aggregate these metrics from message passing events at a cost of <;1\\% runtime overhead for communication in NPB kernel and application benchmarks. We also developed a flexible visualization module for the Boxfish analysis tool to analyze our communication profile over the physical topology of the network. Using case studies, we demonstrate how our approach can identify communication anomalies in network applications and guide performance optimization strategies.",
        "author": "Brown, Kevin A. and Domke, Jens and Matsuoka, Satoshi",
        "booktitle": "Proceedings of the IEEE 21st International Conference on Parallel and Distributed Systems",
        "doi": "10.1109/ICPADS.2015.92",
        "keywords": "type: research, context: hardware, subcontext: network, name: boxfish, subcontext: fat tree, vis: node-link, name: Boxfish, parallel scale: 100",
        "pages": "692 -- 699",
        "series": "ICPADS",
        "title": "Hardware-Centric Analysis of Network Performance for MPI Applications",
        "type": "InProceedings",
        "year": "2015"
    },
    "Brunst2010Vampir": {
        "abstract": "Vampir 7 is a performance visualization tool that provides a comprehensive view on the runtime behavior of parallel programs. It is a new member of the Vampir tool family. This new generation of performance visualizer combines state-of-the-art parallel data processing techniques with an all-new graphical user interface experience. This includes fast local and remote event data browsing, searching, filtering, clustering, and summarization. The software is ported to Unix, Windows, and Apple platforms. This article gives an overview of the novel techniques and features of Vampir 7.",
        "author": "Brunst, Holger and Hackenberg, Daniel and Juckeland, Guido and Rohling, Heide",
        "booktitle": "Tools for High Performance Computing 2009",
        "doi": "10.1007/978-3-642-11261-4_2",
        "editor": "M\\\"uller, Matthias S. and Resch, Michael M. and Schulz, Alexander and Nagel, Wolfgang E.",
        "isbn": "978-3-642-11260-7",
        "keywords": "type: research, name: Vampir, context: tasks, subcontext: trace, vis: clustering, vis: Gantt, vis: timelines",
        "pages": "17-29",
        "publisher": "Springer Berlin Heidelberg",
        "title": "Comprehensive Performance Tracking with {Vampir 7}",
        "type": "InCollection",
        "url": "http://dx.doi.org/10.1007/978-3-642-11261-4_2",
        "year": "2010"
    },
    "Brunst2012Vampir": {
        "abstract": "The development and maintenance of scalable, state-of-the-art applications in High Performance Computing (HPC) is complex and error-prone. Today, performance debuggers and monitors are mandatory in the software development chain and well established. Like the applications, the tools themselves have to keep track of the developments in system and software engineering. Prominent developments in this regard are for example hybrid, accelerated, and energy aware computing. The ever increasing system complexity requires tools that can be adjusted and focused to user specific interests and questions. This article explains how the performance tool Vampir can be used to detect and highlight user-defined hot spots in HPC applications. This includes the customization and derivation of performance metrics, highly configurable performance data filters and a powerful comparison mode for multiple program runs. The latter allows to keep track of the performance improvements of an application during its evolution.",
        "author": "Brunst, Holger and Weber, Matthias",
        "booktitle": "Parallel Tools Workshop",
        "doi": "10.1007/978-3-642-37349-7_7",
        "keywords": "type: research, name: Vampir",
        "pages": "95-114",
        "title": "Custom Hot Spot Analysis of HPC Software with the Vampir Performance Tool Suite",
        "type": "InProceedings",
        "year": "2012"
    },
    "ChassindeKergommeaux2003": {
        "abstract": "Performance debugging of parallel and distributed applications can benefit from behavioral visualization tools helping to capture the dynamics of the executions of applications. The Paje generic tool presented in this article provides interactive and scalable behavioral visualizations; because of its genericity, it can be used unchanged in a large variety of contexts.",
        "author": "Chassin de Kergommeaux, Jacques and de Oliveira Stein, Benhur",
        "doi": "10.1016/S0167-739X(02)00181-4",
        "issn": "0167-739X",
        "journal": "Future Generation Computer Systems",
        "keywords": "type: research, name: Paje, context: tasks, subcontext: trace, subcontext: messages, vis: Gantt, vis: timelines, subcontext: threads, subcontext: semaphores, vis: pie charts",
        "note": "Tools for Program Development and Analysis. Best papers from two Technical Sessions, at ICCS2001, San Francisco, CA, USA, and ICCS2002, Amsterdam, The Netherlands",
        "number": "5",
        "pages": "735 - 747",
        "title": "Flexible performance visualization of parallel and distributed applications",
        "type": "article",
        "volume": "19",
        "year": "2003"
    },
    "Cheadle2006GCspy": {
        "abstract": "We present generic extensions to the GCspy visualisation frame-work that make it suitable for tracking the way continuous dynamic memory allocators such as dlmalloc or incremental and concurrent garbage collectors make use of heap memory. These extensions include sample-driven client-server communication, incremental stream updates and client-controlled stream update frequency. Additional extensions to the current GCspy client are also described. These include hierarchical driver grouping and hierarchical visualisation, zooming, and the ability to define and view relationships between tiles in different spaces. We also introduce a heuristics engine that is responsible for flipping GCspy from its de-coupled \u2018observation\u2019 mode to a synchronous \u2018single-step\u2019 mode, and describe a backtrace facility that can trace the server-side call sequence that led to the triggering of a specified event, such as the allocation or freeing of a block of memory. This enables aspects of the allocator (fragmentation, block ordering, splitting and coalescing policies, etc.) to be understood in the context of a particular application and potential optimisations to be identified. The effectiveness of the enhanced framework is demonstrated with a complete integration with dlmalloc. The framework is evaluated in terms of both performance and its ability to explore contrived modifications to dlmalloc\u2019s coalescing policy.",
        "acmid": "1133972",
        "address": "New York, NY, USA",
        "author": "Cheadle, A. M. and Field, A. J. and Ayres, J. W. and Dunn, N. and Hayden, R. A. and Nystrom-Persson, J.",
        "booktitle": "Proceedings of the 5th International Symposium on Memory Management",
        "doi": "10.1145/1133956.1133972",
        "isbn": "1-59593-221-6",
        "keywords": "type: research, name: GCspy, context: hardware, subcontext: memory, vis: 1D array, vis: indented tree, parallel scale: N/A",
        "location": "Ottawa, Ontario, Canada",
        "numpages": "11",
        "pages": "115--125",
        "publisher": "ACM",
        "series": "ISMM",
        "title": "Visualising Dynamic Memory Allocators",
        "type": "InProceedings",
        "year": "2006"
    },
    "Cheng2014TorusVisND": {
        "abstract": "Torus networks are widely used in supercomputing. However, due to their complex topology and their large number of nodes, it is difficult for analysts to perceive the messages flow in these networks. We propose a visualization framework called TorusVisND that uses modern information visualization techniques to allow analysts to see the network and its communication patterns in a single display and control the amount of information shown via filtering in the temporal and the topology domains. For this purpose we provide three cooperating visual interfaces. The main interface is the network display. It uses two alternate graph numbering schemes \u2013 a sequential curve and a Hilbert curve \u2013 to unravel the 5D torus network into a single string of nodes. We then arrange these nodes onto a circle and add the communication links as line bundles in the circle interior. A node selector based on parallel coordinates and a time slicer based on ThemeRiver help users focus on certain processor groups and time slices in the network display. We demonstrate our approach via a small use case.",
        "author": "Cheng, Shenghui and De, Pradipta and Jiang, Shaofeng H.-C. and Mueller, Klaus",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.7",
        "keywords": "type: research, context: hardware, subcontext: network, name: TorusVisND, subcontext: torus, subcontext: 5d torus, vis: theme river, vis: parallel coordinates, vis: radial, vis: multiple coordinated views, parallel scale: 1k",
        "month": "Nov",
        "pages": "9 -- 16",
        "series": "VPA",
        "title": "{TorusVisND}: Unraveling High-Dimensional Torus Networks for Network Traffic Visualizations",
        "type": "InProceedings",
        "year": "2014"
    },
    "Choudhury2008MTV": {
        "abstract": "We present the Memory Trace Visualizer (MTV), a tool that provides interactive visualization and analysis of the sequence of memory operations performed by a program as it runs. As improvements in processor performance continue to outpace improvements in memory performance, tools to understand memory access patterns are increasingly important for optimizing data intensive programs such as those found in scientific computing. Using visual representations of abstract data structures, a simulated cache, and animating memory operations, MTV can expose memory performance bottlenecks and guide programmers toward memory system optimization opportunities. Visualization of detailed memory operations provides a powerful and intuitive way to expose patterns and discover bottlenecks, and is an important addition to existing statistical performance measurements.",
        "author": "Choudhury, A.N.M. Imroz and Potter, Kristin C. and Parker, Steven G.",
        "doi": "10.1111/j.1467-8659.2008.01212.x",
        "journal": "Computer Graphics Forum",
        "keywords": "type: research, name: MTV, context: hardware, subcontext: memory, context: application, vis: animation, vis: 1D array, vis: matrix, parallel scale: N/A",
        "month": "May",
        "number": "3",
        "pages": "815--822",
        "series": "EuroVis",
        "title": "Interactive Visualization for Memory Reference Traces",
        "type": "Article",
        "volume": "27",
        "year": "2008"
    },
    "Choudhury2011": {
        "abstract": "We present a system for visualizing memory reference traces, the records of the memory transactions performed by a program at runtime. The visualization consists of a structured layout representing the levels of a cache and a set of data glyphs representing the pieces of data in memory being operated on during application runtime. The data glyphs move in response to events generated by a cache simulator, indicating their changing residency in the various levels of the memory hierarchy. Within the levels, the glyphs arrange themselves into higher-order shapes representing the structure of the cache levels, including the composition of their associative cache sets and eviction ordering. We make careful use of different visual channels, including structure, motion, color, and size, to convey salient events as they occur. Our abstract visualization provides a high-level, global view of memory behavior, while giving insight about important events that may help students or software engineers to better understand their software's performance and behavior.",
        "author": "Choudhury, A.N.M. Imroz and Rosen, Paul",
        "booktitle": "Proc. 6th IEEE Int. Workshop on Visualizing Software for Understanding and Analysis",
        "doi": "10.1109/VISSOF.2011.6069452",
        "keywords": "type: research, context: hardware, subcontext: memory, subcontext: trace, subcontext: memory trace, vis: radial, vis: glyphs, vis: animation, parallel scale: N/A",
        "series": "VISSOFT",
        "title": "Abstract visualization of runtime memory behavior",
        "type": "InProceedings",
        "year": "2011"
    },
    "Cornelissen2007ExTraVis": {
        "abstract": "The use of dynamic information to aid in software understanding is a common practice nowadays. One of the many approaches concerns the comprehension of execution traces. A major issue in this context is scalability: due to the vast amounts of information, it is a very difficult task to successfully find your way through such traces without getting lost. In this paper, we propose the use of a novel trace visualization method based on a massive sequence and circular bundle view, constructed with scalability in mind. By means of three usage scenarios that were conducted on three different software systems, we show how our approach, implemented in a tool called EXTRAVIS, is applicable to the areas of trace exploration, feature location, and feature comprehension.",
        "acmid": "1271346",
        "address": "Washington, DC, USA",
        "author": "Cornelissen, Bas and Holten, Danny and Zaidman, Andy and Moonen, Leon and van Wijk, Jarke J. and van Deursen, Arie",
        "booktitle": "Proceedings of the 15th IEEE International Conference on Program Comprehension",
        "doi": "10.1109/ICPC.2007.39",
        "isbn": "0-7695-2860-0",
        "keywords": "type: research, name: ExTraVis, context: software, subcontext: trace, subcontext: class hierarchy, vis: radial, vis: edge-bundling, vis: information mural, parallel scale: N/A",
        "numpages": "10",
        "pages": "49--58",
        "publisher": "IEEE Computer Society",
        "series": "ICPC",
        "title": "Understanding Execution Traces Using Massive Sequence and Circular Bundle Views",
        "type": "InProceedings",
        "year": "2007"
    },
    "Cottam2015": {
        "%    abstract": "Existing high-level, source-to-source compilers can %accept input programs in a high-level language (e.g., C) and %perform complex automatic parallelization and other mappings %using various optimizations. These optimizations often require %trade-offs and can benefit from the user\u2019s involvement in the %process. However, because of the inherent complexity, the barrier %to entry for new users of these high-level optimizing compilers can %often be high. We propose visualization as an effective gateway %for non-expert users to gain insight into the effects of parameter %choices and so aid them in the selection of levels best suited to %their specific optimization goals. % %A popular optimization paradigm is polyhedral mapping %which achieves optimization by loop transformations. We have %augmented a commercial polyhedral-model source-to-source %compiler (R-Stream) with an interactive visual tool we call the %Polyhedral User Mapping and Assistant Visualizer (PUMA-V). %PUMA-V is tightly integrated with the R-Stream source-to-source %compiler and allows users to explore the effects of difficult %mappings and express their goals to optimize trade-offs. It %implements advanced multivariate visualization paradigms such %as parallel coordinates and correlation graphs and applies them %in the novel setting of compiler optimizations. % %We believe that our tool allows programmers to better %understand complex program transformations and deviations %of mapping properties on well understood programs. This in %turn will achieve experience and performance portability across %programs architectures as well as expose new communities in the %computational sciences to the rich features of auto-parallelizing %high-level source-to-source compilers. Analysts commonly use execution traces collected at runtime to %    understand the behavior of applications running on parallel and %\tdistributed systems. These traces are inspected post mortem using %\tvarious visualization techniques that are generally incapable to scale %\tproperly for many events. This issue, mainly due to human perception %\tlimitations, is also the result of the screen size, which prevents the %\tproper drawing of many graphical objects. Several visualization %\ttechniques tackle these issues by reducing the representaton %\tcomplexity, using visual or data aggregation, or even clustering. %\tNevertheless, these solutions have drawbacks that hinder the analysis. %\tWe first evaluate existing trace visualization techniques using %\tdifferent criteria, involving how they are readable, their fidelity to %\trepresent the trace content without modifying its meaning, and so on. %\tThe objective is to determine which factors are responsible for the %\tissues mentioned above. Second, we show how the combination of several %\taggregation techniques, data and visual, through a coherent and %\tuniform treatment on spatial and temporal dimension, helps us to %\tfulfill better the different criteria. This example enable us to claim %\tthe necessity of formalizing an aggregation methodology to provide %\tdecent spatiotemporal trace overviews for performance analysis. False detection is a major issue in deploying and maintaining %\tNetwork-based Intrusion Detection Systems (NIDS). Traditionally, it is %\t    recommended to customize its signature database (DB) to reduce %\t    false detections. However, it requires quite deep knowledge and %\t    skills to appropriately customize the signature DB. Inappropriate %\t    customization causes the increase of false negatives as well as %\t    false positives. In this paper, we propose a visualization system %\t    of a NIDS log, named SnortView, which supports administrators in %\t    analyzing NIDS alerts much faster and much more easily. Instead of %\t    customizing the signature DB, we propose to utilize visualization %\t    to recognize not only each alert but also false detections. The %\t    system is based on a 2-D time diagram and alerts are shown as %\t    icons with different styles and colors. In addition, the system %\t    introduces some visuliazation techniques such as overlayed %\t    statistical information, source-destination matrix, and so on. The %\t    system was used to detect real attacks while recognizing some %\t    false detction.",
        "%    author": "Papenhausen, Eric and Wang, Bing and Langston, M. Harper and %\tBaskaran, Muthu and Henretty, Tom and Izubuchi, Taku and Johnson, Ann %\t    and Jung, Chulwoo and Lin, Meifeng and Meister, Benoit and %\t    Mueller, Klaus and Lethin, Richard Dosimont, Damien and Lamarche-Perrin, Robin and Schnorr, Lucas Mello %    and Huard, Guillaume and Vincent, Jean-Marc Koike, Hideki and Ohno, Kazuhiro",
        "%    booktitle": "Proceedings of the 3rd IEEE Working Conference on Software %\tVisualization Visual Performance Analysis, 1st Workshop on",
        "%    journal": "VizSEC/DMSEC",
        "%    keywords": "type: research, context: software, subcontext: compilers, %\tsubcontext: generalized dependence graph, %\tname: PUMA-V, name: R-Stream, vis: parallel coordinates, vis:  code, %\tvis: tree % %@InProceedings{LaToza2011,",
        "%    month": "sep, Nov",
        "%    series": "VISSOFT 2015",
        "%    title": "Polyhedral User Mapping and Assitant Visualizer Tool for the %\t{R-Stream} Auto-Parallelizing Compiler Combining Data and Visual Aggregation Techniques to Build a Coherent %    Spatiotemporal Overview {SnortView: Visualization System of Snort Logs}",
        "%    year": "2015 2014 2004",
        "%   keywords": "type:research, context:tasks, subcontext:trace, name:Ocelotl, %    aggregation, timelines, gantt, information theory, parallel scale:100 % %@InProceedings{Koike2014SnortView, type:research, context:software, subcontext:security, %\tname:SnortView %",
        "% abstract": "Developers navigate and reason about call graphs throughout %     investigation and debugging activities. This is often difficult: %\t developers can spend tens of minutes answering a single question, get %\t lost and disoriented, and erroneously make assumptions, causing bugs. %\t To address these problems, we designed a new form of interactive call %\t graph visualization - REACHER. Instead of leaving developers to %\t manually traverse the call graph, REACHER lets developers search %\t along control flow. The interactive call graph visualization encodes %\t a number of properties that help developers answer questions about %\t causality, ordering, type membership, repetition, choice, and other %\t relationships. And developers remain oriented while navigating. To %\t evaluate REACHER'S benefits, we conducted a lab study in which 12 %\t participants answered control flow questions. Compared to an existing %\t IDE, participants with REACHER were over 5 times more successful in %\t significantly less time. All enthusiastically preferred REACHER, with %\t many positive comments. Multi-core processors have become increasingly prevalent, driving %     a software shift toward concurrent programs which best utilize these %\t processors. Testing and debugging concurrent programs is difficult %\t due to the many different ways threads can interleave. One solution %\t to testing concurrent software is to use tools, such as NASA's Java %\t PathFinder (JPF), to explore the thread interleaving space. Although %\t tools such as JPF provide comprehensive data about program errors, %     the data is generally in the form of bulk text logs, which provide %     little %\t support for common analysis tasks, such as finding common and rare %\t error states. In this paper, we present an interactive visualization %\t tool, TIE, that integrates with JPF to enhance concurrency testing %\t and debugging.",
        "% acmid": "1879247",
        "% address": "New York, NY, USA",
        "% author": "LaToza, T.D. and Myers, B.A. Maheswara, Gowritharan and Bradbury, Jeremy S. and Collins, Christopher",
        "% booktitle": "Visual Languages and Human-Centric Computing (VL/HCC), 2011 IEEE Symposium on Proceedings of the 5th International Symposium on Software Visualization",
        "% doi": "10.1109/VLHCC.2011.6070388 10.1145/1879211.1879247",
        "% isbn": "978-1-4503-0028-5",
        "% issn": "1943-6092",
        "% keywords": "name:REACHER, context:software, subcontext:callgraph, debugging % %@InProceedings{Maheswara2010, debugging, threads % %@InProceedings{Dosimont2014Ocelotlc,",
        "% location": "Salt Lake City, Utah, USA",
        "% month": "Sept",
        "% numpages": "2",
        "% pages": "117-124 215--216",
        "% publisher": "ACM",
        "% series": "SOFTVIS '10",
        "% title": "Visualizing call graphs TIE: An Interactive Visualization of Thread Interleavings",
        "% url": "http://doi.acm.org/10.1145/1879211.1879247",
        "% year": "2011 2010",
        "abstract": "Visualization  schemas need  to be  enhanced  to support  next-generation  high-performance computing  (HPC)  environments. New HPC runtimes perform more actions in a unit of time, but they also perform a wider variety of actions. Existing schemas are too simple to illustrate the variety of information that HPC developers need. However, existing schemas can be extended in simple ways to become more effective for next-generation HPC environments.  This  paper  presents  extensions  to  the  common Vampir style plot that use high-definition alpha composition and color weaving. These two techniques incorporate new detail into the traditional plot style, providing useful information for HPC developers.",
        "author": "Cottam, Joseph and Martin, Ben and Dalessandro, Luke and Lumsdaine, Andrew",
        "booktitle": "Proceedings of the 3rd IEEE Working Conference on Software Visualization",
        "keywords": "type: research, context: tasks, subcontext: tasks, vis: HD alpha composition, vis: color weaving, vis: Gantt, vis: timelines",
        "month": "sep, % %@InProceedings{Papenhausen2015PUMA-V,",
        "series": "VISSOFT",
        "title": "Pixel-Oriented Techniques for Visualizing Next-Generation HPC Systems",
        "type": "InProceedings",
        "year": "2015"
    },
    "Couch1993Seeplex": {
        "abstract": "To understand the behavior of processors in a large-scale asynchronous execution, we must often consider the global execution context in which each processor is immersed. Global context is best described by scalable execution views that do not change in format, size, meaning, or clarity as processors are added to an execution. One way to produce a scalable view is to categorize processors by behavior and display category statistics. Categorical views are particularly useful when there is an inverse mapping from an arbitrary view region to the subset of processors whose behavior was described in the region. Then the user can define new categories graphically by specifying subregions of views, using graphical attributes such as color and texture to depict category membership. The execution visualization tool Seeplex implements this form of category management to provide scalable execution views.",
        "author": "Alva L. Couch",
        "doi": "\"10.1006/jpdc.1993.1056\",",
        "issn": "\"0743-7315\",",
        "journal": "Journal of Parallel and Distributed Computing",
        "keywords": "type: research, name: Seeplex, context: tasks, vis: scatterplots, vis: multiple coordinated views, vis: filtering, parallel scale: 1+",
        "note": "\"\",",
        "number": "\"2\",",
        "pages": "\"195 - 204\",",
        "series": "JPDC",
        "title": "\"Categories and Context in Scalable Execution Visualization \",",
        "type": "article",
        "volume": "\"18\",",
        "year": "\"1993\","
    },
    "Cuny1992": {
        "abstract": "Visualization tools that display data as it is manipulated by a parallel, MIMD computation must contend with the effects of asynchronous execution. We have developed techniques that manipulate logical time in order to produce coherent animations of par- allel program behavior despite the presence of asynchrony. Our techniques \u201cinterpret\u201d program behavior in light of user-defined abstractions and generate animations based on a logical rather than a physical view of time. If this interpretation succeeds, the resulting animation is easily understood; if it fails, the programmer can be assured that the failure was not an artifact of the visualization. Here we demonstrate that these techniques can be generally applied to enhance visual- izations of a variety of types of dataasit is produced by parallel, MIMD computations.",
        "author": "Cuny, Janice E. and Hough, Alfred A. and Kundu, Joydip",
        "booktitle": "Proceedings of the IEEE Conference on Visualization",
        "doi": "10.1109/VISUAL.1992.235209",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: animation, vis: logical time, vis: node-link, parallel scale: 1+",
        "pages": "186-193",
        "series": "VIS",
        "title": "Logical time in visualizations produced by parallel programs",
        "type": "InProceedings",
        "year": "1992"
    },
    "Cuny1993": {
        "acmid": "174276",
        "author": "Cuny, Janice E. and Forman, George and Hough, Alfred A. and Kundu, Joydip and Lin, Calvin and Snyder, Lawrence and Stemple, David",
        "booktitle": "Proceedings of the 1993 ACM/ONR Workshop on Parallel and Distributed Debugging",
        "doi": "10.1145/174266.174276",
        "isbn": "0-89791-633-6",
        "keywords": "type: research, name: Ariadne, context: tasks, subcontext: trace, vis: logical time, vis: animation, vis: node-link",
        "numpages": "11",
        "pages": "85--95",
        "publisher": "ACM",
        "series": "PADD",
        "title": "The {Ariadne} Debugger: Scalable Application of Event-based Abstraction",
        "type": "InProceedings",
        "year": "1993"
    },
    "DePauw2009StreamSight": {
        "abstract": "Stream processing is a new and important computing paradigm. Innovative streaming applications are being developed in areas ranging from scientific applications (for example, environment monitoring), to business intelligence (for example, fraud detection and trend analysis), to financial markets (for example, algorithmic trading systems). In this paper we describe Streamsight, a new visualization tool built to examine, monitor and help understand the dynamic behavior of streaming applications. Streamsight can handle the complex, distributed and large-scale nature of stream processing applications by using hierarchical graphs, multi-perspective visualizations, and de-cluttering strategies. To address the dynamic and adaptive nature of these applications, Streamsight also provides real-time visualization as well as the capability to record and replay. All these features are used for debugging, for performance optimization, and for management of resources, including capacity planning. More than 100 developers, both inside and outside IBM, have been using Streamsight to help design and implement large-scale stream processing applications.",
        "author": "De Pauw, Wim and Andrade, Henrique",
        "doi": "10.1057/ivs.2009.5",
        "journal": "Information Visualization",
        "keywords": "type: research, name: StreamSight, context: tasks, subcontext: trace, vis: node-link, vis: animation, subcontext: streaming, parallel scale: 1K",
        "number": "2",
        "pages": "87-106",
        "title": "Visualizing Large-Scale Streaming Applications",
        "type": "article",
        "volume": "8",
        "year": "2009"
    },
    "DePauw2010Zinsight": {
        "abstract": "Information in event traces from software systems can help developers with performance analysis, debugging and troubleshooting. However, the volume of data contained in these traces can make such tasks a challenge. In this paper we propose a new tool, Zinsight, to visualize event traces from complex systems. Our contribution is a novel combination of visualizations and pattern extraction techniques, enabling user exploration, analysis and understanding of traces containing millions of events. Three complimentary views help the user answer different questions. First, the Event Flow view shows the trace in its entirety or in detail. The user sees visual patterns representing phases of processing and the relative order of events. Second, the Event Statistics view quantifies events, and presents distributions and averages enabling the user to identify outlier behavior. Third, the Sequence Context view extracts patterns of interest from the trace and represents them along with frequency and performance data in succinct execution flow diagrams. The user can navigate from patterns to their constituent instance sequences and even back to individual events in the other views. Questions can be answered and hypotheses tested using the most natural view for the task.",
        "acmid": "1879233",
        "address": "New York, NY, USA",
        "author": "De Pauw, Wim and Heisig, Steve",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879233",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, name: Zinsight, context: software, context: tasks, subcontext: trace, vis: node-link, vis: indented, vis: timelines, parallel scale: 100",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "143--152",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Zinsight: A Visual and Analytic Environment for Exploring Large Event Traces",
        "type": "InProceedings",
        "year": "2010"
    },
    "DePauw2013VISSOFT": {
        "abstract": "In this paper we describe a visualization system that shows the behavior of jobs in large, distributed computing clusters. The system has been in use for two years, and is sufficiently generic to be applied in two quite different domains: a Hadoop MapReduce environment and the Watson DeepQA DUCC cluster. Scalable and flexible data processing systems typically run hundreds or more of simultaneous jobs. The creation, termination, expansion and contraction of these jobs can be very dynamic and transient, and it is difficult to understand this behavior without showing its evolution over time. While traditional monitoring tools typically show either snapshots of the current load balancing or aggregate trends over time, our new visualization technique shows the behavior of each of the jobs over time in the context of the cluster, and in either a real-time or post-mortem view. Its new algorithm runs in real- time mode and can make retroactive adjustments to produce smooth layouts. Moreover, our system allows users to drill down to see details about individual jobs. The visualization has been proven useful for administrators to see the overall occupancy, trends and job allocations in the cluster, and for users to spot errors or to monitor how many resources are given to their jobs.",
        "author": "De Pauw, Wim and Wolf, Joel L. and Balmin, Andrey",
        "booktitle": "VISSOFT",
        "crossref": "DBLP:conf/vissoft/2013",
        "doi": "10.1109/VISSOFT.2013.6650535",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: timelines, parallel scale: 1K",
        "pages": "1-10",
        "series": "VISSOFT",
        "title": "Visualizing jobs with shared resources in distributed environments",
        "type": "InProceedings",
        "year": "2013"
    },
    "DeRose2007": {
        "abstract": "Scientific applications should be well balanced in order to achieve high scalability on current and future high end massively parallel systems. However, the identification of sources of load imbalance in such applications is not a trivial exercise, and the current state of the art in performance analysis tools do not provide an efficient mechanism to help users to identify the main areas of load imbalance in an application. In this paper we discuss a new set of metrics that we defined to identify and measure application load imbalance. We then describe the extensions that were made to the Cray performance measurement and analysis infrastructure to detect application load imbalance and present to the user in an insightful way.",
        "author": "DeRose, Luiz and Homer, Bill and Johnson, Dean",
        "booktitle": "Euro-Par",
        "date": "2007-08-30",
        "doi": "10.1007/978-3-540-74466-5_17",
        "editor": "Kermarrec, Anne-Marie and Boug\\'e, Luc and Priol, Thierry",
        "isbn": "978-3-540-74465-8",
        "keywords": "type: research, context: software, subcontext: callgraph, vis: node-link, subcontext: load-balancing, parallel scale: 100",
        "pages": "150--159",
        "publisher": "Springer",
        "series": "Lecture Notes in Computer Science",
        "title": "Detecting Application Load Imbalance on High End Massively Parallel Systems.",
        "type": "InProceedings",
        "volume": "4641,",
        "year": "2007,"
    },
    "Devaux2014DataTube": {
        "abstract": "In this paper we study a 3D tubular visualization of software activity log data, with the aim of supporting multi- threaded software development and debugging. We consider an existing visualization called Datatube2 that has already been used to help various domain experts in the analysis of large amounts of time-dependent data. Since software logs are also time series, DataTube2 has been enhanced to support the specific data and tasks that are currently found in debugging, yielding to a specific visualization that we called DataTube4log. In this visualization, each line in the tube is devoted to the activity of a thread. Dependencies between threads are materialized with arrows. Synchronization objects are also represented. Using a real dataset, we show how a domain expert has solved a debugging problem. In this experiment, we found that DataTube4log can be easily learned and adopted, and that the ability of the tube to efficiently render an overview of large time series was beneficial to the software engineer.",
        "author": "Devaux, S. and Bouali, F. and Venturini, G.",
        "booktitle": "2014 18th International Conference on Information Visualisation",
        "doi": "10.1109/IV.2014.73",
        "issn": "1550-6037",
        "keywords": "type: research, context: tasks, subcontext: trace, name: DataTube, subcontext: debugging, vis: 3d, subcontext: threads, vis: timelines, parallel scale: 10",
        "month": "July",
        "pages": "189-195",
        "series": "IV",
        "title": "DataTube4log: A Visual Tool for Mining Multi-threaded Software Logs",
        "type": "InProceedings",
        "year": "2014"
    },
    "Dosimont2014Ocelotlb": {
        "abstract": "Analysts commonly use execution traces collected at runtime to understand the behavior of an application running on distributed and parallel systems. These traces are inspected post mortem using various visualization techniques that, however, do not scale properly for a large number of events. This issue, mainly due to human perception limitations, is also the result of bounded screen resolutions preventing the proper drawing of many graphical objects. This paper proposes a new visualization technique overcoming such limitations by providing a concise overview of the trace behavior as the result of a spatiotemporal data aggregation process. The experimental results show that this approach can help the quick and accurate detection of anomalies in traces containing up to two hundred million events.",
        "author": "Dosimont, Damien and Lamarche-Perrin, Robin and Schnorr, Lucas Mello and Huard, Guillaume and Vincent, Jean-Marc",
        "booktitle": "2014 IEEE International Conference on Cluster Computing",
        "keywords": "type: research, context: tasks, subcontext: trace, name: Ocelotl, vis: aggregation, vis: timelines, vis: gantt, vis: information theory, parallel scale: 1k",
        "month": "Sept",
        "series": "CLUSTER",
        "title": "A Spatiotemporal Data Aggregation Technique for Performance Analysis of Large-scale Execution Traces",
        "type": "InProceedings",
        "year": "2014"
    },
    "Drebes2014": {
        "abstract": "We present Aftermath, an open source graphical tool designed to assist in the performance debugging process of task-parallel programs by visualizing, filtering and analyzing execution traces interactively. To efficiently exploit increasingly complex and conc urrent hardware architectures, both the application and the run-time s ystem that manages task execution must be highly optimized. However, detecting performance anomalies is challenging as bottlenecks can arise directly from the application, the run-time or interaction with the hardware. In Aftermath, key metrics and indicators, such as task duration, state information, hardware performance counter values and data ex changes can be visualized jointly, aggregated and related to the machine\u2019s topology.  The tool supports traces of up to several gigabytes, with fast and intuitive navigation and on-line generation of new derived me trics. As it has proven invaluable to optimize both OpenStream\u2019s run-time and applications, we illustrate Aftermath on genuine cases encountered in the OpenStream project.",
        "author": "Drebes, Andi and Pop, Antoniu and Heydemann, Karine and Cohen, Albert and Drach-Temam, Nathalie",
        "journal": "Proceedings of the 7th Workshop on Programmability Issues for Heterogeneous Multicores",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: gantt, vis: timelines, name: aftermath",
        "series": "MULTIPROG",
        "title": "{Aftermath}: A graphical tool for performance analysis and debugging of fine-grained task-parallel programs and run-time systems",
        "type": "InProceedings",
        "year": "2014"
    },
    "Eick1992SeeSoft": {
        "abstract": "A visualization technique that makes it possible to display and analyze line count profile data is described. The technique is to make a reduced picture of code with the line execution counts identified with color. Hot spots are shown in red, warm spots in orange, and so on. It is possible to identify nonexecuted code and nonexecutable code such as declarations and static tables",
        "acmid": "949724",
        "address": "Los Alamitos, CA, USA",
        "author": "Eick, Stephen G. and Steffen, Joseph L.",
        "booktitle": "Proceedings of the 3rd Conference on Visualization '92",
        "doi": "10.1109/VISUAL.1992.235206",
        "isbn": "0-8186-2896-0",
        "keywords": "type: research, name: SeeSoft, context: software, subcontext: code, subcontext: performance, vis: pixels, vis: seesoft, parallel scale: N/A",
        "location": "Boston, Massachusetts",
        "numpages": "8",
        "pages": "210--217",
        "publisher": "IEEE Computer Society Press",
        "series": "VIS",
        "title": "Visualizing Code Profiling Line Oriented Statistics",
        "type": "InProceedings",
        "year": "1992"
    },
    "Eick1996SeeLog": {
        "abstract": "Computers generate trace files containing reports on system performance, status and faults. To analyze these trace files more efficiently, we have developed a graphical technique embodied in an interactive system for displaying large trace files. Our system uses abstraction, color, aggregation, filtering, interaction, and a drill-down capability to find patterns among the reports. We apply our system and technique to analyze command accounting trace files from a Unix compute server, showing what commands were executed, by which users, when, and how long the commands ran. We identify resource intensive commands, sequences of commands initiated by a compilations, and commands run with super-user permissions.",
        "author": "Eick, Stephen G. and Lucas, Paul J.",
        "doi": "10.1002/(SICI)1097-024X(199604)26:4<399::AID-SPE8>3.0.CO;2-J",
        "issn": "1097-024X",
        "journal": "Software: Practice and Experience",
        "keywords": "type: research, name: SeeLog, context: tasks, subcontext: trace, vis: timelines, vis: glyphs, parallel scale: N/A",
        "number": "4",
        "pages": "399--409",
        "publisher": "John Wiley & Sons, Ltd.",
        "series": "Wiley",
        "title": "Displaying Trace Files",
        "type": "article",
        "volume": "26",
        "year": "1996"
    },
    "Elmqvist2003GrowingSquares": {
        "abstract": "We present a novel information visualization technique for the graphical representation of causal relations, that is based on the metaphor of color pools spreading over time on a piece of paper. Messages between processes in the system affect the colors of their respective pool, making it possible to quickly see the influences each process has received. This technique, called Growing Squares, has been evaluated in a comparative user study and shown to be significantly faster and more efficient for sparse data sets than the traditional Hasse diagram visualization. Growing Squares were also more efficient for large data sets, but not significantly so. Test subjects clearly favored Growing Squares over old methods, naming the new technique easier, more efficient, and much more enjoyable to use.",
        "acmid": "774836",
        "address": "New York, NY, USA",
        "author": "Elmqvist, Niklas and Tsigas, Philippas",
        "booktitle": "Proceedings of the 2003 ACM Symposium on Software Visualization",
        "doi": "10.1145/774833.774836",
        "isbn": "1-58113-642-0",
        "keywords": "type: research ,name: Growing Squares, context: tasks, subcontext: trace, vis: logical time, vis: animation, vis: 3D, parallel scale: 10",
        "location": "San Diego, California",
        "pages": "17--ff",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Growing Squares: Animated Visualization of Causal Relations",
        "type": "InProceedings",
        "year": "2003"
    },
    "EzzatiJivan2014": {
        "abstract": "One solution to handle large data sets is to organize and visualize them in a hierarchical model. This paper investigates hierarchical management of large trace logs and proposes an interactive zoomable timeline view to visualize the multiple levels of information generated by analyzing the ex- ecution trace logs. The view supports both the semantic (data) zooming and physical (visual) zooming. It displays a coarser layer first and provides some operations to explore and navigate the different layers of data. The method mainly facilitates the comprehension of the execution trace logs and can also be used to improve root cause analysis. The paper also discusses the hierarchical data model designed for organizing and visualizing the information at multiple levels.",
        "author": "Ezzati-Jivan, Naser and Dagenais, Michel R.",
        "booktitle": "2014 IEEE 27th Canadian Conferece on Electrical and Computer Engineering",
        "doi": "10.1109/CCECE.2014.6901019",
        "keywords": "type: research, context: software, subcontext: trace, vis: 1d array, vis: semantic zoom, vis: timelines, parallel scale: n/a",
        "month": "May",
        "pages": "1-7",
        "series": "CCECE",
        "title": "Multiscale navigation in large trace data",
        "type": "InProceedings",
        "year": "2014"
    },
    "EzzatiJivan2017Survey": {
        "abstract": "Dynamic analysis through execution traces is frequently used to analyze the runtime behavior of software systems. However, tracing long running executions generates voluminous data, which are complicated to analyze and manage. Extracting interesting performance or correctness characteristics out of large traces of data from several processes and threads is a challenging task. Trace abstraction and visualization are potential solutions to alleviate this challenge. Several efforts have been made over the years in many subfields of computer science for trace data collection, maintenance, analysis, and visualization. Many analyses start with an inspection of an overview of the trace, before digging deeper and studying more focused and detailed data. These techniques are common and well supported in geographical information systems, automatically adjusting the level of details depending on the scale. However, most trace visualization tools operate at a single level of representation, which are not adequate to support multilevel analysis. Sophisticated techniques and heuristics are needed to address this problem. Multi-scale (multi-level) visualization with support for zoom and focus operations is an effective way to enable this kind of analysis. Considerable research and several surveys are proposed in the literature in the field of trace visualization. However, multi-scale visualization has yet received little attention. In this paper, we provide a survey and methodological structure for categorizing tools and techniques aiming at multi-scale abstraction and visualization of execution trace data and discuss the requirements and challenges faced to be able to meet evolving user demands.",
        "author": "Ezzati-Jivan, Naser and Dagenais, Michel R",
        "doi": "10.1002/cpe.4068",
        "journal": "Concurrency and Computation: Practice and Experience",
        "keywords": "type: survey, context: n/a, subcontext: trace, parallel scale: n/a, vis: timelines, vis: Gantt, name: n/a",
        "number": "10",
        "publisher": "Wiley Online Library",
        "series": "Wiley",
        "title": "Multi-scale navigation of large trace data: A survey",
        "type": "article",
        "volume": "29",
        "year": "2017"
    },
    "Fowler1989Moviola": {
        "author": "Fowler, Robert J. and Bella, Ivan",
        "institution": "DTIC Document",
        "keywords": "type: research, name: Moviola, context: tasks, subcontext: trace, vis: timelines, vis: Gantt, subcontext: messages, parallel scale: 10",
        "title": "The programmer's guide to Moviola: An interactive execution history browser",
        "type": "TechReport",
        "year": "1989"
    },
    "Francioni1991": {
        "abstract": "Portraying the behavior of parallel programs can be done in a variety of ways. One way is to generate a graphical display related to the program\u2019s behavior so that a user can visualize what happens during the program\u2019s execution. As an alternative to visualization, auralization can also be used to portray the behavior of parallel programs. This paper explores how sound can be used to depict different events that take place during a parallel program\u2019s execution. In particular, the discussion is focused on dis@ibuted- memory parallel programs. Three mappings of execution behavior to sound were studied. The first mapping is related to process communication in a distributed-memory parallel program. The second mapping tracks the load balance of the processors of a system, In the third mapping, the flows-of-control of the parallel processes are mapped to related sounds.",
        "acmid": "122765",
        "author": "Francioni, Joan M. and Albright, Larry and Jackson, Jay Alan",
        "doi": "10.1145/127695.122765",
        "journal": "SIGPLAN Notes",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: sonification, parallel scale: 1+",
        "month": "dec,",
        "number": "12",
        "numpages": "8",
        "pages": "68--75",
        "publisher": "ACM",
        "seires": "SIGPLAN Notes",
        "title": "Debugging Parallel Programs Using Sound",
        "type": "article",
        "volume": "26",
        "year": "1991"
    },
    "Frishman2005": {
        "abstract": "This paper presents a system for visualizing mobile object frameworks. In such frameworks, the objects can migrate to remote hosts, along with their state and behavior, while the application is running. An innovative graph-based visualization is used to depict the physical and the logical connections in the distributed object network. Scalability is achieved by using a focus+context technique jointly with a user-steered clustering algorithm. In addition, an event synchronization model for mobile objects is presented. The system has been applied to visualizing several mobile object applications.",
        "acmid": "1056038",
        "address": "New York, NY, USA",
        "author": "Frishman, Yaniv and Tal, Ayellet",
        "booktitle": "Proceedings of the 2005 ACM Symposium on Software Visualization",
        "doi": "10.1145/1056018.1056038",
        "isbn": "1-59593-073-6",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: animation, subcontext: migratable objects, vis: nested graphs, vis: aggregation, vis: distortion, parallel scale: 10",
        "location": "St. Louis, Missouri",
        "numpages": "10",
        "pages": "145--154",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Visualization of Mobile Object Environments",
        "type": "InProceedings",
        "year": "2005"
    },
    "Gao2011Survey": {
        "abstract": "Recently the need for extreme scale computing solutions presents demands for powerful and easy to use performance visualization tools. This paper presents a review of existing research on performance visualization for large-scale systems. A general approach to performance visualization is introduced in relation to performance analysis, and issues that need to be addressed throughout the performance visualization process are summarized. Then visualization techniques from 21 performance visualization systems are reviewed and discussed, with the hope of shedding light on the design of visualization tools for ultra-large systems.",
        "author": "Gao, Qin and Zhang, Xuhui and Rau, Pei-Luen Patrick and Maciejewski, Anthony A. and Siegel, Howard Jay",
        "booktitle": "Human-Computer Interaction. Design and Development Approaches",
        "doi": "10.1007/978-3-642-21602-2_49",
        "editor": "Jacko, JulieA.",
        "isbn": "978-3-642-21601-5",
        "keywords": "type: survey, context: n/a, subcontext: n/a, vis: n/a, parallel scale: n/a, name: n/a",
        "pages": "450-460",
        "publisher": "Springer Berlin Heidelberg",
        "series": "Lecture Notes in Computer Science",
        "title": "Performance Visualization for Large-Scale Computing subcontext:A Literature Review",
        "type": "InCollection",
        "volume": "6761",
        "year": "2011"
    },
    "Geimer2010Scalasca": {
        "abstract": "Scalasca is a performance toolset that has been specifically designed to analyze parallel application execution behavior on large-scale systems with many thousands of processors. It offers an incremental performance-analysis procedure that integrates runtime summaries with in-depth studies of concurrent behavior via event tracing, adopting a strategy of successively refined measurement configurations. Distinctive features are its ability to identify wait states in applications with very large numbers of processes and to combine these with efficiently summarized local measurements. In this article, we review the current toolset architecture, emphasizing its scalable design and the role of the different components in transforming raw measurement data into knowledge of application execution behavior. The scalability and effectiveness of Scalasca are then surveyed from experience measuring and analyzing real-world applications on a range of computer systems.",
        "acmid": "1753234",
        "address": "Chichester, UK",
        "author": "Geimer, Markus and Wolf, Felix and Wylie, Brian J. N. and \\'{A}brah\\'{a}m, Erika and Becker, Daniel and Mohr, Bernd",
        "doi": "10.1002/cpe.v22:6",
        "issn": "1532-0626",
        "issue_date": "April 2010",
        "journal": "Concurr. Comput. : Pract. Exper.",
        "keywords": "type: research, name: Scalasca, context: software, context: application, subcontext: callgraph, vis: indented tree, vis: mesh, vis: multiple views, parallel scale: 100K",
        "month": "apr,",
        "number": "6",
        "numpages": "18",
        "pages": "702--719",
        "publisher": "John Wiley and Sons Ltd.",
        "series": "Wiley",
        "title": "The {Scalasca} Performance Toolset Architecture",
        "type": "article",
        "volume": "22",
        "year": "2010"
    },
    "George2010ConcurrencyVisualizer": {
        "author": "George, Boby and Nagpal, Pooja",
        "keywords": "type: research, name: Concurrency Visualizer, context: tasks, subcontext: trace, subcontext: threads, vis: timelines",
        "title": "Optimizing Parallel Applications Using Concurrency Visualizer: A Case Study",
        "type": "TechReport",
        "year": "2010"
    },
    "Gimenez2014MemAxes": {
        "abstract": "Optimizing memory access is critical for performance and power efficiency. CPU manufacturers have developed sampling-based performance measurement units (PMUs) that report precise costs of memory accesses at specific addresses. However, this data is too low-level to be meaningfully interpreted and contains an excessive amount of irrelevant or uninteresting information. We have developed a method to gather fine-grained memory access performance data for specific data objects and regions of code with low overhead and attribute semantic information to the sampled memory accesses. This information provides the context necessary to more effectively interpret the data. We have developed a tool that performs this sampling and attribution and used the tool to discover and diagnose performance problems in real-world applications. Our techniques provide useful insight into the memory behavior of applications and allow programmers to understand the performance ramifications of key design decisions: domain decomposition, multi-threading, and data motion within distributed memory systems.",
        "author": "Gim\\'enez, Alfredo and Gamblin, Todd and Rountree, Barry and Bhatele, Abhinav and Jusufi, Ilir and Bremer, Peer-Timo and Hamann, Bernd",
        "booktitle": "International Conference for High Performance Computing, Networking, Storage and Analysis, SC '13",
        "keywords": "type: research, context: hardware, context: application, subcontext: memory, name: MemAxes, parallel scale: 1+, vis: parallel coordinates, vis: radial, vis: multiple coordinated views",
        "month": "Nov",
        "series": "SC",
        "title": "Dissecting On-Node Memory Access Performance: A Semantic Approach",
        "type": "InProceedings",
        "year": "2014"
    },
    "Greevy2006": {
        "abstract": "The analysis of the runtime behavior of a software system yields vast amounts of information, making accurate interpretations difficult. Filtering or compression techniques are often applied to reduce the volume of data without loss of key information vital for a specific analysis goal. Alternatively, visualization is generally accepted as a means of effectively representing large amounts of data. The challenge lies in creating effective and expressive visual representations that not only allows for a global picture, but also enables us to inspect the details of the large data sets. We define the focus of our analysis to be the runtime behavior of features. Static structural visualizations of a system are typically represented in two dimensions. We exploit a third dimension to visually represent the dynamic information, namely object instantiations and message sends. We introduce a novel 3D visualization technique that supports animation of feature behavior and integrates zooming, panning, rotating and on-demand details. As proof of concept, we apply our visualization technique to feature execution traces of an example system.",
        "acmid": "1148501",
        "author": "Greevy, Orla and Lanza, Michele and Wysseier, Christoph",
        "booktitle": "Proceedings of the 2006 ACM Symposium on Software Visualization",
        "doi": "10.1145/1148493.1148501",
        "isbn": "1-59593-464-2",
        "keywords": "type: research, context: software, subcontext: trace, vis: 3D, vis: node-link, vis: indented tree, parallel scale: N/A, subcontext: class hierarchy",
        "location": "Brighton, United Kingdom",
        "numpages": "10",
        "pages": "47--56",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Visualizing Live Software Systems in 3D",
        "type": "InProceedings",
        "year": "2006"
    },
    "Griswold1989": {
        "author": "Griswold, Ralph E. and Townsend, Gregg M.",
        "institution": "Department of Computer Science. University of Arizona",
        "keywords": "type: research, context: hardware, subcontext: memory, vis: 1D array, parallel scale: N/A",
        "month": "December",
        "number": "TR 89-30",
        "title": "The Visualization of Dynamic Memory Management in the Icon Programming Language",
        "type": "TechReport",
        "year": "1989"
    },
    "Gu1995Falcon": {
        "abstract": "Falcon is a system for online monitoring and steering of large-scale parallel progmms. The purpose of such progmm steering i sto improve the application\u2019s performance or to affect its execution behavior. Thispaper presents the framework of the Falcon system and its implementation, and then evaluates the performance of the system. A complex sample application, a molecular dynamics simulation program (MD), is used to motivate the research as well os to measure the performance of the Falcon system.",
        "author": "Gu, Weiming and Eisenhauer, Greg and Kraemer, Eileen and Schwan, Karsten and Stasko, John T. and Vetter, Jeffrey and Mallavarupu, Nirupama",
        "booktitle": "Proceedings of the Fifth Symposium on the Frontiers of Massively Paralle Computation",
        "doi": "10.1109/FMPC.1995.380483",
        "keywords": "type: research,name: Falcon, context: tasks, subcontext: trace, vis: timelines, vis: Gantt, subcontext: threads",
        "pages": "422-429",
        "series": "Frontiers",
        "title": "Falcon: on-line monitoring and steering of large-scale parallel programs",
        "type": "InProceedings",
        "year": "1995"
    },
    "Hahn2015ThreadCity": {
        "author": "Hahn, Sebastian and Trapp, Matthias and Wuttke, Nikolai and D\\\"{o}llner, J\\\"{u}rgen",
        "booktitle": "19th International Conference on Information Visualisation",
        "doi": "10.1109/iV.2015.28",
        "keywords": "type: research, context: software, subcontext: trace, vis: city metaphor, name: ThreadCity, vis: 2d, subcontext: threads, vis: aggregation, vis: pie charts, vis: scatterplots, vis: icicle plot",
        "month": "July",
        "pages": "101-106",
        "series": "IV",
        "title": "Thread City: Combined Visualization of Structure and Activity for the Exploration of Multi-threaded Software Systems",
        "type": "InProceedings",
        "year": "2015"
    },
    "HamouLhadj2004": {
        "abstract": "The analysis of large execution traces is almost impossible without efficient tool support. Lately, there has been an increase in the number of tools for analyzing traces generated from object-oriented systems. This interest has been driven by the fact that polymorphism and dynamic binding pose serious limitations to static analysis. However, most of the techniques supported by existing tools are found in the context of very specific visualization schemes, which makes them hard to reuse. It is also very common to have two different tools implement the same techniques using different terminology. This appears to result from the absence of a common framework for trace analysis ap- proaches. This paper presents the state of the art in the area of trace analysis. We do this by analyzing the techniques that are supported by eight trace exploration tools. We also discuss their advantages and limitations and how they can be improved.",
        "acmid": "1034918",
        "author": "Hamou-Lhadj, Abdelwahab and Lethbridge, Timothy C.",
        "booktitle": "Proceedings of the 2004 Conference of the Centre for Advanced Studies on Collaborative Research",
        "keywords": "type: survey, vis: n/a, subcontext: n/a, name: n/a, context: n/a",
        "location": "Markham, Ontario, Canada",
        "numpages": "14",
        "pages": "42--55",
        "publisher": "IBM Press",
        "series": "CASCON",
        "title": "A Survey of Trace Exploration Tools and Techniques",
        "type": "InProceedings",
        "year": "2004"
    },
    "Haugen2015": {
        "abstract": "Task-based  scheduling  has  emerged  as  one  solution  to  the complexity of parallel computing.  When using these tools, developers must frame their computation as a series of tasks with  various  data  dependencies.   The scheduler  can  take these  tasks,  along  with  their  input  and  output dependencies, and schedule the task in parallel across a node or cluster. While these schedulers simplify the process of parallel software development, they can obfuscate the performance characteristics of the execution of an algorithm.  The execution trace has been used for many years to give developers a visual representation of how their computations are  performed.   These methods  can  be  easily  employed  to visualize when and where each of the tasks in a task-based algorithm is scheduled.  In addition, the task dependencies can be used to create a directed acyclic graph (DAG) that can also be  visualized to demonstrate  the  dependencies of the various tasks that make up a workload.  The work presented here aims to combine these two data sets and extend execution trace visualization to better suit task-based workloads.  This paper presents a brief description of task-based schedulers and the performance data they produce.  It will then describe an interactive extension to the current trace visualization  methods  that  combines  the  trace  and  DAG data sets.   This  new  tool  allows  users  to  gain  a  greater understanding of how their tasks are scheduled.  It also provides a  simplfied way  for  developers  to  evaluate  and  debug  the performance of their scheduler.",
        "author": "Haugen, Blake and Richmond, Stephen and Kurzak, Jakub and Steed, Chad and Dongarra, Jack",
        "booktitle": "Proceedings of the 2nd Workshop on Visual Performance Analysis",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: gantt, vis: timelines, subcontext: DAG, vis: multiple coordinated views, vis: density plot, parallel scale: 100",
        "month": "Nov",
        "series": "VPA",
        "title": "Visualizing Execution Traces with Task Dependencies",
        "type": "InProceedings",
        "year": "2015"
    },
    "Haynes2001": {
        "abstract": "This paper describes a unique visualization tool that has been used to analyze performance of the CplantTM clusters at Sandia National Laboratories. As commodity cluster systems grow in size and complexity, understanding performance issues becomes more and more difficult. We have developed a tool that facilitates visual performance analysis within the context of the physical and runtime environment of a system. Combining an abstract system model with color-coding for both performance and job information enables quick fault isolation as well as insight into complex system behavior.",
        "author": "Haynes, Rena and Crossno, Patricia and Russell, Eric",
        "booktitle": "Proceedings of the 2001 IEEE International Conference on Cluster Computing",
        "doi": "10.1109/CLUSTR.2001.959990",
        "issn": "1552-5244",
        "keywords": "type: research, context: hardware, subcontext: network, vis: glyphs, vis: 3D, subcontext: 2D torus, subcontext: torus, parallel scale: 100",
        "pages": "295-302",
        "series": "CLUSTER",
        "title": "A visualization tool for analyzing cluster performance data",
        "type": "InProceedings",
        "year": "2001"
    },
    "Heath1991": {
        "abstract": "Graphical visualization aids human comprehension of complex phenomena and large volumes of data. The behavior of parallel programs on advanced architectures is often extremely complex, and monitoring the performance of such programs can gener ate vast quantities of data. So it seems natural to use visualization to gain insight into the behavior of parallel programs so we can better understand them and improve their performance. We have developed ParaGraph, a software tool that provides a detailed, dynamic, graphical animation of the behavior of message-passing parallel programs and graphical summaries of their performance.",
        "author": "Heath, Michael T. and Etheridge, Jennifer A.",
        "doi": "10.1109/52.84214",
        "issn": "0740-7459",
        "journal": "IEEE Software",
        "keywords": "type: research, name: ParaGraph, context: tasks, vis: adjacency matrix, vis: animation, vis: timelines, vis: statistical plots, vis: multiple views, parallel scale: 100",
        "number": "5",
        "pages": "29-39",
        "series": "IEEE Software",
        "title": "Visualizing the performance of parallel programs",
        "type": "ARTICLE",
        "volume": "8",
        "year": "1991"
    },
    "Holten2007": {
        "author": "Holten, Danny and Cornelissen, Bas and van Wijk, Jarke J.",
        "booktitle": "4th IEEE International Workshop on Visualizing Software for Understanding and Analysis",
        "doi": "10.1109/VISSOF.2007.4290699",
        "keywords": "type: research, name: ExTraVis, context: software, subcontext: trace, vis: edge-bundling, vis: information mural, vis: tree, subcontext: class hierarchy, parallel scale: N/A",
        "pages": "47-54",
        "series": "VISSOFT",
        "title": "Trace Visualization Using Hierarchical Edge Bundles and Massive Sequence Views",
        "type": "InProceedings",
        "year": "2007"
    },
    "Hondroudakis1994": {
        "abstract": "Environments for parallel program performance visualization, analysis and tuning have emerged as crucial tools in parallel computing. Unfortunately, though many prototypes have been described in the literature, progress to- wards the identification of generic design requirements has been slow. Whilst detailed requirements may be highly specific to machine architectures, this cannot explain the apparent failure to address the key issue of usability at the more general level. Claims that existing tools aid performance tuning need substantiation, and designers\u2019 intuitions need to be made explicit and scrutinised. In summary, design must be guided by a greater understanding of human factors. This paper attempts to formulate a human factors agenda for the design of performance tuning tools, and to identify those areas where understanding is currently weakest. Finally, it considers some implications of changes in users\u2019 requirements.",
        "author": "Hondroudakis, Anna and Procter, Rob",
        "booktitle": "Parallel Architectures and Languages Europe: 6th International PARLE Conference",
        "doi": "10.1007/3-540-58184-7_148",
        "editor": "Halatsis, Costas and Maritsas, Dimitrios and Philokyprou, George and Theodoridis, Sergios",
        "keywords": "type: position, context: n/a, subcontext: n/a, vis: n/a, parallel scale: n/a, name: n/a",
        "pages": "749--752",
        "series": "PARLE",
        "title": "Applying Human Factors to The Design of Parallel Software Performance Analysis Tools",
        "type": "article",
        "year": "1994"
    },
    "Hough1988": {
        "abstract": "Highly parallel programs are often best understood in terms of logical patterns of interprocess communication. In order to debug such programs, the user must determine the extent to which the intended patterns occur during execution. To facilitate this, we have designed and implemented a pattern-oriented debugger in which abstract, user-defined communication events can be described and animated. We report here on our initial experiences with its use.",
        "acmid": "69234",
        "address": "New York, NY, USA",
        "author": "Hough, Alfred A. and Cuny, Janice E.",
        "booktitle": "Proceedings of the 1988 ACM SIGPLAN and SIGOPS Workshop on Parallel and Distributed Debugging",
        "doi": "10.1145/68210.69234",
        "isbn": "0-89791-296-9",
        "keywords": "type: research,name: Ariadne, name: Belvedere, context: tasks, subcontext: trace, vis: animation, subcontext: debugging, vis: logical time, vis: node-link, parallel scale: 1+",
        "location": "Madison, Wisconsin, USA",
        "numpages": "11",
        "pages": "195--205",
        "publisher": "ACM",
        "series": "PADD",
        "title": "Initial Experiences with a Pattern-oriented Parallel Debugger",
        "type": "InProceedings",
        "year": "1988"
    },
    "Huck2014VisIt": {
        "abstract": "Understanding the performance of program exe- cution is essential when optimizing simulations run on high- performance supercomputers. Instrumenting and profiling codes is itself a difficult task and interpreting the resulting complex data is often facilitated through visualization of the gathered measures. However, these measures typically ignore spatial information specific to a simulation, which may contain useful knowledge on program behavior. Linking the instrumentation data to the visualization of performance within a spatial context is not straightforward as information needed to create the visualizations is not, by default, included in data collection, and the typical visualization approaches do not address spatial concerns. In this work, we present an approach that links the collection of spatially-aware performance data to a visualization paradigm through both analysis and visualization abstractions to facilitate better understanding of performance in the spatial context of the simulation. Because the potential costs for such a system are quite high, we leverage existing performance profiling and visualization systems and demonstrate their combined potential on climate simulation.",
        "author": "Huck, Kevin A. and Potter, Kristin C., and Jacobsen, Doug W. and Childs, Hank and Malony, Allen D.",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.9",
        "keywords": "type: research, context: hardware, context: application, context: software, name: VisIt, name: TAU, vis: ensemble",
        "month": "Nov",
        "pages": "50 -- 57",
        "series": "VPA",
        "title": "Linking Performance Data into Scientific Visualization Tools",
        "type": "InProceedings",
        "year": "2014"
    },
    "Husain2015": {
        "abstract": "Understanding performance data, and more specifically memory access pattern is essential in optimizing scientific applications. Among the various factors affecting performance, such as the hardware architecture, the algorithms, or the system software stack, performance is also often related to the applications' physics. While there exists a number of techniques to collect relevant performance metrics, such as number of cache misses, traditional tools almost exclusively present this data relative to the code or as abstract tuples. This can obscure the data dependent nature of performance bottlenecks and make root-cause analysis difficult. Here we take advantage of the fact that a large class of applications are defined over some domain discretized by a mesh. By projecting the performance data directly onto these meshes, we enable developers to explore the performance data in the context of their application resulting in more intuitive visualizations. We introduce a lightweight, general interface to couple a performance visualization tool, MemAxes, to an external visualization tool, VisIt. This allows us to harness the advanced analytic capabilities of MemAxes to drive the exploration while exploiting the capabilities of VisIt to visualize both application and performance data in the application domain.",
        "acmid": "2835243",
        "articleno": "5",
        "author": "Husain, Benafsh and Gim{\\'e}nez, Alfredo and Levine, Joshua A. and Gamblin, Todd and Bremer, Peer-Timo",
        "booktitle": "Proceedings of the 2nd Workshop on Visual Performance Analysis",
        "doi": "10.1145/2835238.2835243",
        "keywords": "type: research, subcontext: memory, context: application, context: hardware, name: MemAxes, name: VisIt, vis: coordination API, parallel scale: n/a",
        "numpages": "8",
        "pages": "5:1--5:8",
        "publisher": "ACM",
        "series": "VPA",
        "title": "Relating Memory Performance Data to Application Domain Data Using an Integration API",
        "type": "InProceedings",
        "year": "2015"
    },
    "Huynh2015DAGViz": {
        "abstract": "In task-based parallel programming, programmers can ex- pose logical parallelism of their programs by creating finne- grained tasks at arbitrary places in their code. All other bur- dens in the parallel execution of these tasks such as thread management, task scheduling, and load balancing are han- dled automatically by runtime systems. This kind of paral- lel programming model has been conceived as a promising paradigm that brings intricate parallel programming tech- niques to a larger audience of programmers because of its high programmability. There have been many languages (e.g., OpenMP, Cilk Plus) and libraries (e.g, Intel TBB, Qthreads, MassiveThreads) supporting task parallelism. How- ever, the nondeterministic nature of task parallel execution which hides runtime scheduling mechanisms from program- mers has made it difficult for programmers to understand the cause of suboptimal performance of their programs. As an effort to tackle this problem, and also to clarify differ- ences between task parallel runtime systems, we have de- veloped a toolset that captures and visualizes the trace of an execution of a task parallel program in the form of a directed acyclic graph (DAG). A computation DAG of a task parallel program's run is extracted automatically by our lightweight portable wrapper around all five systems which incurs no intervention into the target systems' code. The DAG is stored in a file and then visualized to analyze per- formance. We leverage the hierarchical structure of the DAG to enhance the DAG fille format and DAG visualization, and make them manageable even with a huge DAG of arbitrar- ily large numbers of nodes. This DAG visualization provides a task-centric view of the program, which is different from other popular visualizations such as thread-centric timeline visualization and code-centric hotspots analysis. Besides, DAGViz also provides an additional timeline visualization which is constructed by individual nodes of the DAG, and is useful in coordinating user attention to low-parallelism areas on the DAG. We demonstrate usefulness of our DAG visual- izations in some case studies. We expect to build other kinds of effective visualizations based on this computation DAG in future work, and make DAGViz an effective tool support- ing the process of analyzing task parallel performance and developing scheduling algorithms for task parallel runtime schedulers.",
        "author": "Huynh, An and Thain, Douglas and Pericas, Miquel and Taura, Kenjiro",
        "booktitle": "Proceedings of the 2nd Workshop on Visual Performance Analysis",
        "keywords": "type: research, context: tasks, subcontext: trace, subcontext: task graph, vis: timelines, vis: node-link, vis: hierarchical, vis: interactive, vis: timelines, subcontext: threads",
        "month": "Nov",
        "series": "VPA",
        "title": "{DAGViz}: A {DAG} Visualization Tool for Analyzing Task-Parallel Program Traces",
        "type": "InProceedings",
        "year": "2015"
    },
    "Ilsche2012Vampir": {
        "abstract": "Event tracing is an important tool for understanding the performance of parallel applications. As concurrency in- creases in leadership-class computing systems, the quantity of performance log data can overload the parallel file system, perturbing the application being observed. In this work we present a solution for event tracing at leadership scales. We enhance the I/O forwarding system software to aggregate and reorganize log data prior to writing to the storage sys- tem, significantly reducing the burden on the underlying file system for this type of traffic. Furthermore, we augment the I/O forwarding system with a write buffering capability to limit the impact of artificial perturbations from log data accesses on traced applications. To validate the approach, we modify the Vampir tracing toolset to take advantage of this new capability and show that the approach increases the maximum traced application size by a factor of 5x to more than 200,000 processes.",
        "acmid": "2287085",
        "address": "New York, NY, USA",
        "author": "Ilsche, Thomas and Schuchart, Joseph and Cope, Jason and Kimpe, Dries and Jones, Terry and Kn\\\"{u}pfer, Andreas and Iskra, Kamil and Ross, Robert and Nagel, Wolfgang E. and Poole, Stephen",
        "booktitle": "Proceedings of the 21st International Symposium on High-Performance Parallel and Distributed Computing",
        "doi": "10.1145/2287076.2287085",
        "isbn": "978-1-4503-0805-2",
        "keywords": "type: research, name: Vampir, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, subcontext: messages, vis: client-server, parallel scale: 100K",
        "location": "Delft, The Netherlands",
        "numpages": "12",
        "pages": "49--60",
        "publisher": "ACM",
        "series": "HPDC",
        "title": "Enabling Event Tracing at Leadership-class Scale Through I/O Forwarding Middleware",
        "type": "InProceedings",
        "year": "2012"
    },
    "Isaacs2012": {
        "acmid": "2477134",
        "address": "Washington, DC, USA",
        "author": "Isaacs, Katherine E. and Landge, Aaditya G. and Gamblin, Todd and Bremer, Peer-Timo and Pascucci, Valerio and Hamann, Bernd",
        "booktitle": "Proceedings of the 2012 SC Companion: High Performance Computing, Networking Storage and Analysis",
        "doi": "10.1109/SC.Companion.2012.202",
        "isbn": "978-0-7695-4956-9",
        "keywords": "type: research, name: Boxfish, context: hardware, subcontext: network, vis: multiple coordinated views, vis: filtering, parallel scale: NR",
        "numpages": "2",
        "pages": "1380--1381",
        "publisher": "IEEE Computer Society",
        "series": "SCC",
        "title": "Abstract: Exploring Performance Data with {Boxfish}",
        "type": "InProceedings",
        "year": "2012"
    },
    "Isaacs2014Ravel": {
        "abstract": "With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies \u2013 potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and inter-process messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code\u2019s structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.",
        "author": "Isaacs, Katherine E. and Bremer, Peer-Timo and Jusufi, Ilir and Gamblin, Todd and Bhatele, Abhinav and Schulz, Martin and Hamann, Bernd",
        "journal": "IEEE Transactions on Visualization and Computer Graphics, Proceedings of InfoVis '14",
        "keywords": "type: research, context: tasks, subcontext: trace, name: Ravel, vis: gantt, vis: timelines, subcontext: messages, vis: multiple coordinated views, vis: logical time, vis: clustering, parallel scale: 10k",
        "number": "12",
        "series": "InfoVis",
        "title": "Combing the communication hairball: Visualizing large-scale parallel execution traces using logical time",
        "type": "article",
        "year": "2014"
    },
    "Isaacs2014STAR": {
        "abstract": "Performance visualization comprises techniques that aid developers and analysts in improving the time and energy efficiency of their software.  In this work, we discuss performance as it relates to visualization and survey existing approaches in performance visualization. We present an overview of what types of performance data can be collected and a categorization of the types of goals that performance visualization techniques can address. We develop a taxonomy for the contexts in which different performance visualizations reside and describe the state of the art research pertaining to each. Finally, we discuss unaddressed and future challenges in performance visualization.",
        "author": "Isaacs, Katherine E. and Gim\\'{e}nez, Alfredo and Jusufi, Ilir and Gamblin, Todd and Bhatele, Abhinav and Schulz, Martin and Hamann, Bernd and Bremer, Peer-Timo",
        "booktitle": "Eurographics/IEEE Conference on Visualization State-of-the-Art Reports",
        "keywords": "type: survey, context: n/a, subcontext: n/a, parallel scale: n/a, vis: n/a, subcontext: n/a",
        "series": "EuroVis",
        "title": "State of the Art of Performance Visualization",
        "type": "InProceedings",
        "year": "2014"
    },
    "Jerding1997": {
        "abstract": "mplementing, validating, modifying, or reengineering an object-oriented system requires an understanding of the object and class interactions which occur as a program executes. This work seeks to identify, visualize, and analyze interactions in object-oriented program executions as a means for examining and understanding dynamic behavior. We have discovered recurring interaction scenarios in program executions that can be used as abstractions in the understanding process, and have developed a means for identifying these interaction patterns. Our visualizations focus on supporting design recovery, vahdation, and reengineering tasks, and can be applied to both object-oriented and procedural programs.",
        "acmid": "253356",
        "address": "New York, NY, USA",
        "author": "Jerding, Dean F. and Stasko, John T. and Ball, Thomas",
        "booktitle": "Proceedings of the 19th International Conference on Software Engineering",
        "doi": "10.1145/253228.253356",
        "isbn": "0-89791-914-9",
        "keywords": "type: research, name: Polka, context: software, subcontext: trace, vis: information mural, vis: code, vis: node-link, parallel scale: N/A",
        "location": "Boston, Massachusetts, USA",
        "numpages": "11",
        "pages": "360--370",
        "publisher": "ACM",
        "series": "ICSE",
        "title": "Visualizing Interactions in Program Executions",
        "type": "InProceedings",
        "year": "1997"
    },
    "Kale2003Projections": {
        "abstract": "Some of the most challenging applications to parallelize scalably are the ones that present a relatively small amount of computation per iteration. Multiple interacting performance challenges must be identified and solved to attain high parallel efficiency in such cases. We present a case study involving NAMD, a parallel molecular dynamics application, and efforts to scale it to run on 3000 processors with Tera-FLOPS level performance. NAMD is implemented in Charm++, and the performance analysis was carried out using \"projections\", the performance visualization/analysis tool associated with Charm++. We will showcase a series of optimizations facilitated by projections. The resultant performance of NAMD led to a Gordon Bell award at SC2002.",
        "author": "Kal\\'e, Laxmikant V. and Kumar, Sameer and Zheng, Gengbin and Lee, Chee Wai",
        "booktitle": "\"Terascale Performance Analysis Workshop, International Conference on Computational Science\",",
        "keywords": "type: research, name: Projections, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, vis: multiple views, vis: statistical plots, parallel scale: 10K",
        "month": "\"June\",",
        "series": "Lecture Notes in Computer Science",
        "title": "\"Scaling Molecular Dynamics to 3000 Processors with Projections: A Performance Analysis Case Study\",",
        "type": "InProceedings",
        "year": "\"2003\","
    },
    "Kale2006": {
        "author": "Kal\\'e Laxmikant V. and Zheng, Gengbin and Lee, Chee Wai and Kumar",
        "booktitle": "Future Generation Computer Systems Special Issue on: Large-Scale System Performance Modeling and Analysis",
        "doi": "10.1016/j.future.2004.11.020",
        "keywords": "type: research, name: Projections, context: tasks, subcontext: trace, vis: timelines, vis: Gantt, subcontext: messages, vis: scatterplots, parallel scale: 10K",
        "month": "February",
        "number": "3",
        "pages": "347-358",
        "title": "Scaling Applications to Massively Parallel Machines Using {Projections} Performance Analysis Tool",
        "type": "InProceedings",
        "volume": "22",
        "year": "2006"
    },
    "Karavanic1997": {
        "abstract": "Performance tuning a parallel application involves integrating performance data from many components of the system, including the message passing library, performance monitoring tool, resource manager. operating system, and the application itself. The current practice of visualizing these data streams using a separate, customized tool for each source is inconvenient from a usability perspective, and there is no easy way to visualize the data in an integrated fashion. We demonstrate a solution to this problem using Devise, a generic visualization tool which is designed to allow an arbitrary number of different but related data streams to be integrated and explored visually in a flexible manner. We display data emanating from a variety of sources side by side in three case studies. First we interface the Paradyn parallel performance tool and Devise, using two simple data export modules and Paradyn\u2019s simple visualization interface. We show several Devise/Paradyn visualizations which are useful for performance tuning parallel codes, and which incorporate data from Unix utilities and application output. Next we describe the visualization of trace data from a parallel application running in a Condor cluster of workstations. Finally we demonstrate the utility of Devise visualizations in a study of Condor cluster activity.",
        "acmid": "260677",
        "address": "Amsterdam, The Netherlands, The Netherlands",
        "author": "Karavanic, Karen L. and Myllymaki, Jussi and Livny, Miron and Miller, Barton P.",
        "doi": "10.1016/S0167-8191(96)00104-4",
        "issn": "0167-8191",
        "issue_date": "April 1997",
        "journal": "Parallel Computing",
        "keywords": "type: research, name: Devise, name: Paradyn, context: tasks, subcontext: trace, vis: timelines, vis: scatterplots, parallel scale: 10",
        "month": "apr,",
        "number": "1-2",
        "numpages": "18",
        "pages": "181--198",
        "publisher": "Elsevier Science Publishers B. V.",
        "series": "Parallel Computing",
        "title": "Integrated Visualization of Parallel Program Performance Data",
        "type": "article",
        "volume": "23",
        "year": "1997"
    },
    "Karran2013SyncTrace": {
        "abstract": "In software comprehension, program traces are important to gain insight into certain aspects of concurrent runtime behavior, e.g., thread-interplay. Here, key tasks are finding usages of blocking operations, such as synchronization and I/O operations, assessing temporal order of such operations, and analyzing their effects. This is a hard task for large and complex program traces due to their size and number of threads involved. In this paper, we present SYNCTRACE, a new visualization technique based on (bended) activity diagrams and edge bundles that allows for parallel analysis of multiple threads and their inter-thread correspondences. We demonstrate how the technique, implemented as a tool, can be applied on real-world trace datasets to support understanding concurrent behavior.",
        "author": "Karran, Benjamin and Tr\\\"umper, Jonas and D\\\"ollner, J\\\"urgen",
        "booktitle": " Proceedings of the 1st Working Conference on Software Visualization ",
        "doi": "10.1109/VISSOFT.2013.6650534",
        "keywords": "type: research, name: SyncTrace, context: tasks, subcontext: trace, vis: icicle timelines, vis: sunburst, vis: thread-centric, subcontext: threads, parallel scale: 100",
        "pages": " 10 ",
        "publisher": " IEEE Computer Society ",
        "series": "VISSOFT",
        "title": " SyncTrace: Visual Thread-Interplay Analysis ",
        "type": "InProceedings",
        "year": " 2013 "
    },
    "Karrer2011": {
        "abstract": "We present Stacksplorer, a new tool to support source code navigation and comprehension. Stacksplorer computes the call graph of a given piece of code, visualizes relevant parts of it, and allows developers to interactively traverse it. This augments the traditional code editor by offering an additional layer of navigation. Stacksplorer is particularly useful to understand and edit unknown source code because branches of the call graph can be explored and backtracked easily. Visualizing the callers of a method reduces the risk of introducing unintended side effects. In a quantitative study, programmers using Stacksplorer performed three of four software maintenance tasks significantly faster and with higher success rates, and Stacksplorer received a System Usability Scale rating of 85.4 from participants.",
        "acmid": "2047225",
        "address": "New York, NY, USA",
        "author": "Karrer, Thorsten and Kr\\\"{a}mer, Jan-Peter and Diehl, Jonathan and Hartmann, Bj\\\"{o}rn and Borchers, Jan",
        "booktitle": "Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology",
        "doi": "10.1145/2047196.2047225",
        "isbn": "978-1-4503-0716-1",
        "keywords": "type: research, context: software, subcontext: callgraph, name: Stacksplorer, vis: code",
        "location": "Santa Barbara, California, USA",
        "numpages": "8",
        "pages": "217--224",
        "publisher": "ACM",
        "series": "UIST",
        "title": "Stacksplorer: Call Graph Navigation Helps Increasing Code Maintenance Efficiency",
        "type": "InProceedings",
        "url": "http://doi.acm.org/10.1145/2047196.2047225",
        "year": "2011"
    },
    "Kim2007": {
        "abstract": "It is important to debug unintended data races in OpenMP programs efficiently, because such programs are often complex and long-running. Previous tools for detecting the races does not provide any effective facility for understanding the complexity of threads involved in the reported races. This paper presents a thread visualization tool to present a partial order of threads executed in the traced programs with a scalable graph of abstract threads upon a three-dimensional cone. The scalable thread visualization is proved to be effective in debugging races using a set of synthetic programs.",
        "acmid": "1759895",
        "address": "Berlin, Heidelberg",
        "author": "Kim, Young-Joo and Lim, Jae-Seon and Jun, Yong-Kee",
        "booktitle": "Proceedings of the 2nd International Conference on Advances in Grid and Pervasive Computing",
        "doi": "10.1007/978-3-540-72360-8_27",
        "isbn": "978-3-540-72359-2",
        "keywords": "type: research, context: tasks, subcontext: dependency graphs, vis: tree, vis: cone, vis: 3D, subcontext: threads, subcontext: openMP, vis: code, subcontext: data races, parallel scale: 1K",
        "location": "Paris, France",
        "numpages": "12",
        "pages": "310--321",
        "publisher": "Springer-Verlag",
        "series": "GPC",
        "title": "Scalable Thread Visualization for Debugging Data Races in OpenMP Programs",
        "type": "InProceedings",
        "year": "2007"
    },
    "Kockerbauer2017g-Eclipse": {
        "abstract": "The use of event graphs is a common approach to debug and analyze message passing parallel programs. Although event graphs are very useful for program understanding and debugging, they get confusing and hard to read for programs with complex communication behavior, long runtimes and a large numbers of processes. An approach to ease this problem is to simplify the event graph by marking occurrences of predefined well known communication structures. This allows to quickly identify different regions of activity in the event graph without further inspection. It also helps to identify parts, where certain communication patterns are expected but do not occur due to a bug in the parallel application, in this case the pattern might only match to a certain degree. In this paper we present a language for the description of such communication patterns, which allows to describe the patterns in a way that also covers variations in process numbers and process mappings. Furthermore it demonstrates a pattern matching plugin for the Trace Viewer of g-Eclipse which uses an specialized algorithm for detecting patterns in prerecorded event traces of parallel programs. Based on the presented approach a variety of improvements for the processing and presentation of event graphs are imaginable. The extracted pattern information could be used to optimize the analyzed program or to reduce the contents of the graph to areas of interest, by substituting non interesting parts by placeholders.",
        "author": "K{\\\"o}ckerbauer, Thomas and Kranzlm{\\\"u}ller, Dieter",
        "booktitle": "Tools for High Performance Computing 2016",
        "doi": "10.1007/978-3-319-56702-0_2",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, pattern search, parallel scale: 10, name: g-Eclipse",
        "pages": "23--40",
        "publisher": "Springer",
        "title": "Defining and Searching Communication Patterns in Event Graphs Using the g-Eclipse Trace Viewer Plugin",
        "type": "incollection",
        "year": "2017"
    },
    "Kohl1996XPVM": {
        "abstract": "One of the more bothersome aspects of developing a parallel program is that of monitoring the behavior of the program for debugging and performance tuning. This paper discusses an enhanced tracing facility and tracing tool for PVM (Parallel Virtual Machine), a message passing library for parallel processing in a heterogeneous environment. PVM supports mixed collections of workstation clusters, shared-memory multiprocessors, and MPPs. The upcoming release of PVM, Version 3.4, contains a new and improved tracing facility which provides more flexible and efficient access to run-time program information. This new tracing system supports a buffering mechanism to reduce the perturbation of user applications caused by tracing, and a more flexible trace event definition scheme which is based on a self-defining data format. The new scheme expedites the collection of program execution histories, and allows for integration of user-defined custom trace events. The tracing instrumentation is built into the PVM library, to avoid re-compilation when tracing is desired, and supports on-the-fly adjustments to each task's trace event mask, for control over the level of tracing detail",
        "author": "Kohl, James Arthur and Geist, GA",
        "booktitle": "Proceedings of the Twenty-Ninth Hawaii International Conference on System Sciences",
        "doi": "10.1109/HICSS.1996.495474",
        "keywords": "type: research, name: XPVM, context: tasks, subcontext: trace, vis: multiple views",
        "organization": "IEEE",
        "pages": "290--299",
        "series": "HICSS",
        "title": "The PVM 3.4 tracing facility and XPVM 1.1",
        "type": "InProceedings",
        "volume": "1",
        "year": "1996"
    },
    "Koike1997": {
        "abstract": "This paper describes the VisuaLanda system, which is an integration of a Linda server and a visualizer of parallel Linda programs. Since the visualization module is built in the Linda server, programmers do *rutneed to put additional visualization primitives their client programs in order to visualize the behavior of these programs. This framework significantly reduces the programmers' burden in debugging parallel programs, owing to the",
        "author": "Koike, Hideki and Takada, Tetsuji and Masui, Toshiyuki",
        "booktitle": "IEEE Symposium on Visual Languages",
        "doi": "10.1109/VL.1997.626578",
        "following two ,": "features. First, it minimizes \"probe effect,\" which is one of the main concerns in monitoring parallel programs. Second, VisuaLanda uses three-dimensional space to display both the relation between the Linda server and the client programs, and the execution of client programs.  This framework canbe used to display a much larger number of processes than using 2D visualization techiques, see two relations simultaneously, izmprove the visibility of communication lines, and see see each process's state as well as the overview of the execution.",
        "issn": "1049-2615",
        "keywords": "type: research, name: VisuaLinda, context: tasks, subcontext: trace, vis: timelines, vis: 3D, vis: Gantt, parallel scale: 10",
        "pages": "174-178",
        "title": "VisuaLinda: a framework for visualizing parallel Linda programs",
        "type": "InProceedings",
        "year": "1997"
    },
    "Koppelman2014PSE": {
        "abstract": "CPU performance is determined by the interaction between available resources, microarchitectural features, the execution of instructions, and by the data. These elements can interact in complex ways, making it difficult for those seeing only aggregate performance numbers, such as miss ratios and issue rates, to determine whether there are reasonable avenues for performance improvement. A technique called instruction- level visualization helps users connect these disparate elements by showing the timing of the execution of individual program in- structions. The PSE visualization program enhances instruction- level visualization by showing which instructions contribute to execution inefficiency in a way that makes it easy to locate dependent instructions and the history of events affecting the instruction. A simple annotation system makes it easy for a user to attach custom information. PSE has been used for microar- chitecture research, simulator debugging, and for instructional use.",
        "author": "Koppelman, David M. and Michael, Chris J.",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.11",
        "keywords": "type: research, context: software, subcontext: trace, subcontext: instructions, name: PSE",
        "month": "Nov",
        "pages": "36 -- 41",
        "series": "VPA",
        "title": "Discovering Barriers to Efficient Execution, Both Obvious and Subtle, Using Instruction-Level Visualization",
        "type": "InProceedings",
        "year": "2014"
    },
    "Kraemer1993": {
        "abstract": "Interactive program steering is a promising technique for improving the performance of parallel and distributed applications. Steering decisions are typically based on visual presentations of some subset of the computation\u2019s current state, a historical view of the computation\u2019s behavior; or views of metrics basedon the program\u2019s performance. As in any endeavor; good decisions require accurate information. However; the distributed nature of the collection process may result in distortions in the portrayal of the program\u2019s execution. These distortions stem from the merging of streams of information from distributed collection points into a single stream without enforcing the ordering relationships that held among the program components that produced the information. An ordering filter placed at the point at which the streams are merged can ensure a valid ordering, leading to more accurate visualizations and better informed steering decisions. In this paper we describe the implementation of such filters in the Falcon interactive steering toolkit, and present a methodology for their specification for automated generation.",
        "acmid": "163533",
        "author": "Kraemer, Eileen and Stasko, John T.",
        "doi": "10.1006/jpdc.1993.1050",
        "issn": "0743-7315",
        "issue_date": "June 1993",
        "journal": "Journal of Parallel and Distributed Computing",
        "keywords": "type: survey, vis: n/a, subcontext: n/a, parallel scale: n/a, context: n/a, name: n/a",
        "month": "jun,",
        "number": "2",
        "numpages": "13",
        "pages": "105--117",
        "publisher": "Academic Press, Inc.",
        "series": "JPDC",
        "title": "The Visualization of Parallel subcontext:An Overview",
        "type": "article",
        "volume": "18",
        "year": "1993"
    },
    "Kraemer1998PARADE": {
        "abstract": "Visualization tools for concurrent systems must support designers in their quest to create visualizations that promote an understanding of concurrent computations and avoid inconsistent or unsynchronized views that mislead users. A visualization system with reorderable, synchronous, and independent displays provides the necessary framework for understanding concurrent computations. This article opens with a discussion of current visualization faults and limitations. We then explain why we find the characteristics mentioned above essential to the analysis of concurrent computations and how we applied them to create a more effective visualization system through our Parade visualization environment and Polka animation toolkit.",
        "acmid": "614078",
        "address": "Piscataway, NJ, USA",
        "author": "Kraemer, Eileen and Stasko, John T.",
        "doi": "10.1109/4434.656778",
        "issn": "1092-3063",
        "issue_date": "January 1998",
        "journal": "IEEE Concurrency",
        "keywords": "type: research,name: PARADE, name: Polka, context: application, context: tasks, vis: animation",
        "month": "jan,",
        "number": "1",
        "numpages": "11",
        "pages": "36--46",
        "publisher": "IEEE Educational Activities Department",
        "title": "Creating an Accurate Portrayal of Concurrent Executions",
        "type": "article",
        "volume": "6",
        "year": "1998"
    },
    "Landge2012Boxfish": {
        "abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D\u2019s performance on an IBM Blue Gene/P system.",
        "author": "Landge, Aaditya G. and Levine, Joshua A. and Bhatele, Abhinav and Isaacs, Katherine E. and Gamblin, Todd and Schulz, Martin and Langer, Steven H. and Bremer, Peer-Timo and Pascucci, Valerio",
        "doi": "10.1109/TVCG.2012.286",
        "issn": "1077-2626",
        "journal": "IEEE Transactions on Visualization and Computing Graphics, Proceedings of InfoVis",
        "keywords": "type: research, name: Boxfish, context: hardware, subcontext: network, subcontext: 3D torus, subcontext: torus, vis: projection, parallel scale: 10K",
        "number": "12",
        "pages": "2467-2476",
        "series": "InfoVis",
        "title": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
        "type": "article",
        "volume": "18",
        "year": "2012"
    },
    "LeBlanc1990": {
        "abstract": "To understand a parallel program\u2019s execution we must be able to analyze lots of information describing complex relationships among many processes. Various techniques have been used, from program replay to program animation, but each has limited applicability and the lack of a common foundation preclues an integrated solution. Our approach to parallel program analysis is based on a multiplicity of views of an execution. We use a synchronization trace captured during execution to construct a graph represnetation of  the program's behavior. A user manipulates this representation to creat eand fine-tune visualizations using an integrated, programmable toolkit. Additional execution details can be recovered as needed using program replay to reconstructan execution from an existing synchronization trace. We presenta framework for describing views of a parallel program\u2019s execution, and ananalysis methodology that relates a sequence of views to the progra mdevelopment cycle. We then describe our toolkit implementation and explain how users construct visualizations using the toolkit. Finally, we present an extended example to illustrate both our methodology and the power of our programmable toolkit.",
        "acmid": "78272",
        "author": "LeBlanc, Thomas J. and Mellor-Crummey, John M. and Fowler, Robert J.",
        "doi": "10.1016/0743-7315(90)90046-R",
        "issn": "0743-7315",
        "issue_date": "June 1990",
        "journal": "Journal of Parallel and Distributed Computing",
        "keywords": "type: research,name: Moviola, context: application, context: tasks, vis: logical time, vis: timelines, vis: scatterplots, vis: bar charts, vis: multiple views, parallel scale: 10",
        "month": "jun,",
        "number": "2",
        "numpages": "15",
        "pages": "203--217",
        "publisher": "Academic Press, Inc.",
        "series": "JPDC",
        "title": "Analyzing Parallel Program Executions Using Multiple Views",
        "type": "article",
        "volume": "9",
        "year": "1990"
    },
    "Lehr1989PIE": {
        "acmid": "74875",
        "address": "Los Alamitos, CA, USA",
        "author": "Lehr, Ted and Segall, Zary and Vrsalovic, Dallbor F. and Caplan, Eddie and Chung, Alan L. and Fineman, Charles E.",
        "doi": "10.1109/2.42013",
        "issn": "0018-9162",
        "issue_date": "October 1989",
        "journal": "Computer",
        "keywords": "type: research, name: PIE, context: tasks, context: software, subcontext: dependency graphs, vis: multiple views, vis: timelines, vis: histograms, parallel scale: 10",
        "month": "oct,",
        "number": "10",
        "numpages": "14",
        "pages": "38--51",
        "publisher": "IEEE Computer Society Press",
        "title": "Visualizing Performance Debugging",
        "type": "article",
        "volume": "22",
        "year": "1989"
    },
    "Liao1999": {
        "abstract": "The SUIF Explorer is an interactive parallelization tool that is more effective than previous systems in minimizing the number of lines of code that require programmer assistance. First, the interprocedural analyses in the SUIF system is successful in parallelizing many coarse-grain loops, thus minimizing the number of spurious dependences requiring attention. Second, the system uses dynamic execution analyzers to identify those important loops that are likely to be parallelizable. Third, the SUIF Explorer is the first to apply program slicing to aid programmers in interactive parallelization. The system guides the programmer in the parallelization process using a set of sophisticated visualization techniques. This paper demonstrates the effectiveness of the SUIF Explorer with three case studies. The programmer was able to speed up all three programs by examining only a small fraction of the program and privatizing a few variables.",
        "acmid": "301108",
        "address": "New York, NY, USA",
        "author": "Liao, Shih-Wei and Diwan, Amer and Bosch, Robert P. and Ghuloum, Anwar and Lam, Monica S.",
        "booktitle": "Proceedings of the Seventh ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming",
        "doi": "10.1145/301104.301108",
        "isbn": "1-58113-100-3",
        "keywords": "type: research, name: SUIF Explorer",
        "location": "Atlanta, Georgia, USA",
        "numpages": "12",
        "pages": "37--48",
        "publisher": "ACM",
        "series": "PPoPP",
        "title": "SUIF Explorer: An Interactive and Interprocedural Parallelizer",
        "type": "InProceedings",
        "year": "1999"
    },
    "Lin2010": {
        "abstract": "Developers must often diagnose anomalies in programs they only have a partial knowledge of. As a result, they must simultaneously reverse engineer parts of the system they are unfamiliar with while interpreting dynamic observation data (performance profiling traces, error-propagation channels, memory leaks), a task particularly difficult. To support developers in this kind of comprehension task, filtering and aggregation have long been suggested as key enabling strategies. Unfortunately, traditional approaches typically only provide a uniform level of aggregation, thus limiting the ability of developers to construct context-dependent representations of a program\u2019s execution. In this paper, we propose a localised approach to navigate and analyse the CPU usage of little-known programs and libraries. Our method exploits the structural information present in profiling call trees to selectively raise or lower the local abstraction level of the performance data. We explain the formalism underpinning our approach, describe a prototype, and present a preliminary user study that shows our tool has the potential to complement more traditional navigation approaches.",
        "acmid": "1879228",
        "address": "New York, NY, USA",
        "author": "Lin, Shen and Ta\\\"{i}ani, Fran\\c{c}ois and Ormerod, Thomas C. and Ball, Linden J.",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879228",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, context: software, subcontext: callgraph, vis: node-link, vis: indented tree, vis: aggregation, parallel scale: NR",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "103--112",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Towards Anomaly Comprehension: Using Structural Compression to Navigate Profiling Call-trees",
        "type": "InProceedings",
        "year": "2010"
    },
    "Liu2013HPCToolkit": {
        "abstract": "It is difficult to manually identify opportunities for enhanc- ing data locality. To address this problem, we extended the HPCToolkit performance tools to support data-centric pro- filing of scalable parallel programs. Our tool uses hardware counters to directly measure memory access latency and at- tributes latency metrics to both variables and instructions. Different hardware counters provide insight into different as- pects of data locality (or lack thereof). Unlike prior tools for data-centric analysis, our tool employs scalable measure- ment, analysis, and presentation methods that enable it to analyze the memory access behavior of scalable parallel pro- grams with low runtime and space overhead. We demon- strate the utility of HPCToolkit\u2019s new data-centric analysis capabilities with case studies of five well-known benchmarks. In each benchmark, we identify performance bottlenecks caused by poor data locality and demonstrate non-trivial performance optimizations enabled by this guidance.",
        "acmid": "2503297",
        "address": "New York, NY, USA",
        "articleno": "28",
        "author": "Liu, Xu and Mellor-Crummey, John M.",
        "booktitle": "Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis",
        "doi": "10.1145/2503210.2503297",
        "isbn": "978-1-4503-2378-9",
        "keywords": "type: research, name: HPCToolkit, context: software, vis: code, subcontext: calltree, vis: indented tree, parallel scale: 10",
        "location": "Denver, Colorado",
        "numpages": "12",
        "pages": "28:1--28:12",
        "publisher": "ACM",
        "series": "SC",
        "title": "A Data-centric Profiler for Parallel Programs",
        "type": "InProceedings",
        "year": "2013"
    },
    "Maletic2002Survey": {
        "abstract": "A number of taxonomies to classify and categorize software visualization systems have been proposed in the past. Most notable are those presented by Price [1993] and Roman [1993]. While these taxonomies are an accurate representation of software visualization issues, they are somewhat skewed with respect to current research areas on software visualization. We revisit this important work and propose a number of realignments with respect to addressing the software engineering tasks of large-scale development and maintenance. We propose a framework to emphasize the general tasks of understanding and analysis during development and maintenance of large-scale software systems. Five dimensions relating to the what, where, how, who, and why of software visualization make up this framework. The focus of this work is not so much as to classify software visualization system, but to point out the need for matching the method with the task. Lastly, a number of software visualization systems are examined under our framework to highlight the particular problems each addresses.",
        "author": "Maletic, Jonathan I. and Marcus, Andrian and Collard, Michael L.",
        "booktitle": "Procedings of the First International Workshop on Visualizing Software for Understanding and Analysis",
        "doi": "10.1109/VISSOF.2002.1019792",
        "keywords": "type: survey, context: n/a, subcontext: n/a, parallel scale: n/a, name: n/a, vis: n/a",
        "pages": "32-40",
        "series": "VISSOFT",
        "title": "A task oriented view of software visualization",
        "type": "InProceedings",
        "year": "2002"
    },
    "Malony1991Traceview": {
        "abstract": "The design, development, and application of Traceview, a general-purpose trace-visualization tool that implements the trace-management and I/O features usually found in special-purpose trace-analysis systems, are described. The aspects of trace visualization that can be incorporated into a reusable tool are identified. The tradeoff in general-purpose design versus semantically based, detailed trace-data analysis is evaluated. Display methods and Traceview applications are discussed.",
        "author": "Malony, Allen D. and Hammerslag, David H. and Jablonowski, David J.",
        "doi": "10.1109/52.84213",
        "issn": "0740-7459",
        "journal": "IEEE Software",
        "keywords": "type: research, name: Traceview, context: tasks, subcontext: trace, vis: Gantt, vis: time series, parallel scale: 10",
        "number": "5",
        "pages": "19-28",
        "series": "IEEE Software",
        "title": "Traceview: a trace visualization tool",
        "type": "ARTICLE",
        "volume": "8",
        "year": "1991"
    },
    "Maoz2007Tracer": {
        "author": "Maoz, Shahar and Kleinbort, Asaf and Harel, David",
        "booktitle": "IEEE Symposium on Visual Languages and Human-Centric Computing",
        "doi": "10.1109/VLHCC.2007.27",
        "keywords": "type: research, context: software, subcontext: trace, vis: Gantt, vis: sequence diagram, vis: logical time, vis: contours, name: Tracer",
        "month": "sep,",
        "pages": "153--156",
        "series": "VL/HCC",
        "title": "Towards Trace Visualization and Exploration for Reactive Systems",
        "type": "InProceedings",
        "year": "2007"
    },
    "McCarthy2014Boxfish": {
        "abstract": "Understanding the interactions between a parallel application and the interconnection network over which it exchanges data is critical to optimizing performance in modern supercomputers. However, recent supercomputing architectures use networks that do not have natural low-dimensional representations, making them difficult to comprehend or visualize. In particular, high-dimensional torus networks are common and are used in four of the top ten supercomputers and eight of the top ten on the Graph500 list. We present a new visualization of five-dimensional torus networks. We use four connected views depicting the network at different levels of detail, allowing analysts to observe general large-scale traffic patterns while simultaneously viewing individual links or outliers in any specific section of the network. We demonstrate this approach by analyzing network traffic for a pF3D simulation running on the IBM Blue Gene/Q architecture, and show how it is both intuitive and effective for understanding and optimizing parallel application behavior.",
        "author": "McCarthy, Collin M. and Isaacs, Katherine E. and Bhatele, Abhinav and Bremer, Peer-Timo and Hamann, Bernd",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.10",
        "keywords": "type: research, context: hardware, subcontext: network, name: Boxfish, vis: slicing, vis: projection, subcontext: torus, subcontext: 5d torus, vis: multiple coordinated views, parallel scale: 1k",
        "month": "Nov",
        "pages": "24 -- 27",
        "series": "VPA",
        "title": "Visualizing the Five-dimensional Torus Network of the {IBM Blue Gene/Q}",
        "type": "InProceedings",
        "year": "2014"
    },
    "Meyer2016": {
        "abstract": "Stored procedures are used in database systems to process and aggregate data. Hundreds of stored procedures often form a complex process network with documented and hidden dependencies that is difficult to understand, maintain, and debug. This paper introduces a novel approach to support such tasks by visually comparing a specific process run to other runs of the same process.  The visualization is based on a force-directed node-link diagram arranged on a timeline. Color coding, histograms, and trend charts are used to highlight temporal deviations. The approach has been imple- mented as an interactive web application and used by professional database developers for solving realistic maintenance and debugging tasks. The feedback of these expert users confirms the usefulness and practical relevance of the approach.",
        "author": "Meyer, Matthias and Beck, Fabian and Lohmann, Steffen",
        "booktitle": "Proceedings of the 2016 IEEE Pacific Visualization Symposium",
        "keywords": "type: research, context: tasks, subcontext: databases, vis: Gantt, vis: timelines, vis: histogram, vis: multiple coordinated views, vis: filtering, vis: aggregation",
        "series": "PacificVis",
        "title": "Visual Monitoring of Process Runs: An Application Study for Stored Procedures",
        "type": "InProceedings",
        "year": "2016"
    },
    "Miller1993": {
        "author": "Miller, Barton P.",
        "doi": "10.1006/jpdc.1993.1063",
        "issn": "0743-7315",
        "journal": "Journal of Parallel and Distributed Computing",
        "keywords": "type: position, subcontext: n/a, vis: n/a, context: n/a, parallel scale: n/a, name: n/a",
        "number": "2",
        "pages": "265 - 269",
        "series": "JPDC",
        "title": "What to Draw? When to Draw? An Essay on Parallel Program Visualization",
        "type": "article",
        "volume": "18",
        "year": "1993"
    },
    "Mohr2003Kojak": {
        "abstract": "Today\u2019s parallel computers with SMP nodes provide both multithreading and message passing as their modes of parallel execution. As a consequence, performance analysis and optimization becomes more difficult and creates a need for advanced performance tools that are custom made for this class of computing environments. Current state-of-the-art tools provide valuable assistance in analyzing the performance of mpi and Openmp programs by visualizing the run-time behavior and calculating statistics over the performance data. However, the developer of parallel programs is still required to filter out relevant parts from a huge amount of low-level information shown in numerous displays and map that information onto program abstractions without tool support. The kojak project (Kit for Objective Judgement and Knowledge-based Detection of Performance Bottlenecks) is aiming at the development of a generic automatic performance analysis environment for parallel programs. Performance problems are specified in terms of execution patterns that represent situations of inefficient behavior. These patterns are input for an analysis process that recognizes and quantifies the inefficient behavior in event traces. Mechanisms that hide the complex relationships within event pattern specifications allow a simple description of complex inefficient behavior on a high level of abstraction. The analysis process transforms the event traces into a three-dimensional representation of performance behavior. The first dimension is the kind of behavior. The second dimension describes the behavior\u2019s source-code location and the execution phase during which it occurs. Finally, the third dimension gives information on the distribution of performance losses across different processes or threads. The hierarchical organization of each dimension enables the investigation of performance behavior on varying levels of granularity. Each point of the representation is uniformly mapped onto the corresponding fraction of execution time, allowing the convenient correlation of different behavior using only a single view. In addition, the set of predefined performance problems can be extended to meet individual (e.g., application-specific) needs.",
        "author": "Mohr, Bernd and Wolf, Felix",
        "booktitle": "Euro-Par 2003 Parallel Processing",
        "doi": "10.1007/978-3-540-45209-6_177",
        "editor": "Kosch, Harald and B\u00f6sz\u00f6rm\u00e9nyi, L\u00e1szl\u00f3 and Hellwagner, Hermann",
        "isbn": "978-3-540-40788-1",
        "keywords": "type: research, name: KOJAK, name: Scalasca, context: software, subcontext: callgraph, vis: indented tree",
        "pages": "1301-1304",
        "publisher": "Springer Berlin Heidelberg",
        "series": "Lecture Notes in Computer Science",
        "title": "KOJAK - A Tool Set for Automatic Performance Analysis of Parallel Programs",
        "type": "InCollection",
        "volume": "2790",
        "year": "2003"
    },
    "Moreta2007": {
        "abstract": "We present a visualization tool for dynamic memory allocation information btained from instrumenting the runtime allocator used by C programs. The goal of the presented visualization techniques is to convey insight in the dynamic behavior of the allocator The purpose is to help the allocator designers understand how the performance and working of the allocator depend on the actual allocation scenarios in order to optimize itsfunctionality by decreasing fragmentation and improving response time. We use an orthogonal dense pixel layout of time versus memory space which can show tens of thousands of allocation events on a single screen. We enhance the basic idea with several new techniques: antialiased metric bars for detecting high and low activity areas; cushion cursors for checking correlations of multiple views; and a view toshow correlation between program structure (functions) and memory allocations. The presented techniques are demonstrated on data from a real application.",
        "author": "Moreta, Sergio and Telea, Alexandru",
        "booktitle": "4th IEEE International Workshop on Visualizing Software for Understanding and Analysis",
        "doi": "10.1109/VISSOF.2007.4290697",
        "keywords": "type: research, context: hardware, subcontext: memory, subcontext: trace, subcontext: memory trace, vis: timelines, vis: cushions, parallel scale: N/A",
        "pages": "31-38",
        "series": "VISSOFT",
        "title": "Visualizing Dynamic Memory Allocations",
        "type": "InProceedings",
        "year": "2007"
    },
    "Moritz2015Perfopticon": {
        "abstract": "Distributed database performance is often unpredictable due to issues such as system complexity, network congestion, or imbalanced data distribution. These issues are difficult for users to assess in part due to the opaque mapping between declaratively-specified queries and actual physical execution plans. Database developers currently must expend significant time and effort scanning log files to isolate and debug the root causes of performance issues. In response, we present Perfopticon, an interactive query profiling tool that enables rapid insight into common problems such as performance bottlenecks and data skew. Perfopticon combines interactive visualizations of (1) query plans, (2) overall query execution, (3) data flow among servers, and (4) execution traces. These views coordinate multiple levels of abstraction to enable detection, isolation, and understanding of performance issues. We evaluate our design choices through engagements with system developers, scientists, and students. We demonstrate that Perfopticon enables performance debugging for real-world tasks. ,",
        "author": "Moritz, Dominik and Halperin, Daniel and Howe, Bill and Heer, Jeffrey",
        "booktitle": "Proceedings of EuroVis",
        "keywords": "type: research, context: tasks, subcontext: databases, vis: matrix, vis: multiple coordinated views, vis: hierarchical, vis: node-link, vis: timelines, name: Perfopticon",
        "number": "3",
        "publisher": "Computer Graphics Forum",
        "series": "EuroVis",
        "title": "{Perfopticon}: Visual Query Analysis for Distributed Databases",
        "type": "InProceedings",
        "volume": "34",
        "year": "2015"
    },
    "Mu2003": {
        "abstract": "Optimizing the performance of shared-memory NUMA programs remains something of a black art, requiring that application writers possess deep understanding of their programs\u2019 behaviors. This difficulty represents one of the remaining hindrances to the widespread adoption and deployment of these cost-efficient and scalable shared-memory NUMA architectures. To address this problem, we have developed a performance monitoring infrastructure and a corresponding set of tools to aid in visualizing and understanding the subtleties of the memory access behavior of parallel NUMA applications with large datasets. The tools are designed to be general, interoperable, and easily portable. We give detailed examples of the use of one particular tool in the set. We have used this memory access visualization tool profitably on a range of applications, improving performance by around 90\\%, on average.",
        "acmid": "774853",
        "address": "New York, NY, USA",
        "author": "Mu, Tao and Tao, Jie and Schulz, Martin and McKee, Sally A.",
        "booktitle": "Proceedings of the 2003 ACM Symposium on Software Visualization",
        "doi": "10.1145/774833.774853",
        "isbn": "1-58113-642-0",
        "keywords": "type: research, context: hardware, subcontext: memory, vis: 3D, vis: 1D array, vis: matrix, vis: bar charts, parallel scale: 1K",
        "location": "San Diego, California",
        "pages": "133--ff",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Interactive Locality Optimization on NUMA Architectures",
        "type": "InProceedings",
        "year": "2003"
    },
    "Muelder2009": {
        "abstract": "In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.",
        "address": "Los Alamitos, CA, USA",
        "author": "Muelder, Chris and Gygi, Francois and Ma, Kwan-Liu",
        "doi": "10.1109/TVCG.2009.196",
        "issn": "1077-2626",
        "journal": "IEEE Transactions on Visualization and Computer Graphics, Proceedings of InfoVis",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: timelines, vis: opacity scaling, parallel scale: 10K",
        "number": "6",
        "pages": "1129-1136",
        "publisher": "IEEE Computer Society",
        "series": "InfoVis",
        "title": "Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing",
        "type": "article",
        "volume": "15",
        "year": "2009"
    },
    "Muelder2011": {
        "abstract": "As supercomputers grow ever larger, so too do application run times and data requirements. The operational patterns of modern parallel I/O systems are far too complex to allow for a direct analysis of their trace logs. Several visualization methods have therefore been developed to address this issue. Traditional, direct visualizations of parallel systems, such as Gantt charts, can be applied to parallel file systems, but do they not capture domain specific properties nor scale up to modern systems. We propose a portable I/O tracing system and visualization methods to analyze the traces we have obtained. We demonstrate the effectiveness of this system on existing parallel storage systems.",
        "acmid": "1996036",
        "address": "New York, NY, USA",
        "author": "Muelder, Chris and Sigovan, Carmen and Ma, Kwan-Liu and Cope, Jason and Lang, Sam and Iskra, Kamil and Beckman, Pete and Ross, Robert",
        "booktitle": "Proceedings of the Third International Workshop on Large-scale System and Application Performance",
        "doi": "10.1145/1996029.1996036",
        "isbn": "978-1-4503-0703-1",
        "keywords": "type: research, context: tasks, context: hardware, subcontext: trace, vis: timelines, vis: fisheye, subcontext: I/O, vis: opacity scaling, vis: matrix, parallel scale: 1K",
        "location": "San Jose, California, USA",
        "numpages": "8",
        "pages": "19--26",
        "publisher": "ACM",
        "series": "LSAP",
        "title": "Visual Analysis of I/O System Behavior for High-end Computing",
        "type": "InProceedings",
        "year": "2011"
    },
    "Muelder2016": {
        "abstract": "Cloud computing is an essential technology to Big Data analytics and services. A cloud computing system is often comprised of a large number of parallel computing and storage devices. Monitoring the usage and performance of such a system is important for efficient operations, maintenance, and security. Tracing every application on a large cloud system is untenable due to scale and privacy issues. But profile data can be collected relatively efficiently by regularly sampling the state of the system, including properties such as CPU load, memory usage, network usage, and others, creating a set of multivariate time series for each system. Adequate tools for studying such large-scale, multidimensional data are lacking. In this paper, we present a visual based analysis approach to understanding and analyzing the performance and behavior of cloud computing systems. Our design is based on similarity measures and a layout method to portray the behavior of each compute node over time. When visualizing a large number of behavioral lines together, distinct patterns often appear suggesting particular types of performance bottleneck. The resulting system provides multiple linked views, which allow the user to interactively explore the data by examining the data or a selected subset at different levels of detail. Our case studies, which use datasets collected from two different cloud systems, show that this visual based approach is effective in identifying trends and anomalies of the systems.",
        "author": "Muelder, Chris and Zhu, Biao and Chen, Wei and Zhang, Hongxin and Ma, Kwan-Liu",
        "doi": "10.1109/TVCG.2016.2534558",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "keywords": "type: research, context: tasks, subcontext: cloud, vis: time series, vis: story lines, vis: stacked area chart, vis: signal processing, vis: visual clustering, vis: multiple coordinated views, parallel scale: 1k",
        "series": "TVCG",
        "title": "Visual Analysis of Cloud Computing Performance Using Behavioral Lines",
        "type": "ARTICLE",
        "year": "2016"
    },
    "Myers2010": {
        "abstract": "Visual representations of runtime software structures such as heap memory graphs can aid in debugging and help to develop program understanding. However, such structures may contain thousands of objects and have no obvious spatial organisation. If the program contains flaws the appearance of objects may well differ from the user\u2019s expectations. Navigating these graphs can be challenging to the user as the space is abstract and potentially unfamiliar. To alleviate this problem we employ a systematic approach grounded in the principles of navigational landmarks. We identify subgraphs within the heap that correspond to significant design abstractions and apply various visualization techniques to highlight and organise these structures. The aim is to provide the user with recognisable features that are linked to more familiar representations of the software. We claim that the enhanced representation can sup- port existing memory debugging tools by providing the user with a usable \u2019map\u2019 of an otherwise abstract data space. The results are demonstrated using data extracted from an instrumented version of the Visualization Tool Kit (VTK), a complex and widely-used architecture for data visualization.",
        "acmid": "1879223",
        "address": "New York, NY, USA",
        "author": "Myers, Colin and Duke, David",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879223",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, context: hardware, subcontext: heap, subcontext: debugging, vis: node-link, vis: tree-layout, vis: contours, parallel scale: N/A",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "63--72",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "A Map of the Heap: Revealing Design Abstractions in Runtime Structures",
        "type": "InProceedings",
        "year": "2010"
    },
    "Nagel1996": {
        "author": "Nagel, Wolfgang E. and Arnold, Alfred and Weber, Michael and Hoppe, Hans-Christian and Solchenbach, Karl",
        "journal": "Supercomputer",
        "keywords": "type: research, name: Vampir, context: tasks, subcontext: trace, vis: timelines, vis: Gantt, subcontext: messages, vis: multiple views, parallel scale: 100",
        "number": "1",
        "pages": "69--80",
        "title": "{VAMPIR}: Visualization and Analysis of {MPI} Resources",
        "type": "article",
        "volume": "12",
        "year": "1996"
    },
    "Nguyen2016VIPACT": {
        "abstract": "Profiling tools are indispensable for performance optimization of parallel codes. They allow users to understand where a code spends its time, and to focus optimization efforts on the most time consuming regions. However, two sources of complexity make them difficult to use on large-scale parallel applications. First, the code complexity of parallel applications is increasingly, and identifying the problematic regions in the code is difficult. Traditional profilers show either a flat view or a calling context tree view. Second, most tools average performance data across processes, losing per-process behavior. Diagnosing problems like load imbalance requires profiles from many processes, and manually analyzing profiles from hundreds or thousands of processes is infeasible. We introduce VIPACT, a visualization tool to identify different behaviors in multiple processes. VIPACT introduces \u201chalo nodes\u201d that concisely encode the distributions of runtimes from all processes, and a hybrid tree view that combines the advantages of calling context trees with those of flat profiles. We combine these with approaches such as ring charts, as well as the filtering and subselection of nodes, and we apply these techniques to a production multi-physics code.",
        "author": "Nguyen, Huu Tan and Wei, Lai and Bhatele, Abhinav and Gamblin, Todd and Boehme, David and Schulz, Martin and Ma, Kwan-Liu and Bremer, Peer-Timo",
        "booktitle": "Proceedings of the Third International Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2016.9",
        "keywords": "type: research, context: software, subcontext: callgraph, vis: tree, vis: glyphs, vis: node-link, vis: histograms, name: VIPACT",
        "pages": "25--28",
        "series": "VPA",
        "title": "{VIPACT}: a visualization interface for analyzing calling context trees",
        "type": "inproceedings",
        "year": "2016"
    },
    "Osmari2014SmartTraces": {
        "abstract": "Most performance analysis tools focus on presenting an overload of details, with little application-dependent structure, and predefined statistical summaries. This makes the complex relations present in a parallel program not directly recognizable to the user, making the task of identifying performance issues more costly in both time and effort. In this work we investigate the requirements to create visualizations of execution traces of parallel programs modeled as dataflows. We propose the Smart Trace (ST) concept, to encode the structure of the data, and guide the construction of specialized visualizations. A visualization tool can then leverage the relationships in the data to automate a given analysis task. We show with examples the power and flexibility of visualizations we can create to address specific questions formulated about the analysis of the data, with emphasis in parallel dataflow traces.",
        "author": "Osmari, Daniel K. and Vo, Huy T. and Silva, Claudio T. and Comba, Joao L.D. and Lins, Lauro",
        "booktitle": "2014 27th SIBGRAPI Conference on Graphics, Patterns and Images",
        "doi": "10.1109/SIBGRAPI.2014.2",
        "keywords": "type: research, context: tasks, context: hardware, subcontext: trace, name: Smart Traces (ST), subcontext: heterogenous, vis: gantt, vis: node-link, vis: scatterplots, vis: multiple coordinated views, vis: timelines, parallel scale: 100",
        "month": "Aug",
        "pages": "165-172",
        "series": "SIBGRAPI",
        "title": "Visualization and Analysis of Parallel Dataflow Execution with Smart Traces",
        "type": "InProceedings",
        "year": "2014"
    },
    "Paje2000": {
        "abstract": "This paper describes Paje, an interactive visualization tool for displaying the execution of parallel applications where a potentially large number of communicating threads of various life-times execute on each node of a distributed memory parallel system. Paje is capable of representing a wide variety of interactions between threads. The main characteristics of Paje, interactivity and scalability, are exempli\u00aeed by the performance tuning of a molecular dynamics application. In order to be easily extensible, the architecture of the system was based on components which are connected in a data flow graph to produce a given visualization tool. Innovative components were designed, in addition to ``classical'' components existing in similar visualization systems, to support scalability and interactivity.",
        "acmid": "357838",
        "address": "Amsterdam, The Netherlands, The Netherlands",
        "author": "Chassin de Kergommeaux, Jacques and de Oliveira Stein, Benhur and Bernard, P.E.",
        "doi": "10.1016/S0167-8191(00)00010-7",
        "issn": "0167-8191",
        "issue_date": "Sept. 2000",
        "journal": "Parallel Computing",
        "keywords": "type: research, name: Paje, context: tasks, subcontext: trace, subcontext: messages, vis: Gantt, vis: timelines, subcontext: threads, subcontext: semaphores, vis: pie charts, parallel scale: 100",
        "month": "sep,",
        "number": "10",
        "numpages": "22",
        "pages": "1253--1274",
        "publisher": "Elsevier Science Publishers B. V.",
        "series": "Parallel Computing",
        "title": "{Paje}, an Interactive Visualization Tool for Tuning Multi-threaded Parallel Applications",
        "type": "article",
        "volume": "26",
        "year": "2000"
    },
    "Pancake1989": {
        "abstract": "The complexity of parallel programming has stimulated the development of a variety of debugging tools. This survey of recent research focuses on debugger visualization systems. The effectiveness of such systems is bounded by the degree to which their representations of runtime behavior correlate with the language structures used to incorporate parallelism, as well as the logical framework adopted by the programmer. Current visualization systems are compared with the conceptual models supported by parallel languages. Attention is drawn to the fact that debuggers are tied to specific models and that this association may restrict their usefulness and acceptability.",
        "acmid": "76334",
        "author": "Pancake, Cherri M. and Utter, Sue",
        "booktitle": "Proceedings of the 1989 ACM/IEEE Conference on Supercomputing",
        "doi": "10.1145/76263.76334",
        "isbn": "0-89791-341-8",
        "keywords": "type: survey, context: n/a, subcontext: debugging, vis: n/a, parallel scale: n/a",
        "numpages": "10",
        "pages": "627--636",
        "publisher": "ACM",
        "series": "SC",
        "title": "Models for Visualization in Parallel Debuggers",
        "type": "InProceedings",
        "year": "1989"
    },
    "Pillet1995": {
        "author": "Pillet, Vincent and Labarta, Jes{\\'u}s and Cortes, Toni and Girona, Sergi",
        "booktitle": "Proceedings of WoTUG-18: Transputer and occam Developments",
        "keywords": "type: research, name: Paraver, context: tasks, subcontext: trace, vis: timelines, vis: Gantt, subcontext: messages",
        "pages": "17--31",
        "title": "Paraver: A tool to visualize and analyze parallel code",
        "type": "InProceedings",
        "volume": "44",
        "year": "1995"
    },
    "Pinto2016": {
        "abstract": "In this paper, we present visual analysis techniques to evaluate the performance of HPC task-based applications on hybrid architectures. Our approach is based on composing modern data analysis tools (pjdump, R, ggplot2, plotly), enabling an agile and flexible scripting framework with minor development cost. We validate our proposal by analyzing traces from the full-fledged implementation of the Cholesky decomposition available in the MORSE library running on a hybrid (CPU/GPU) platform.  The analysis compares two different workloads and three different task schedulers from the StarPU runtime system. Our analysis based on composite views allows to identify allocation mistakes, priority problems in scheduling decisions, GPU tasks anomalies causing bad performance, and critical path issues.",
        "author": "Pinto, Vin{\\'\\i}cius Garcia and Stanisic, Luka and Legrand, Arnaud and Schnorr, Lucas Mello and Thibault, Samuel and Danjean, Vincent",
        "booktitle": "Proceedings of the Third International Workshop on Visual Performance Analysis",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, vis: bar charts, vis: line charts, parallel scale: 10, name: n/a",
        "series": "VPA",
        "title": "Analyzing dynamic task-based applications on hybrid platforms: an agile scripting approach",
        "type": "article",
        "year": "2016"
    },
    "Pisciuneri2013": {
        "abstract": "A new computational methodology, termed \u201cirregularly portioned Lagrangian Monte Carlo--finite difference\u201d (IPLMCFD), is developed for large eddy simulation (LES) of turbulent combustion via the filtered density function (FDF). This is a hybrid methodology which couples a Monte Carlo FDF simulator with a structured Eulerian finite difference LES solver. The IPLMCFD is scalable to thousands of processors; thus it is suited for simulation of complex reactive flows. The scalability and consistency of the hybrid solver and the realizability and reliability of the generated results are demonstrated via LES of several turbulent flames under both nonpremixed and premixed conditions.",
        "author": "Pisciuneri, P. H. and Yilmaz, S. L. and Strakey, P. A. and Givi, P.",
        "doi": "10.1137/130911512",
        "journal": "SIAM Journal on Scientific Computing",
        "keywords": "type: research, context: application, context: tasks, subcontext: simulation, subcontext: CPU time, vis: 3D, vis: projection, vis: volume rendering, vis: bar charts",
        "number": "4",
        "pages": "C438--C452",
        "title": "An Irregularly Portioned {FDF} Simulator",
        "type": "article",
        "volume": "35"
    },
    "Reed1993Pablo": {
        "abstract": "Developers of application codes for massively parallel computer systems face daunting performance tuning and optimization problems that must be solved if massively parallel systems are to fulfill their promise. Recording and analyzing the dynamics of application program, system software, and hardware interactions is the key to understanding and the prerequisite to performance tuning, but this instrumentation and analysis must not unduly perturb program execution. Pablo is a performance analysis environment designed to provide unobtrusive performance data capture, analysis, and presentation across a wide variety of scalable parallel systems. Current efforts include dynamic statistical clustering to reduce the volume of data that must be captured and complete performance data immersion via head-mounted displays",
        "author": "Reed, Daniel A. and Roth, Philip C. and Aydt, Ruth A. and Shields, Keith A. and Tavera, Luis F. and Noe, Roger J. and Schwartz, Bradley W.",
        "booktitle": "Scalable Parallel Libraries Conference, 1993., Proceedings of the",
        "doi": "10.1109/SPLC.1993.365577",
        "keywords": "type: research, name: Pablo, vis: scatterplots, vis: virtual reality, vis: 3D, vis: 4D, vis: scatterplot array",
        "organization": "IEEE",
        "pages": "104--113",
        "title": "Scalable performance analysis: The Pablo performance analysis environment",
        "type": "InProceedings",
        "year": "1993"
    },
    "Reed1995": {
        "abstract": "Recording and analyzing the dynamics of application-program, system-software, and hardware interactions are the keys to understanding and tuning the performance of massively parallel systems. Because such systems contain hundreds or thousands of processors, each potentially with many dynamic performance metrics, the performance data occupies a sparsely populated, high-dimensional space. These dynamic performance metrics define a group of evolving, n-dimensional points. Understanding the dynamic \"shape\" of the metric movement is possible only if multiple, lower dimensional projections can be examined. The authors have implemented an immersive virtual world, called Avatar, that shows all possible three-dimensional projections of a sparsely populated, n-dimensional metric space. The presentation metaphor is a three-dimensional generalization of a two-dimensional scatterplot matrix. Users can move about scatterplot cubes, control selected characteristics of the scatterplot display, listen to the sounds of statistical data attributes, and interactively modify application behavior and performance in real time.",
        "author": "Reed, Daniel A. and Shields, Keith A. and Scullin, Will H. and Tavera, Luis F. and Elford, Christopher L.",
        "doi": "10.1109/2.471180",
        "issn": "0018-9162",
        "journal": "Computer",
        "keywords": "type: research, name: Pablo, vis: virtual reality, vis: 3D, vis: scatterplots, vis: scatterplot cubes, parallel scale: 100",
        "number": "11",
        "pages": "57-67",
        "title": "Virtual reality and parallel systems performance analysis",
        "type": "ARTICLE",
        "volume": "28",
        "year": "1995"
    },
    "Reilly1990": {
        "abstract": "The paper describes the performance analysis tools developed for Digital Equipment Corporation\u2019s experimental multiprocessor, M31. The tools allow a user to instrument an application, monitor its execution, and analyze the collected event traces. The analysis and presentation tools afford the user a view of the application\u2019s dynamic call tree as well as the flow of control within and between cooperating processes. The paper describes the trajectory of a scientific application through the performance debugging process. Experience with the tools indicates that they can be used to provide insight that results in improved performance of a complex application.",
        "author": "Reilly, Matthew H.",
        "booktitle": "Proceedings of the Twenty-Third Annual Hawaii International Conference on Systems Sciences",
        "doi": "10.1109/HICSS.1990.205129",
        "keywords": "type: research, context: tasks, context: software, subcontext: callgraph, subcontext: trace, vis: icicle timelines, vis: node-link, parallel scale: 1+",
        "pages": "307-313 vol.1",
        "series": "HICSS",
        "title": "Presentation tools for performance visualization: the M31 instrumentation experience",
        "type": "InProceedings",
        "volume": "i",
        "year": "1990"
    },
    "Reinders2005": {
        "author": "Reinders, James",
        "isbn": "9780974364957",
        "keywords": "type: research, name: VTune, vis: multiple views, vis: multiple views",
        "publisher": "Intel Press",
        "series": "Engineer to Engineer Series",
        "title": "VTune Performance Analyzer Essentials: Measurement and Tuning Techniques for Software Developers",
        "type": "Book",
        "year": "2005"
    },
    "Reiss2010Dyview": {
        "abstract": "Modern systems, particularly servers, involve multiple threads dealing with multiple incoming transactions using either implicit or explicit internal tasks. Understanding the inherently complex behavior of such systems can be quite difficult. We present a framework that offers a visualization of this behavior in system-specific terms in real time. The framework is unique in that it uses a combination of program analyses to minimize the work the user needs to do to construct the visualization.",
        "author": "Reiss, Steven P. and Karumuri, Suman",
        "booktitle": "Proceedings of the 9th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering",
        "doi": "10.1145/1806672.1806675",
        "keywords": "type: research, context: tasks, subcontext: trace, subcontext: threads, vis: Gantt, name: Dyview, parallel scale: 1+",
        "pages": "9--16",
        "series": "PASTE",
        "title": "Visualizing Threads, Transactions and Tasks",
        "type": "InProceedings",
        "year": "2010"
    },
    "Renieris1999ALMOST": {
        "abstract": "We built a tool to visualize and explore program execution traces. Our goal was to help programmers without any prior knowledge of a program, quickly get enough knowledge about its structure so that they can make small to medium changes. In the process, a number of problems were faced and tackled concerning the efficient use of screen space, interaction with multiple concurrent views, and linking of asymmetric views",
        "author": "Renieris, Manos and Reiss, Steven P.",
        "booktitle": "1999 Workshop on New Paradigms in Information Visualization and Manipulation",
        "doi": "10.1145/331770.331788",
        "keywords": "type: research, name: ALMOST, context: software, subcontext: trace, vis: icicle timelines, vis: spiral, parallel scale: N/A",
        "pages": "70-77",
        "publisher": "ACM",
        "title": "{ALMOST}: Exploring program traces",
        "type": "InProceedings",
        "year": "1999"
    },
    "Roberts2005": {
        "abstract": "This paper describes TraceVis, a tool for graphically exploring application behavior as it relates to its execution on a microprocessor. Because the human mind can process enormous amounts of visual data\u2013readily identifying trends and patterns -- such a tool facilitates performance analysis by allowing raw data to be inspected rather than summaries of pre-selected characteristics. To this end, TraceVis has been designed to enable interactive navigation of many kinds data useful for studying performance problems including: relating the execution to disassembly and high-level language code, annotating the program trace with events (e.g., branch mispredictions and cache misses), and tracing instruction dependencies. In addition, TraceVis provides mechanisms for searching in traces and annotating traces (to Bookmark areas of interest or mark regions previously characterized) to allow an analyst to focus their attention on the desired behaviors and regions. Along with exhibiting TraceVis\u2019s features, this paper demonstrates how these features can be used in conjunction to analyze the performance of a simulated microprocessor\u2019s execution. TraceVis is available in source form for non-commercial use [1].",
        "author": "\t{Roberts, James and Zilles, Craig",
        "booktitle": "MoBS '05",
        "keywords": "type: research, name: TraceVis, context: software, subcontext: trace, vis: code, subcontext: instructions, parallel scale: 1+",
        "title": "\t{TraceVis: An Execution Trace Visualization Tool",
        "type": "InProceedings",
        "year": "\t{2005"
    },
    "Robertson2010": {
        "abstract": "A program\u201fs memory system performance is one of the key determinants of its overall performance. Lack of understanding of a program\u201fs memory system behavior can lead to performance problems, the most common being memory fragmentation and memory leaks. In this paper, we present AllocRay, a visualization that animates memory allocation event trace information over a time period of execution of a program. Various modes of display with custom color mappings and zooming allow the programmer to see how heaps are used over time (by allocation type, age, size, or thread id). Custom displays also allow the programmer to quickly detect potential memory leaks and fragmentation problems. Composable filters enable the programmer to focus on specific issues. We describe the techniques used to enable processing of a huge number of trace events while enabling rapid response to visualization view changes. We also describe informal interviews with four expert programmers to examine the usability of the AllocRay design.",
        "acmid": "1879221",
        "author": "Robertson, George G. and Chilimbi, Trishul and Lee, Bongshin",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879221",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research,name: AllocRay, context: hardware, subcontext: memory, vis: filtering, vis: timelines, parallel scale: N/A",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "43--52",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "AllocRay: Memory Allocation Visualization for Unmanaged Languages",
        "type": "InProceedings",
        "year": "2010"
    },
    "Rosen2013": {
        "abstract": "We present an approach to investigate the memory behavior of a parallel kernel executing on thousands of threads simultaneously within the CUDA architecture. Our top-down approach allows for quickly identifying any significant differences between the execution of the many blocks and warps. As interesting warps are identified, we allow further investigation of memory behavior by visualizing the shared memory bank conflicts and global memory coalescence, first with an overview of a single warp with many operations and, subsequently, with a detailed view of a single warp and a single operation. We demonstrate the strength of our approach in the context of a parallel matrix transpose kernel and a parallel 1D Haar Wavelet transform kernel.",
        "author": "Rosen, Paul",
        "booktitle": "Computer Graphics Forum ({EuroVis})",
        "doi": "10.1111/cgf.12103",
        "keywords": "type: research, context: hardware, subcontext: memory, subcontext: GPUs, subcontext: threads, context: tasks, parallel scale: 100",
        "number": "3",
        "series": "EuroVis",
        "title": "A Visual Approach to Investigating Shared and Global Memory Behavior of {CUDA} Kernels",
        "type": "InProceedings",
        "volume": "32",
        "year": "2013"
    },
    "Ross2016": {
        "abstract": "Parallel discrete-event simulation (PDES) is an important tool in the codesign of extreme-scale systems because PDES provides a cost-effective way to evaluate designs of high-performance computing systems. Optimistic synchronization algorithms for PDES, such as Time Warp, allow events to be processed without global synchronization among the processing elements. A rollback mechanism is provided when events are processed out of timestamp order. Although optimistic synchronization protocols enable the scalability of large-scale PDES, the performance of the simulations must be tuned to reduce the number of rollbacks and provide an improved simulation runtime. To enable efficient large-scale optimistic simulations, one has to gain insight into the factors that affect the rollback behavior and simulation performance. We developed a tool for ROSS model developers that gives them detailed metrics on the performance of their large-scale optimistic simulations at varying levels of simulation granularity. Model developers can use this information for parameter tuning of optimistic simulations in order to achieve better runtime and fewer rollbacks. In this work, we instrument the ROSS optimistic PDES framework to gather detailed statistics about the simulation engine. We have also developed an interactive visualization interface that uses the data collected by the ROSS instrumentation to understand the underlying behavior of the simulation engine. The interface connects real time to virtual time in the simulation and provides the ability to view simulation data at different granularities. We demonstrate the usefulness of our framework by performing a visual analysis of the dragonfly network topology model provided by the CODES simulation framework built on top of ROSS. The instrumentation needs to minimize overhead in order to accurately collect data about the simulation performance. To ensure that the instrumentation does not introduce unnecessary overhead, we perform a scaling study that compares instrumented ROSS simulations with their noninstrumented counterparts in order to determine the amount of perturbation when running at different simulation scales.",
        "author": "Ross, Caitlin and Carothers, Christopher D and Mubarak, Misbah and Carns, Philip and Ross, Robert and Li, Jianping Kelvin and Ma, Kwan-Liu",
        "booktitle": "Proceedings of the 7th International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computing Systems",
        "doi": "10.1109/PMBS.2016.14",
        "keywords": "type: research, context: hardware, subcontext: simulation, subcontext: trace, subcontext: dragonfly, subcontext: commgraph, vis: parallel coordinates, vis: chord diagram, vis: node-link, vis: scatterplots, parallel scale: 1k, naem: n/a",
        "pages": "87--97",
        "series": "PMBS",
        "title": "Visual data-analytics of large-scale parallel discrete-event simulations",
        "type": "inproceedings",
        "year": "2016"
    },
    "Rover1992": {
        "abstract": "Observing the activities of a complex parallel computer system is no small feat, and relating these observations to program behavior is even harder: In this paper, we present a general measurement approach that is applicable to a large class of scalable programs and machines, specifically data parallel programs executing on distributed memory computer systems. The combined instrumentation and visualization paradigm, called VISTA, is based on our experiences programming and monitoring applications running on an nCUBE 2 computer and a MasPar MP-1 computer. The key is that performance data are treated similar to any distributed data in the context of the data parallel programming model. Because of the data-parallel mapping of program onto machine, we can view the performance as it relates to each processor, processor cluster; or the processor ensemble and as it relates to the data structures of the program. We illustrate the utility of VISTA by example.",
        "author": "Rover, Diane T.",
        "booktitle": "Proceedings of the Twenty-Fifth Hawaii International Conference on Systems Sciences",
        "doi": "10.1109/HICSS.1992.183288",
        "keywords": "type: research, name: VISTA, name: ParaGraph, context: tasks, context: hardware, vis: statistical plots, vis: timelines, subcontext: messages, vis: small multiples, parallel scale: 10",
        "pages": "149-160 vol.2",
        "series": "HICSS",
        "title": "A performance visualization paradigm for data parallel computing",
        "type": "InProceedings",
        "volume": "ii",
        "year": "1992"
    },
    "Sambasivan2013": {
        "abstract": "Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system\u2019s many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.",
        "author": "Sambasivan, Raja R. and Shafer, Ilari and Mazurek, Michelle L. and Ganger, Gregory R.",
        "doi": "10.1109/TVCG.2013.233",
        "issn": "1077-2626",
        "journal": "IEEE Transactions on Visualization and Computer Graphics, Proceedings of InfoVis",
        "keywords": "type: research, context: software, subcontext: trace, type: technique comparison, vis: timelines, vis: animation, vis: ensemble",
        "number": "12",
        "pages": "2466-2475",
        "series": "InfoVis",
        "title": "Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems",
        "type": "ARTICLE",
        "volume": "19",
        "year": "2013"
    },
    "Sarukkai1993SIEVE": {
        "abstract": "This paper describes a new approach to designing performance analysis tools for parallel processing systems. A primary contribution of this work is to explore the way in which application source code structure can be incorporated into an interactive, programmable event trace analyzer. Event histories are organized as a temporal, relational data base. The user interface is based on a simple two dimensional spreadsheet metaphor that provides a direct and flexible view of the data base and also provides a simple but powerful interactive graphics facility.",
        "acmid": "163538",
        "author": "Sarukkai, Sekhar R. and Gannon, Dennis",
        "doi": "10.1006/jpdc.1993.1053",
        "issn": "0743-7315",
        "issue_date": "June 1993",
        "journal": "Journal of Parallel and Distributed Computing",
        "keywords": "type: research, name: SIEVE, context: tasks, subcontext: trace, vis: timelines, vis: contours, vis: tables, vis: code, vis: bar charts, vis: pie charts, vis: multiple views, parallel scale: 10",
        "month": "jun,",
        "number": "2",
        "numpages": "22",
        "pages": "147--168",
        "publisher": "Academic Press, Inc.",
        "series": "JPDC",
        "title": "{SIEVE}: A Performance Debugging Environment for Parallel Programs",
        "type": "article",
        "volume": "18",
        "year": "1993"
    },
    "Schaubschlager2003DeWiz": {
        "abstract": "Due to the increased complexity of parallel and distributed programs, debugging of them is considered to be the most difficult and time consuming part of the software lifecycle. Tool support is hence a crucial necessity to hide complexity from the user. However, most existing tools seem inadequate as soon as the program under consideration exploits more than a few processors over a long execution time. This problem is addressed by the novel debugging toolDeWiz (DebuggingWizard),whose focus lies on scalability.DeWiz has a modular, scalable architecture, and uses the event graph model as a representation of the investigated program. DeWiz provides a set of modules, which can be combined to generate, analyze, and visualize event graph data.Within this processing pipeline the toolset tries to extract useful information,which is presented to the user at an arbitrary level of abstraction. Additionally, DeWiz is a framework, which can be used to easily implement arbitrary user-defined modules.",
        "author": "Schaubschl\\\"{a}ger, C. and Kranzlm\\\"{u}ller, D. and Volkert, J.",
        "booktitle": "Proceedings of the Fifth International Workshop on Automated Debugging AADEBUG2003",
        "keywords": "type: research, name: DeWiz, context: tasks, subcontext: trace, vis: logical time, subcontext: messages, vis: timelines",
        "series": "AADEBUG",
        "title": "Event-based Program Analysis with {DeWiz}",
        "type": "InProceedings",
        "year": "2003"
    },
    "Schmitt2014": {
        "abstract": "One of the challenges for the developer of highly-parallel MPI applications running on distributed high performance computing systems is to understand the complex behavior of their applications. It requires to identify inefficiencies, and to optimize them such that communication waiting times can be reduced. This task can only be accomplished with the help of elaborated tools that provide insight into the details of the application using an automatic analysis or an intuitive visualization approach. While the first can only target a specific problem domain, the latter allows humans to discuss performance problems with a broader view and from multiple perspectives. We present a new visualization technique for performance data of MPI applications based on circular hierarchies. It intuitively presents communication patterns and allows developers to cor- relate those with arbitrary performance metrics. A hierarchy- aware layout increases scalability and helps to identify commu- nication inefficiencies by analyzing and integrating the system\u2019s hardware topology. We discuss both our approach as well as its integration into the Score-P performance analysis work flow. Its applicability is presented with a real-world use case of the COSMO+SPECS+FD4 climate simulation code.",
        "author": "Schmitt, Felix and Dietrich, Robert and Ku\\ss, Ren\\'e and Doleschal, Jens and Kn\\\"upfer, Andreas",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.5",
        "keywords": "type: research, context: tasks, context: hardware, subcontext: communication, vis: hierarchical, vis: circos, vis: radial, vis: stacked bar charts, vis: scatterplots, vis: heat maps, vis: histograms",
        "month": "Nov",
        "pages": "1 -- 8",
        "series": "VPA",
        "title": "Visualization of Performance Data for {MPI} Applications Using Circular Hierarchies",
        "type": "InProceedings",
        "year": "2014"
    },
    "Schnorr2008": {
        "abstract": "Parallel computing is increasingly used to provide more performance to applications that need tremendous computational power. The main characteristics of distributed parallel machines are heterogeneity, dynamism and size. They influence directly the way the application and platform monitoring tasks are performed, especially when analyzing a large quantity of information collected in a topologically complex machine. This paper describes our efforts to provide parallel programmers and Grid users a new way to visualize monitoring data. Using graphics in three dimensions and information visualization techniques, we aim at bringing rich topological information to the rendered scene. It results in an immersible and human readable representation of complex monitoring data, suited to Grid environments. We first review known techniques in information visu- alization context, especially those that address the case of hierarchical information, and we discuss about their use in our context. Then, we propose a new 3D approach that combines the classical space-time visualization of application traces with the representation of the application\u2019s communication pattern. Finally, we present experimental results obtained through the visualization of parallel applications in our prototype.",
        "author": "Schnorr, Lucas Mello and Huard, Guillaume and Navaux, Philippe O.A.",
        "booktitle": "9th IEEE/ACM International Conference on Grid Computing",
        "doi": "10.1109/GRID.2008.4662804",
        "keywords": "type: research, name: Triva, context: tasks, subcontext: trace, vis: timelines, vis: force-directed, vis: 3D, parallel scale: 100",
        "pages": "233-241",
        "series": "GRID",
        "title": "3D approach to the visualization of parallel applications and Grid monitoring information",
        "type": "InProceedings",
        "year": "2008"
    },
    "Schnorr2010": {
        "abstract": "Parallel applications use grid infrastructures to obtain more performance during their execution. The successful result of these executions depends directly on a performance analysis that takes into account the grid characteristics, such as the network topology and resources location. This paper presents Triva, a software analysis tool that implements a novel technique to visualize the behavior of parallel applications. The proposed technique explores 3D graphics in order to show the application behavior together with a description of the resources, highlighting communication patterns, the net- work topology and a visual representation of a logical organization of the resources. We have used a real grid infrastructure in order to execute and trace applications composed of thousands of processes.",
        "author": "Schnorr, Lucas Mello and Huard, Guillaume and Navaux, Philippe O.A.",
        "doi": "10.1016/j.future.2009.10.006",
        "journal": "Future Generation Computer Systems",
        "keywords": "type: research, name: Triva, context: tasks, subcontext: trace, vis: timelines, vis: force-directed, vis: 3D, vis: treemap, parallel scale: 1K",
        "number": "3",
        "pages": "348 - 358",
        "title": "Triva: Interactive 3D visualization for performance analysis of parallel applications",
        "type": "article",
        "volume": "26",
        "year": "2010"
    },
    "Schnorr2012": {
        "abstract": "The analysis of large-scale parallel applications today has several issues, such as the observation and identification of unusual behavior of processes, expected state of the application, and so on. Performance visualization tools offer a wide spectrum of techniques to visually analyze the monitoring data collected from these applications. The problem is that most of the techniques were not conceived to deal with a high number of processes, in large-scale scenarios. A common example for that is the space\u2013time view, largely used in the performance visualization area, but limited on how much data can be analyzed at the same time. The work presented in this article addresses the problem of visualization scalability in the analysis of parallel applications, through a combination of a temporal integration technique, an aggregation model and treemap representations. Results show that our approach can be used to analyze applications composed of several thousands of processes in large-scale and dynamic scenarios.",
        "author": "Schnorr, Lucas Mello and Huard, Guillaume and Navaux, Philippe O.A.",
        "doi": "j.parco.2011.12.001",
        "journal": "Parallel Computing",
        "keywords": "type: research, name: Triva, context: tasks, subcontext: trace, parallel scale: 100k, vis: treemap, vis: aggregation",
        "number": "3",
        "pages": "91 - 110",
        "series": "Parallel Computing",
        "title": "A hierarchical aggregation model to achieve visualization scalability in the analysis of parallel applications",
        "type": "article",
        "volume": "38",
        "year": "2012"
    },
    "Schulz2011": {
        "abstract": "To exploit the capabilities of current and future systems, developers must understand the interplay between on-node performance, domain decomposition, and an application's intrinsic communication patterns. While tools exist to gather and analyze data for each of these components individually, the resulting information is generally processed in isolation and presented in an abstract, categorical fashion unintuitive to most users. In this paper we present the HAC model, in which we identify the three domains of performance data most familiar to the user: (i)the application domain containing the application's working set, (ii) the hardware domain of the compute and network devices, and (iii) the communication domain of logical data transfers. We show that taking data from each of these domains and projecting, visualizing, and correlating it to the other domains can give valuable insights into the behavior of parallel application codes. The HAC abstraction opens the door for a new generation of tools that can help users more easily and intuitively associate performance data with root causes in the hardware system, the application's structure, and in its communication behavior, and by doing so leads to an improved understanding of the performance of their codes.",
        "author": "Schulz, Martin and Levine, Joshua A. and Bremer, Peer-Timo and Gamblin, Todd and Pascucci, Valerio",
        "booktitle": "2011 International Conference on Parallel Processing",
        "doi": "10.1109/ICPP.2011.60",
        "issn": "0190-3918",
        "keywords": "type: research,context: application, context: hardware, subcontext: network, subcontext: 3D torus, subcontext: torus, subcontext: simulation, subcontext: CPU time, vis: matrix, parallel scale: 10K",
        "pages": "206-215",
        "series": "ICPP",
        "title": "Interpreting Performance Data across Intuitive Domains",
        "type": "InProceedings",
        "year": "2011"
    },
    "Shaffer1999Virtue": {
        "abstract": "High-speed, wide-area networks have made it both possible and desirable to interconnect geographically distributed applications that control distributed collections of scientific data, remote scientific instruments, and high-performance computer systems. Historically, performance analysis has focused on monolithic applications executing on large, stand-alone, parallel systems. In such a domain, measurement, postmortem analysis, and code optimization suffice to eliminate performance bottlenecks and optimize applications. Distributed visualization, data mining, and analysis tools allow scientists to collaboratively analyze and understand complex phenomena. Likewise, real-time performance measurement and immersive performance display systems--that is, systems providing large stereoscopic displays of complex data--enable collaborating groups to interact with executing software, tuning its behavior to meet research and performance goals. To satisfy these demands, the authors designed Virtue, a prototype system that integrates collaborative, immersive performance visualization with real-time performance measurement and adaptive control of applications on computational grids. These tools enable physically distributed users to explore and steer the behavior of complex software in real time and to analyze and optimize distributed-application dynamics.",
        "author": "Shaffer, Eric and Reed, Daniel A. and Whitmore, Shannon and Schaeffer, Benjamin",
        "doi": "10.1109/2.809250",
        "issn": "0018-9162",
        "journal": "Computer",
        "keywords": "type: research, name: Virtue, context: tasks, subcontext: trace, vis: 3D, parallel scale: 100",
        "number": "12",
        "pages": "44-51",
        "title": "Virtue: performance visualization of parallel and distributed applications",
        "type": "ARTICLE",
        "volume": "32",
        "year": "1999"
    },
    "Sharma1990": {
        "abstract": "Parallel programs usually have complex execution behavior which can be studied by visualizing their execution. The run-time visualization captures the dynamic behavior of the program which is otherwise hidden by postmortem visualization. The visualization effort for hierarchical systems such as Cedar requires parallelism to be detected at cluster and processor level simultaneously. We examine the real-time visualization methodology for shared memory multiprocessors. Two applications, visualizing the concurrent processes and matrix-related computations, are used to highlight the importance of visualization in understanding parallel program execution on shared memory multiprocessors.",
        "author": "Sharma, Sanjay",
        "doi": "10.1007/3-540-53065-7_160",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: animation, context: application, vis: matrix",
        "publisher": "Springer",
        "title": "Real-time visualization of concurrent processes",
        "type": "Book",
        "year": "1990"
    },
    "Sigovan2013": {
        "abstract": "Large-scale scientific simulations require execution on parallel computing systems in order to yield useful results in a reasonable time frame. But parallel execution adds communication overhead. The impact that this overhead has on performance may be difficult to gauge, as parallel application behaviors are typically harder to understand than the sequential types. We introduce an animation-based interactive visualization technique for the analysis of communication patterns occurring in parallel application execution. Our method has the advantages of illustrating the dynamic communication patterns in the system as well as a static image of MPI (Message Passing Interface) utilization history. We also devise a data streaming mechanism that allows for the exploration of very large data sets. We demonstrate the effectiveness of our approach scaling up to 16 thousand processes using a series of trace data sets of ScaLAPACK matrix operations functions.",
        "author": "Sigovan, Carmen and Muelder, Chris and Ma, Kwan-Liu",
        "doi": "10.1111/cgf.12101",
        "issn": "1467-8659",
        "journal": "Computer Graphics Forum, Proceedings of EuroVis",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: animation, parallel scale: 10K",
        "number": "3pt2",
        "pages": "141--150",
        "publisher": "Blackwell Publishing Ltd",
        "series": "EuroVis",
        "title": "Visualizing Large-scale Parallel Communication Traces Using a Particle Animation Technique",
        "type": "article",
        "volume": "32",
        "year": "2013"
    },
    "Sigovan2013IO": {
        "abstract": "Large-scale scientific simulations require execution on parallel computing systems in order to yield useful results in a reasonable time frame. But parallel execution adds communication overhead. The impact that this overhead has on performance may be difficult to gauge, as parallel application behaviors are typically harder to understand than the sequential types. We introduce an animation-based interactive visualization technique for the analysis of communication patterns occurring in parallel application execution. Our method has the advantages of illustrating the dynamic communication patterns in the system as well as a static image of MPI (Message Passing Interface) utilization history. We also devise a data streaming mechanism that allows for the exploration of very large data sets. We demonstrate the effectiveness of our approach scaling up to 16 thousand processes using a series of trace data sets of ScaLAPACK matrix operations functions.",
        "address": "Los Alamitos, CA, USA",
        "author": "Sigovan, Carmen and Muelder, Chris and Ma, Kwan-Liu and Cope, Jason and Iskra, Kamil and Ross, Robert",
        "doi": "10.1109/IPDPS.2013.96",
        "issn": "1530-2075",
        "journal": "Proceedings of the International Parallel and Distributed Processing Symposium",
        "keywords": "type: research, context: hardware, subcontext: memory, vis: radial, parallel scale: 1K, subcontext: I/O",
        "pages": "308-319",
        "publisher": "IEEE Computer Society",
        "series": "IPDPS",
        "title": "A Visual Network Analysis Method for Large-Scale Parallel I/O Systems",
        "type": "InProceedings",
        "year": "2013"
    },
    "Sisneros2014": {
        "abstract": "For a system the scale of Blue Waters it is of primary importance to minimize high-speed network (HSN) congestion. We hypothesize that the ability to analyze the HSN in a system-wide manner will aid in the detection of network traffic patterns thereby providing a clearer picture of HSN congestion. The benefit of this is obvious we want to eliminate, or at lest minimize HSN congestion and have a better chance of doing so with a more complete understanding. To this end we have developed a visual analytics tool for viewing system-wide traffic patterns. Specifically, we employ a simple representation of Blue Waters\u2019 torus network to visually show congested areas of the network. In this work we will describe the development of this tool and demonstrate its potential uses.",
        "author": "Sisneros, Robert and Chadalavada, Kalyana",
        "booktitle": "Cray User Group Meeting",
        "keywords": "type: research, context: hardware, parallel scale: 10k, subcontext: network, subcontext: torus, subcontext: 3d torus",
        "series": "CUG",
        "title": "Toward Understanding Congestion Protection Events on Blue Waters Via Visual Analytics",
        "type": "InProceedings",
        "year": "2014"
    },
    "Socha1988Voyeur": {
        "abstract": "Voyeur is a prototype system that facilitates the construction of application-specific, visual views of parallel programs. These views range from textual views showing the contents of variables to graphical maps of the state of the computational domain of the program. These views have been instrumental in quickly detecting bugs that would have been difficult to de- tect otherwise.",
        "acmid": "69235",
        "address": "New York, NY, USA",
        "author": "Socha, David and Bailey, Mary L. and Notkin, David",
        "booktitle": "Proceedings of the 1988 ACM SIGPLAN and SIGOPS Workshop on Parallel and Distributed Debugging",
        "doi": "10.1145/68210.69235",
        "isbn": "0-89791-296-9",
        "keywords": "type: research, name: Voyeur, subcontext: debugging, context: application, context: tasks, subcontext: trace, vis: animation, context: software, subcontext: data structures, vis: node-link",
        "location": "Madison, Wisconsin, USA",
        "numpages": "10",
        "pages": "206--215",
        "publisher": "ACM",
        "series": "PADD",
        "title": "Voyeur: Graphical Views of Parallel Programs",
        "type": "InProceedings",
        "year": "1988"
    },
    "Song2004CUBE": {
        "abstract": "Performance tuning of parallel applications usually involves multiple experiments to compare the effects of differ- ent optimization strategies.  This article describes an algebra that can be used to compare, integrate, and summarize performance data from multiple sources.  The algebra consists of a data model to represent the data in a platform- independent fashion plus  arithmetic  operations to  merge, subtract, and ave rage the data from different experiments. A distinctive feature of this approach is its closure property, which allows processing and viewing all  instances of  the data model in the same way - regardless of whether they represent original or derived data - in addition to an arbitrary and easy composition of operations.",
        "author": "Song, Fengguang and Wolf, Felix and Bhatia, Nikhil and Dongarra, Jack and Moore, Shirley",
        "booktitle": "Proceedings of the 2004 International Conference on Parallel Porcessing",
        "keywords": "type: research, name: CUBE, context: software, context: hardware, vis: indented tree",
        "pages": "63 -- 72",
        "publisher": "IEEE Computer Society",
        "series": "ICCP",
        "title": "An Algebra for Cross-Experiment Performance Analysis",
        "type": "InProceedings",
        "year": "2004"
    },
    "Spear2011ParaProf": {
        "abstract": "With increases in the scale of parallelism the dimensionality and complexity of parallel performance measurements has placed greater challenges on analysis tools. Performance visualization can assist in understanding performance properties and relationships. However, the creation of new visualizations in practice is not supported by existing parallel profiling tools. Users must work with presentation types provided by a tool and have limited means to change its design. Here we present an approach for creating new performance visualizations within an existing parallel profile analysis tool. The approach separates visual layout design from the underlying performance data model, making custom visualizations such as performance over system topologies straightforward to implement and adjust for various use cases.",
        "acmid": "2238458",
        "address": "Berlin, Heidelberg",
        "author": "Spear, Wyatt and Malony, Allen D. and Lee, Chee Wai and Biersdorff, Scott and Shende, Sameer",
        "booktitle": "Proceedings of the 2011 International Conference on Parallel Processing - Volume 2",
        "doi": "10.1007/978-3-642-29740-3\\_19",
        "isbn": "978-3-642-29739-7",
        "keywords": "type: research, name: ParaProf, context: tasks, subcontext: profile, vis: 3D, vis: scripting, vis: user layout, parallel scale: 10K",
        "location": "Bordeaux, France",
        "numpages": "10",
        "pages": "156--165",
        "publisher": "Springer-Verlag",
        "series": "Lecture Notes in Computer Science",
        "title": "An Approach to Creating Performance Visualizations in a Parallel Profile Analysis Tool",
        "type": "InProceedings",
        "year": "2012"
    },
    "Stasko1993": {
        "abstract": "An application-specific visualization of a parallel program presents the inherent application domain, semantics, and data being manipulated by the program in a manner natural to one\u2032s understanding of the program. In this paper we discuss why application-specific views are necessary for program debugging, and we list several requirements and challenges that a system for application-specific viewing should meet. We also introduce an animation methodology particularly well-suited for application-specific visualizations, and we describe program animations developed using the methodology.",
        "acmid": "163550",
        "address": "Orlando, FL, USA",
        "author": "Stasko, John T. and Kraemer, Eileen",
        "doi": "10.1006/jpdc.1993.1062",
        "issn": "0743-7315",
        "issue_date": "June 1993",
        "journal": "Journal of Parallel and Distributed Computing",
        "keywords": "type: position, context: application, type: methodology, vis: animation",
        "month": "jun,",
        "number": "2",
        "numpages": "7",
        "pages": "258--264",
        "publisher": "Academic Press, Inc.",
        "series": "JPDC",
        "title": "A Methodology for Building Application-specific Visualizations of Parallel Programs",
        "type": "article",
        "volume": "18",
        "year": "1993"
    },
    "Stone1988ConcurrencyMap": {
        "abstract": "This paper describes a graphical representation called a concurency map. It provides a succinct representation of the potentially large collection of possible correct event-orderings for a se1of concurrent processes. The normal problems of monitoring, dehugging and analyzing performnce of single-process programs are compounded for programs with concurrent processes. Although we can observe the behavior of each separate process, we do not know what is occurrin g concurrently in the various processes during successive monlents as execution progresses. Furthermore, unknown timing delays among the processes may cause different program behavior when we rerun the program. The relative time-ordering of event in different concurrent processes is not, in general, fixed, ;incl events that occurred in one order on one occasion on which the program performed correctly might occur in another order on another occasion, with equal correctness. We need to know both how the program behaved during execution and how that behavior might have differed under normal variations of concurrent execution. The concurrency map aids in solving these problems.",
        "acmid": "69237",
        "address": "New York, NY, USA",
        "author": "Stone, Janice M.",
        "booktitle": "Proceedings of the 1988 ACM SIGPLAN and SIGOPS Workshop on Parallel and Distributed Debugging",
        "doi": "10.1145/68210.69237",
        "isbn": "0-89791-296-9",
        "keywords": "type: research, name: Concurrency Map, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, parallel scale: 1+",
        "location": "Madison, Wisconsin, USA",
        "numpages": "10",
        "pages": "226--235",
        "publisher": "ACM",
        "series": "PADD",
        "title": "A Graphical Representation of Concurrent Processes",
        "type": "InProceedings",
        "year": "1988"
    },
    "Summers2004": {
        "abstract": "We are exploring the development and application of information visualization techniques for the analysis of new massively parallel supercomputer architectures. Modern supercomputers typically comprise very large clusters of commodity SMPs interconnected by possibly dense and often non-standard networks. The scale, complexity, and inherent non-locality of the structure and dynamics of this hardware, and the operating systems and applications distributed over them, challenge traditional analysis methods. As part of the \u00e1 la carte (A Los Alamos Computer Architecture Toolkit for Extreme-Scale Architecture Simulation) team at Los Alamos National Laboratory, who are simulating these new architectures, we are exploring advanced visualization techniques and creating tools to enhance analysis of these simulations with intuitive three-dimensional representations and interfaces. This work complements existing and emerging algorithmic analysis tools. In this paper, we give background on the problem domain, a description of a prototypical computer architecture of interest (on the order of 10,000 processors connected by a quaternary fat-tree communications network), and a presentation of three classes of visualizations that clearly display the switching fabric and the flow of information in the interconnecting network.",
        "author": "Summers, Kenneth L. and Caudell, Thomas Preston and Berkbigler, Kathryn and Bush, Brian and Davis, Kei and Smith, Steve",
        "doi": "10.1057/palgrave.ivs.9500079",
        "journal": "Information Visualization",
        "keywords": "type: research, context: hardware, subcontext: network, vis: 2.5D, subcontext: fat tree, vis: 3D, vis: H-tree",
        "number": "3",
        "pages": "209-222",
        "title": "Graph Visualization for the Analysis of the Structure and Dynamics of Extreme-Scale Supercomputers",
        "type": "article",
        "volume": "3",
        "year": "2004"
    },
    "Tallent2011HPCToolkit": {
        "abstract": "Applications must scale well to make efficient use of even medium-scale parallel systems. Because scaling problems are often difficult to diagnose, there is a critical need for scalable tools that guide scientists to the root causes of performance bottlenecks. Although tracing is a powerful performance-analysis technique, tools that employ it can quickly become bottlenecks themselves. Moreover, to obtain actionable performance feedback for modular parallel software systems, it is often necessary to collect and present fine-grained context-sensitive data --- the very thing scalable tools avoid. While existing tracing tools can collect calling contexts, they do so only in a coarse-grained fashion; and no prior tool scalably presents both context- and time-sensitive data. This paper describes how to collect, analyze and present fine-grained call path traces for parallel programs. To scale our measurements, we use asynchronous sampling, whose granularity is controlled by a sampling frequency, and a compact representation. To present traces at multiple levels of abstraction and at arbitrary resolutions, we use sampling to render complementary slices of calling-context-sensitive trace data. Because our techniques are general, they can be used on applications that use different parallel programming models (MPI, OpenMP, PGAS). This work is implemented in HPCToolkit.",
        "acmid": "1995908",
        "address": "New York, NY, USA",
        "author": "Tallent, Nathan R. and Mellor-Crummey, John M. and Franco, Michael and Landrum, Reed and Adhianto, Laksono",
        "booktitle": "Proceedings of the International Conference on Supercomputing",
        "doi": "10.1145/1995896.1995908",
        "isbn": "978-1-4503-0102-2",
        "keywords": "type: research, name: HPCToolkit, context: tasks, subcontext: trace, vis: timelines, parallel scale: 10K",
        "location": "Tucson, Arizona, USA",
        "numpages": "12",
        "pages": "63--74",
        "publisher": "ACM",
        "series": "ICS",
        "title": "Scalable Fine-grained Call Path Tracing",
        "type": "InProceedings",
        "year": "2011"
    },
    "Tao2001": {
        "abstract": "Data locality is one of the most important issues affecting the performance of shared memory applications on NUMA architectures. A possibility to improve data locality is the specification of a correct data layout within the source code. This kind of optimization, however, requires in depth knowledge about the run-time memory access behavior of programs. In order to acquire this knowledge without causing a probe overhead, as it would be caused by software instrumentation approaches, it is necessary to adopt a hardware performance monitor that can provide detailed information about memory transactions. As the monitored information is usually very low-level and not user-readable, a visualization tool is necessary as well. This paper presents such a visualization tool displaying the monitored data in a user understandable way thereby showing the memory access behavior of shared memory applications. In addition, it projects the physical addresses in the memory transactions back to the data structures within the source code. This increases a programmer\u2019s ability to effectively understand, develop, and optimize programs.",
        "author": "Tao, Jie and Karl, Wolfgang and Schulz, Martin",
        "booktitle": "In Proceedings of the 2001 International Conference on Computational Science (ICCS), volume 2074 of LNCS",
        "doi": "10.1007/3-540-45718-6_91",
        "keywords": "type: research, context: hardware, subcontext: memory, vis: multiple views, vis: bar charts, vis: matrix, vis: time series, parallel scale: 1+",
        "pages": "861--870",
        "series": "Lecture Notes in Computer Science",
        "title": "Visualizing the Memory Access Behavior of Shared Memory Applications on NUMA Architectures",
        "type": "InProceedings",
        "year": "2001"
    },
    "Theisen2014VisTorus": {
        "abstract": "High-dimensional torus networks are becoming common in flagship HPC systems, with five of the top ten systems in June 2014 having networks with more than three dimensions. Although such networks combine performance with scalability at reasonable cost, the challenge of how to achieve optimal performance remains. Tools are needed to help understand how well the traffic is distributed among the many dimensions. This involves not only capturing network traffic but also its comprehensible visualization. However, visualizing such networks requires projecting multiple dimensions onto a two-dimensional screen, which is naturally challenging. To tackle this problem, in this position paper, we propose a visualization technique which can display traffic on torus networks with up to six dimensions. Our fundamental approach is to simultaneously present multiple views of the same network section, with each view visualizing different dimensions. Furthermore, we leverage the multiple-coordinate system concept and combine it with a customized polygon view to provide both a global and a zoomed-in perspective of the network. By interactively linking all the views, our technique makes it possible to analyze how the communication pattern of an application is mapped onto a network.",
        "author": "Theisen, Lucas and Shah, Aamer and Wolf, Felix",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "DOI 10.1109/VPA.2014.6",
        "keywords": "type: research, context: hardware, subcontext: network, name: VisTorus, subcontext: 5d torus, subcontext: 6d torus",
        "month": "Nov",
        "pages": "17 -- 23",
        "series": "VPA",
        "title": "Down to Earth \u2013 How to Visualize Traffic on High-dimensional Torus Networks",
        "type": "InProceedings",
        "year": "2014"
    },
    "Topol1998PVaniM": {
        "abstract": "Network computing has evolved into a popular and effective mode of high performance computing. Network computing environments have fundamental differences from hardware multiprocessors, involving a different approach to measuring and characterizing performance, monitoring an application\u2019s progress and understanding program behavior. In this paper, we present the design and implementation of PVaniM, an experimental visualization environment we have developed for the PVM network computing system. PVaniM supports a two-phase approach whereby on-line visualization focuses on large-grained events that are influenced by and relate to the dynamic network computing environment, and postmortem visualization provides for detailed program analysis and tuning. PVaniM\u2019s capabilities are illustrated via its use on several applications and a comparison with single-phase visualization environments developed for network computing. Our experiences indicate that, for several classes of applications, the two-phase visualization scheme can provide valuable insight into the behavior, efficiency and operation of distributed and parallel programs in network computing environments.",
        "author": "Topol, Brad and Stasko, John T. and Sunderam, Vaidy",
        "doi": "10.1002/(SICI)1096-9128(19981210)10:14<1197::AID-CPE364>3.0.CO;2-O",
        "issn": "1096-9128",
        "journal": "Concurrency: Practice and Experience",
        "keywords": "type: research, name: PVaniM, context: tasks, subcontext: commgraph, subcontext: trace, vis: timelines, vis: Gantt, vis: animation, vis: adjacency matrix, vis: bar charts, parallel scale: 1+",
        "number": "14",
        "pages": "1197--1222",
        "publisher": "John Wiley & Sons, Ltd",
        "series": "Wiley",
        "title": "PVaniM: a tool for visualization in network computing environments",
        "type": "article",
        "volume": "10",
        "year": "1998"
    },
    "Trumper2010": {
        "abstract": "Understanding multithreaded software systems is typically a tedious task: Due to parallel execution and interactions between multiple threads, such a system\u2019s runtime behavior is often much more complex than the behavior of a single-threaded system. For many maintenance activities, system understanding is a prerequisite. Hence, tasks such as bug fixing or performance optimization are highly demanding in the case of multithreaded systems. Unfortunately, state-of-the-art tools for system understanding and debuggers provide only limited support for these systems. We present a dynamic analysis and visualization technique that helps developers in understanding multithreaded software systems in general and in identifying performance bottlenecks in particular. The technique first performs method boundary trac- ing. Second, developers perform a post-mortem analysis of a system\u2019s behavior using visualization optimized for trace data of multithreaded software systems. The technique enables developers to understand how multiple threads collaborate at runtime. The technique is integrated into a professional and scalable tool for visualizing the behavior of complex software systems. In case studies, we have tested the technique with industrially developed, multithreaded software systems to understand system behavior and to identify multithreading-related performance bottlenecks.",
        "acmid": "1879232",
        "address": "New York, NY, USA",
        "author": "Tr\\\"{u}mper, Jonas and Bohnet, Johannes and D\\\"{o}llner, J\\\"{u}rgen",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879232",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, context: software, subcontext: trace, vis: icicle timelines, vis: distortion, vis: timelines, subcontext: threads",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "133--142",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Understanding Complex Multithreaded Software Systems by Using Trace Visualization",
        "type": "InProceedings",
        "year": "2010"
    },
    "VampirManual": {
        "howpublished": "\\httpAddr{www.vampir.eu}",
        "keywords": "type: manual, name: Vampir, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, subcontext: messages, vis: adjacency matrix, vis: multiple views",
        "month": "November",
        "title": "{Manual - Vampir 8.2}",
        "type": "misc",
        "year": "2013"
    },
    "Vierjahn2016": {
        "abstract": "Understanding the performance behaviour of massively parallel high-performance computing (HPC) applications based on call-path performance profiles is a time-consuming task. In this paper, we introduce the concept of directed variance in order to help analysts find performance bottlenecks in massive performance data and in the end optimize the application. According to HPC experts\u2019 requirements, our technique automatically detects severe parts in the data that expose large variation in an application\u2019s performance behaviour across system resources. Previously known variations are effectively filtered out. Analysts are thus guided through a reduced search space towards regions of interest for detailed examination in a 3D visualization. We demonstrate the effectiveness of our approach using performance data of common benchmark codes as well as from actively developed production codes.",
        "author": "Vierjahn, Tom and Hermanns, Marc-Andr{\\'e} and Mohr, Bernd and M{\\\"u}ller, Matthias S and Kuhlen, Torsten W and Hentschel, Bernd",
        "booktitle": "Proceedings of the Third International Workshop on Visual Performance Analysis",
        "keywords": "type: research, context: hardware, subcontext: profile, subcontext: torus, subcontext: 5d torus, subcontext: 3d torus, vis: 3D, vis: slices, vis: glyphs, vis: line charts, name: n/a",
        "pages": "9--16",
        "series": "VPA",
        "title": "Using directed variance to identify meaningful views in call-path performance profiles",
        "type": "inproceedings",
        "year": "2016"
    },
    "Waller2013SynchroVis": {
        "abstract": "The increasing code complexity in modern software systems exceeds the capabilities of most software engineers to understand the system\u2019s behavior by just looking at its program code. The addition of concurrency issues through the advent of multi-core processors in the consumer market further escalates this complexity. A solution to these problems is visualizing a model of the system to ease program comprehension. Especially for the comprehension of concurrency issues, static information is often not sufficient. For this purpose, profiling and monitoring can provide additional information on the actual behavior of a system. An established visualization approach is the 3D city metaphor. It utilizes the familiarity with navigating a city to improve program comprehension. In this paper, we present our trace-based SynchroVis 3D visualization approach for concurrency. It employs the city metaphor to visualize both static and dynamic properties of software systems with a focus on illustrating the concurrent behavior. To evaluate our approach, we provide an open source implementation of our concepts and present an exemplary dining philosophers scenario showing its feasibility.",
        "author": "Waller, Jan and Wulf, Christan and Fittkau, Florian and D{\\\"o}hring, Philipp and Hasselbring, Wilhelm",
        "booktitle": "1st IEEE International Working Conference  on Software Visualization (VISSOFT 2013)",
        "doi": "10.1109/VISSOFT.2013.6650520",
        "keywords": "type: research, context: software, subcontext: trace, subcontext: software design, subcontext: threads, vis: animation, vis: city metaphor, subcontext: semaphores",
        "month": "September",
        "series": "VISSOFT",
        "title": "SynchroVis: 3D Visualization of Monitoring Traces in the City Metaphor for Analyzing Concurrency",
        "type": "InProceedings",
        "year": "2013"
    },
    "Wang2000": {
        "abstract": "Code mobility has the potential to provide more flexible and efficient solutions to traditional distributed applications. However, developing distributed programs with code mobility is quite a challenge and so is the understanding of their dynamic behavior. Graphical visualizations are a promising way to help to understand the dynamic behavior of distributed applications, including those that contain mobile agents. This paper addresses two issues: what needs to be visualized and how do we visualize it. We present an innovative approach to visualizing code mobility in the context of process-time diagrams/message sequence charts. An infrastructure that provides tracing facilities and supports both on-line and postmortem visualization is discussed to demonstrate our approach.",
        "acmid": "663332",
        "address": "London, UK, UK",
        "author": "Wang, Yi and Kunz, Thomas",
        "booktitle": "Proceedings of the Second International Workshop on Mobile Agents for Telecommunication Applications",
        "doi": "10.1007/3-540-45391-1_8",
        "isbn": "3-540-41069-4",
        "keywords": "type: research, context: tasks, subcontext: trace, subcontext: migratable objects, vis: animation",
        "numpages": "12",
        "pages": "103--114",
        "publisher": "Springer-Verlag",
        "series": "MATA",
        "title": "Visualizing Mobile Agent Executions",
        "type": "InProceedings",
        "year": "2000"
    },
    "Wang2003EVolve": {
        "abstract": "Existing visualization tools typically do not allow easy extension by new visualization techniques, and are often coupled with inflexible data input mechanisms. This paper presents EVolve, a flexible and  extensible  framework  for visualizing  program  characteristics and behaviour.  The framework is flexible in the sense that it can visualize many kinds of data, and it is extensible in the sense that it is quite straightforward to add new kinds of visualizations. The overall architecture of the framework  consists of the core EVolve platform that communicates  with data sources via a well defined data protocol and which communicates with visualization methods via a visualization protocol. Given a data source, an end-user can use EVolve as a stand-alone tool  by  interactively  creating,  configuring  and  modifying  visualizations.   A  variety  of  visualizations  are  provided  in  the  current EVolve library, with features that facilitate the comparison of multiple views on the same execution data. We demonstrate EVolve in the context of visualizing execution behaviour of Java programs.",
        "author": "Wang, Qin and Wang, Wei and Brown, Rhodes and Driesen, Karel and Dufour, Bruno and Hendren, Laurie and Verbrugge, Clark",
        "booktitle": "Proceedings of the 2003 ACM Symposium on Software Visualization",
        "doi": "100.1145/774833.774839",
        "keywords": "type: research, context: software, name: EVolve, vis: dotplot, vis: icicle timelines, vis: bar charts, vis: Gantt",
        "series": "SoftVis",
        "title": "{EVolve}: An Open Extensible Software Visualization Framework",
        "type": "InProceedings",
        "year": "2003"
    },
    "Weber2015Folding": {
        "author": "Weber, Matthias and Geisler, Ronald and Brunst, Holger and Nagel, Wolfgang E.",
        "booktitle": "2015 IEEE International Parallel and Distributed Processing Symposium Workshop",
        "doi": "10.1109/IPDPSW.2015.47",
        "keywords": "type: research, subcontext: trace, context: tasks, name: Vampir, subcontext: GPUs, vis: aggregation",
        "month": "May",
        "pages": "205-214",
        "series": "IPDPSW",
        "title": "Folding Methods for Event Timelines in Performance Analysis",
        "type": "InProceedings",
        "year": "2015"
    },
    "Weber2016": {
        "abstract": "The identification of performance bottlenecks in parallel applications is a challenging task. Without some form of performance measurement tool, this task lacks any guidance and purely relies on trial-and-error. At the same time, data sets from parallel performance measurements are often large and overwhelming. We provide an effective solution to automatically identify and highlight several types of performance critical sections in an application run. Our approach first identifies time dominant functions of an application that are subsequently used to analyze runtime imbalances throughout the application run. We then present the resulting runtime variations in an intuitive visualization that guides the analyst to performance hot spots. We demonstrate the effectiveness of our approach in a case study with three applications, detecting performance problems and identifying their root-causes in all cases.",
        "author": "Weber, Matthias and Geisler, Ronald and Hilbrich, Tobias and Lieber, Matthias and Brendel, Ronny and Tsch{\\\"u}ter, Ronny and Brunst, Holger and Nagel, Wolfgang E",
        "booktitle": "Proceedings of the Workshops of the 45th International Conference on Parallel Processing",
        "doi": "10.1109/ICPPW.2016.50",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, metrics",
        "pages": "289--298",
        "series": "ICPPW",
        "title": "Detection and Visualization of Performance Variations to Guide Identification of Application Bottlenecks",
        "type": "inproceedings",
        "year": "2016"
    },
    "Weidendorfer2004": {
        "abstract": "In this paper, two tools are presented: an execution driven cache simulator which relates event metrics to a dynamically built-up call-graph, and a graphical front end able to visualize the generated data in various ways. To get a general purpose, easy-to-use tool suite, the simulation approach allows us to take advantage of runtime instrumentation, i.e. no preparation of application code is needed, and enables for sophisticated preprocessing of the data already in the simulation phase. In an ongoing project, research on advanced cache analysis is based on these tools. Taking a multigrid solver as an example, we present the results obtained from the cache simulation together with real data measured by hardware performance counters.",
        "author": "Weidendorfer, Josef and Kowarschik, Markus and Trinitis, Carsten",
        "booktitle": "Computational Science - ICCS 2004",
        "doi": "10.1007/978-3-540-24688-6_58",
        "editor": "Bubak, Marian and Albada, Geert Dick and Sloot, Peter M.A. and Dongarra, Jack",
        "isbn": "978-3-540-22116-6",
        "keywords": "type: research, context: software, subcontext: callgraph, vis: node-link, vis: treemap, parallel scale: N/A",
        "pages": "440-447",
        "publisher": "Springer Berlin Heidelberg",
        "series": "Lecture Notes in Computer Science",
        "title": "A Tool Suite for Simulation Based Analysis of Memory Access Behavior",
        "type": "InCollection",
        "volume": "3038",
        "year": "2004"
    },
    "Weyers2014": {
        "abstract": "The available memory bandwidth of existing high performance computing platforms turns out as being more and more the limitation to various applications. Therefore, modern microarchitectures integrate the memory controller on the proces- sor chip, which leads to a non-uniform memory access behavior of such systems. This access behavior in turn entails major chal- lenges in the development of shared memory parallel applications. An improperly implemented memory access functionality results in a bad ratio between local and remote memory access, and causes low performance on such architectures. To address this problem, the developers of such applications rely on tools to make these kinds of performance problems visible. This work presents a new tool for the visualization of performance data of the non-uniform memory access behavior. Because of the visual design of the tool, the developer is able to judge the severity of remote memory access in a time-dependent simulation, which is currently not possible using existing tools.",
        "author": "Weyers, Benjamin and Terboven, Christian and Schmidl, Drik and Herber, Joachim and Kuhlen, Torsten W. and M\\\"{u}ller, Matthias S. and Hentschel, Bernd",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.12",
        "keywords": "type: research, context: hardware, subcontext: memory, vis: small multiples",
        "month": "Nov",
        "pages": "43 -- 49",
        "series": "VPA",
        "title": "Visualization of Memory Access Behavior on Hierarchical NUMA Architectures",
        "type": "InProceedings",
        "year": "2014"
    },
    "Wheeler2010ThreadScope": {
        "abstract": "As highly parallel multicore machines become commonplace, programs must exhibit more concurrency to exploit the available hardware. Many multithreaded programming models already encourage programmers to create hundreds or thousands of short-lived threads that interact in complex ways. Programmers need to be able to analyze, tune, and troubleshoot these large-scale multithreaded programs. To address this problem, we present ThreadScope: a tool for tracing, visualizing, and analyzing massively multi-threaded programs. ThreadScope extracts the machine-independent program structure from execution trace data from a variety of tracing tools and displays it as a graph of dependent execution blocks and memory objects, enabling identification of synchronization and structural problems, even if they did not occur in the traced run. It also uses graph-based analysis to identify potential problems. We demonstrate the use of ThreadScope to view program structure, memory access patterns, and synchronization problems in three programming environments and seven applications.",
        "acmid": "1673015",
        "address": "Chichester, UK",
        "author": "Wheeler, Kyle B. and Thain, Douglas",
        "doi": "10.1002/cpe.v22:1",
        "issn": "1532-0626",
        "issue_date": "January 2010",
        "journal": "Concurr. Comput. : Pract. Exper.",
        "keywords": "type: research, name: ThreadScope, context: tasks, subcontext: trace, vis: node-link, subcontext: threads, subcontext: memory, parallel scale: 1K",
        "month": "jan,",
        "number": "1",
        "numpages": "23",
        "pages": "45--67",
        "publisher": "John Wiley and Sons Ltd.",
        "series": "Wiley",
        "title": "Visualizing Massively Multithreaded Applications with ThreadScope",
        "type": "article",
        "volume": "22",
        "year": "2010"
    },
    "Wilhelm2016Parceive": {
        "abstract": "Since the advent of multicore processors, developers struggle with the parallelization of legacy software. Automatic methods are only appropriate to identify parallelism at instruction level or within simple loops. For most applications, however, a scalable redesign require profound comprehension of the underlying software architecture and its dynamic aspects. This leads to an increasing demand for interactive tools that foster parallelization at various granularity levels. To cope with this problem, we propose a visualization framework, and three tailored views for parallelism detection. The framework is part of Parceive, a tool that utilizes dynamic binary instrumentation to trace C/C++ and C# programs. The cooperative views allow identification and analysis of potential parallelism scenarios using seamless navigation, abstraction, and filtering. In this paper, we motivate our approach, illustrate the architecture of the visualization framework, and highlight the key features of the views. A case study demonstrates the usefulness of Parceive.",
        "author": "Wilhelm, Andreas and Savu, Victor and Amadasun, Efe and Gerndt, Michael and Schuele, Tobias",
        "booktitle": "Proceedings of the IEEE Working Conference on Software Visualization",
        "doi": "10.1109/VISSOFT.2016.35",
        "keywords": "type: research, context: tasks, context: software, subcontext: trace, subcontext: callgraph, subcontext: code, name: Parceive",
        "pages": "81--85",
        "series": "VISSOFT",
        "title": "A Visualization Framework for Parallelization",
        "type": "inproceedings",
        "year": "2016"
    },
    "Wininger2016TraceCompass": {
        "abstract": "With newer complex multi-core systems, it is important to understand an application's runtime behavior to be able to debug its execution, detect possible problems and bottlenecks and finally identify potential root causes. Execution traces usually contain precise data about an application execution. Their analysis and abstraction at multiple levels can provide valuable information and insights about an application's runtime behavior. However, with multiple abstraction levels, it becomes increasingly difficult to find the exact location of detected performance or security problems. Tracing tools provide various analysis views to help users to understand their application problems. However, these pre-defined views are often not sufficient to reveal all analysis aspects of the underlying application. A declarative approach that enables users to specify and build their own custom analysis and views based on their knowledge, requirements and problems can be more useful and effective. In this paper, we propose a generic declarative trace analysis framework to analyze, comprehend and visualize execution traces. This enhanced framework builds custom analyses based on a specified modeled state, extracted from a system execution trace and stored in a special purpose database. The proposed solution enables users to first define their different analysis models based on their application and requirements, then visualize these models in many alternate representations (Gantt chart, XY chart, etc.), and finally filter the data to get some highlights or detect some potential patterns. Several sample applications with different operating systems are shown, using trace events gathered from Linux and Windows, at the kernel and user-space levels.",
        "author": "Wininger, Florian and Ezzati-Jivan, Naser and Dagenais, Michel R.",
        "doi": "10.1007/s11219-016-9311-0",
        "journal": "Software Quality Journal",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: declarative language, vis: gantt, vis: histogram, vis: filtering, name: trace compass",
        "pages": "1--29",
        "title": "A declarative framework for stateful analysis of execution traces",
        "type": "Article",
        "year": "2016"
    },
    "Wu2010lviz": {
        "abstract": "Operating system traces contain the detailed behavior of the persistent actions of an application; interactions between multiple applications; and the functioning of the system as a whole. The challenge is that such traces are large and consequently hard to understand and analyze. We present lviz, a novel visualization tool, which meets these challenges. We focus on Windows system traces though our visualization is general. Our visualization is flexible and can be customized to highlight different aspects of the behavior program(s) and the overall operating system.",
        "acmid": "1879231",
        "address": "New York, NY, USA",
        "author": "Wu, Yongzheng and Yap, Roland H.C. and Halim, Felix",
        "booktitle": "Proceedings of the 5th International Symposium on Software Visualization",
        "doi": "10.1145/1879211.1879231",
        "isbn": "978-1-4503-0028-5",
        "keywords": "type: research, name: lviz, context: software, subcontext: trace, vis: dotplot, vis: comparison, vis: ensemble, subcontext: jobs",
        "location": "Salt Lake City, Utah, USA",
        "numpages": "10",
        "pages": "123--132",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Visualizing Windows System Traces",
        "type": "InProceedings",
        "year": "2010"
    },
    "Wu2014CommGram": {
        "abstract": "The performance of massively parallel program is often impacted by the cost of communication across computing nodes. Analysis of communication patterns is critical for under- standing and optimizing massively parallel programs. Visualiza- tion can help identify potential communication bottlenecks by displaying message trace data. However, the visual clutter and temporal incoherence problems are typically incurred in existing visualization tools for a considerable number of processors. In this paper, we present a new tool, named CommGram, which supports visual analysis of communication patterns for massive parallel MPI programs. With the benefit of MPI trace library DUMPI of SST, our framework builds hierarchical clustering trees for computational community domain, and takes advantage of graphical user interface (GUI) to convey communication patterns at different levels of detail. The effectiveness of our tool is demonstrated using large-scale parallel applications.",
        "author": "Wu, Jieting and Zeng, Jianping and Yu, Hongfeng and Kenny, Joseph P.",
        "booktitle": "Proceedings of the 1st Workshop on Visual Performance Analysis",
        "doi": "10.1109/VPA.2014.8",
        "keywords": "type: research, context: tasks, name: CommGram, subcontext: messages, subcontext: communication, vis: splines, vis: node-link",
        "month": "Nov",
        "pages": "28 -- 35",
        "series": "VPA",
        "type": "InProceedings",
        "year": "2014"
    },
    "Wylie2011Scalasca": {
        "abstract": "The PFLOTRAN code for multiphase subsurface flow and reactive transport has featured prominently in US Department of Energy SciDAC and INCITE programmes, where is has been used to simulate migration of radionucleide contaminants in groundwater. As part of its ongoing development, execution performance with up to 128k processor cores on Cray XT and IBM BG/P systems has been investigated, and a variety of aspects have been identified to inhibit PFLOTRAN performance at larger scales using the open-source Scalasca toolset. Scalability of Scalasca measurements and analyses themselves, previously demonstrated with a range of applications and benchmarks, required re-engineering in key areas to handle the complexities of PFLOTRAN executions employing MPI within PETSc, LAPACK, BLAS and HDF5 libraries at large scale.",
        "author": "Wylie, Brian J. N. and Geimer, Markus",
        "booktitle": "Proc. of the 53rd Cray User Group meeting, Fairbanks, AK, USA",
        "keywords": "type: research, name: Scalasca, context: software, context: application, subcontext: callgraph, vis: indented tree, vis: mesh, vis: statistical plots, parallel scale: 100K",
        "month": "may,",
        "publisher": "Cray User Group Inc.",
        "series": "CUG",
        "title": "Large-scale performance analysis of {PFLOTRAN} with {Scalasca}",
        "type": "InProceedings",
        "year": "2011"
    },
    "Yamaguchi2003": {
        "abstract": "Visualization of distributed processes is useful for the management of large-scale distributed computing systems. Reactivity and scalability are especially important requirements for such visualization of distributed processes. We have proposed the visualization technique \"Data Jewelry Box\" algorithm, which satisfies both of above requirements. The technique can be applied for the visualization of distributed processes, however, the algorithm has a problem that may yield much different data layouts even among very similar datasets. This is a serious issue for the seamless visualization of time-varying data. To solve the problem, we propose the extension of \"Data Jewelry Box\" algorithm. The extension places data elements referring positions of the previous data layout, so that the extension can yield similar layouts among similar datasets. This paper introduces the extended algorithm, and proposes the visualization system for distributed computing systems using the extended algorithm.",
        "author": "Yamaguchi, Yumi and Itoh, Takayuki",
        "booktitle": "Computer Graphics International, 2003. Proceedings",
        "doi": "10.1109/CGI.2003.1214461",
        "issn": "1530-1052",
        "keywords": "type: research, name: Data Jewelry Box, vis: nesting, vis: hierarchical, vis: 3D, subcontext: migratable objects, vis: bar charts, vis: space-filling",
        "pages": "162-169",
        "title": "Visualization of distributed processes using \"Data Jewelry Box\" algorithm",
        "type": "InProceedings",
        "year": "2003"
    },
    "Yan1995AIMS": {
        "abstract": "Writing large-scale parallel and distributed scientific applications that make optimum use of the multiprocessor is a challenging problem. Typically, computational resources are underused due to performance failures in the application being executed. Performance-tuning tools are essential for exposing these performance failures and for suggesting ways to improve program performance. In this paper, we first address fundamental issues in building useful performance-tuning tools and then describe our experience with the AIMS toolkit for tuning parallel and distributed programs on a variety of platforms. AIMS supports source-code instrumentation, run-time monitoring, graphical execution profiles, performance indices and automated modeling techniques as ways to expose performance problems of programs. Using several examples representing a broad range of scientific applications, we illustrate AIMS\u2019 effectiveness in exposing performance problems in parallel and distributed programs.",
        "author": "Yan, Jerry and Sarukkai, Sekhar and Mehra, Pankaj",
        "doi": "10.1002/spe.4380250406",
        "issn": "1097-024X",
        "journal": "Software: Practice and Experience",
        "keywords": "type: research, name: AIMS, context: tasks, subcontext: trace, vis: multiple views, vis: animation, vis: Gantt, vis: timelines, subcontext: messages, vis: code, vis: node-link, vis: bar charts, vis: code tree, parallel scale: 10",
        "number": "4",
        "pages": "429--461",
        "publisher": "John Wiley & Sons, Ltd.",
        "series": "Wiley",
        "title": "Performance measurement, visualization and modeling of parallel and distributed programs using the AIMS toolkit",
        "type": "article",
        "volume": "25",
        "year": "1995"
    },
    "Yoo2016PATHA": {
        "abstract": "Big data is prevalent in HPC computing. Many HPC projects rely on complex workflows to analyze terabytes or petabytes of data. These workflows often require running over thousands of CPU cores and performing simultaneous data accesses, data movements, and computation. It is challenging to analyze the performance involving terabytes or petabytes of workflow data or measurement data of the executions, from complex workflows over a large number of nodes and multiple parallel task executions. To help identify performance bottlenecks or debug the performance issues in large-scale scientific applications and scientific clusters, we have developed a performance analysis framework, using state-ofthe-art open-source big data processing tools. Our tool can ingest system logs and application performance measurements to extract key performance features, and apply the most sophisticated statistical tools and data mining methods on the performance data. It utilizes an efficient data processing engine to allow users to interactively analyze a large amount of different types of logs and measurements. To illustrate the functionality of the big data analysis framework, we conduct case studies on the workflows from an astronomy project known as the Palomar Transient Factory (PTF) and the job logs from the genome analysis scientific cluster.",
        "author": "Yoo, Wucherl and Koo, Michelle and Cao, Yi and Sim, Alex and Nugent, Peter and Wu, Kesheng",
        "booktitle": "Conquering Big Data with High Performance Computing",
        "doi": "10.1007/978-3-319-33742-5_7",
        "keywords": "type: research, context: application, context: hardware, subcontext: checkpoints, subcontext: job logs, name: PATHA, vis: statistical plots, vis: line graphs, vis: scatterplots, vis: bar charts, vis: stacked bar charts, data mining",
        "pages": "139--161",
        "publisher": "Springer",
        "title": "Performance Analysis Tool for HPC and Big Data Applications on Scientific Clusters",
        "type": "incollection",
        "year": "2016"
    },
    "Zaki1999JumpShot": {
        "abstract": "Jumpshot is a graphical tool for understanding the performance of parallel programs. It is in the tradition of the upshot tool but contains a number of extensions and enhancements that make it suitable for large-scale parallel computations. Jumpshot takes as input a new, more flexible logfile format and comes with a library for generating such logfiles. An MPI profiling library is also included, enabling the automatic generation of such logfiles from MPI programs. Jumpshot is written in Java and can easily be integrated as an applet into browser-based computing environments. The most novel feature of Jumpshot is its automatic detection of anomalous durations, drawing the user's attention to problem areas in a parallel execution. This capability is particularly useful in large-scale parallel computations containing many events.",
        "author": "Zaki, Omer and Lusk, Ewing and Gropp, William and Swider, Deborah",
        "doi": "10.1177/109434209901300310",
        "journal": "High Performance Computing Applications",
        "keywords": "type: research, name: JumpShot, context: tasks, subcontext: trace, vis: Gantt, vis: timelines, subcontext: messages, vis: histograms, parallel scale: 10",
        "month": "Fall",
        "number": "2,",
        "pages": "277--288",
        "title": "Toward Scalable Performance Visualization with {Jumpshot}",
        "type": "Article",
        "volume": "13,",
        "year": "1999,"
    },
    "Zernik1991": {
        "acmid": "122763",
        "address": "New York, NY, USA",
        "author": "Zernik, Dror and Rudolph, Larry",
        "booktitle": "Proceedings of the 1991 ACM/ONR Workshop on Parallel and Distributed Debugging",
        "doi": "10.1145/122759.122763",
        "isbn": "0-89791-457-0",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: animation, vis: logical time, vis: multiple coordinated views, vis: tree, vis: node-link, vis: nesting, parallel scale: 1+",
        "location": "Santa Cruz, California, USA",
        "numpages": "11",
        "pages": "46--56",
        "publisher": "ACM",
        "series": "PADD",
        "title": "Animating Work and Time for Debugging Parallel Programs Foundation and Experience",
        "type": "InProceedings",
        "year": "1991"
    },
    "Zernik1992": {
        "abstract": "A visualization tool that provides an aggregate view of execution through a graph of events called the causality graph, which is suitable for systems with hundreds or thousands of processors, coarse-grained parallelism, and for a language that makes communication and synchronization explicit, is discussed. The methods for computing causality graphs and stepping through an execution with causality graphs are described. The properties of the abstraction algorithms and super nodes, the subgraphs in causality graphs, are also discussed.",
        "author": "Zernik, Dror and Snir, Marc and Malki, Dalia",
        "doi": "10.1109/52.136185",
        "issn": "0740-7459",
        "journal": "IEEE Software",
        "keywords": "type: research, context: tasks, subcontext: trace, vis: hierarchical, vis: logical time, vis: node-link, subcontext: messages, subcontext: debugging, parallel scale: 10",
        "number": "3",
        "pages": "87-92",
        "series": "IEEE Software",
        "title": "Using visualization tools to understand concurrency",
        "type": "ARTICLE",
        "volume": "9",
        "year": "1992"
    },
    "Zhou2003": {
        "abstract": "We are exploring the development and application of information visualization techniques for the analysis of new massively parallel supercomputer architectures. Modern supercomputers typically comprise very large clusters of commodity SMPs interconnected by possibly dense and often nonstandard networks. The scale, complexity, and inherent nonlocality of the structure and dynamics of this hardware, and the systems and applications distributed over it, challenge traditional analysis methods. As part of the \\'a la carte team at Los Alamos National Laboratory, who are simulating these advanced architectures, we are exploring advanced visualization techniques and creating tools to provide intuitive exploration, discovery, and analysis of these simulations. This work complements existing and emerging algorithmic analysis tools. This paper gives background on the problem domain, a description of a prototypical computer architecture of interest (on the order of 10,000 processors connected by a quaternary fat-tree communications network), and a presentation of two classes of visualizations that clearly display the switch structure and the flow of information in the interconnecting network.",
        "acmid": "774854",
        "address": "New York, NY, USA",
        "author": "Zhou, Cheng and Summers, Kenneth L. and Caudell, Thomas P.",
        "booktitle": "Proceedings of the 2003 ACM Symposium on Software Visualization",
        "doi": "10.1145/774833.774854",
        "isbn": "1-58113-642-0",
        "keywords": "type: research, context: hardware, subcontext: network, subcontext: fat tree, vis: 3D, vis: 2.5D, vis: tree, vis: H-tree",
        "location": "San Diego, California",
        "numpages": "7",
        "pages": "143--149",
        "publisher": "ACM",
        "series": "SOFTVIS",
        "title": "Graph Visualization for the Analysis of the Structure and Dynamics of Extreme-scale Supercomputers",
        "type": "InProceedings",
        "year": "2003"
    },
    "vonRuden2015": {
        "abstract": "Performance-analysis tools are indispensable for understanding and optimizing the behavior of parallel programs running on increasingly powerful supercomputers. However, with size and complexity of hardware and software on the rise, performance data sets are becoming so voluminous that their analysis poses serious challenges. In particular, the search space that must be traversed and the number of individual performance views that must be explored to identify phenomena of interest becomes too large. To mitigate this problem, we use visual analytics. Specifically, we accelerate the analysis of performance profiles by automatically identifying (1) relevant and (2) similar data subsets and their performance views. We focus on views of the virtual-process topology, showing that their relevance can be well captured with visual-quality metrics and that they can be further assigned to topical groups according to their visual features. A case study demonstrates that our approach helps reduce the search space by up to 80\\%.",
        "acmid": "2835242",
        "articleno": "4",
        "author": "von R\\\"{u}den, Laura and Hermanns, Marc-Andr{\\'e} and Behrisch, Michael and Keim, Daniel and Mohr, Bernd and Wolf, Felix",
        "booktitle": "Proceedings of the 2Nd Workshop on Visual Performance Analysis",
        "doi": "10.1145/2835238.2835242",
        "keywords": "type: research, vis: visual analytics, vis: filtering, context: hardware, context: software, subcontext: load-balancing, vis: matrix, name: CUBE",
        "numpages": "8",
        "pages": "4:1--4:8",
        "publisher": "ACM",
        "series": "VPA",
        "title": "Separating the Wheat from the Chaff: Identifying Relevant and Similar Performance Data with Visual Analytics",
        "type": "InProceedings",
        "year": "2015"
    }
}});